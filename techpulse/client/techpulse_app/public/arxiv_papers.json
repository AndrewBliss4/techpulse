[
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.06279v1",
        "title": "Mitigating Blockchain extractable value (BEV) threats by Distributed Transaction Sequencing in Blockchains",
        "authors": [
            "Xiongfei Zhao",
            "Hou-Wan Long",
            "Zhengzhe Li",
            "Jiangchuan Liu",
            "Yain-Whar Si"
        ],
        "published": "2025-03-08T16:55:52Z",
        "summary": "The rapid growth of Blockchain and Decentralized Finance (DeFi) has introduced new challenges and vulnerabilities that threaten the integrity and efficiency of the ecosystem. This study identifies critical issues such as Transaction Order Dependence (TOD), Blockchain Extractable Value (BEV), and Transaction Importance Diversity (TID), which collectively undermine the fairness and security of DeFi systems. BEV-related activities, including Sandwich attacks, Liquidations, and Transaction Replay, have emerged as significant threats, collectively generating $540.54 million in losses over 32 months across 11,289 addresses, involving 49,691 cryptocurrencies and 60,830 on-chain markets. These attacks exploit transaction mechanics to manipulate asset prices and extract value at the expense of other participants, with Sandwich attacks being particularly impactful. Additionally, the growing adoption of Blockchain in traditional finance highlights the challenge of TID, where high transaction volumes can strain systems and compromise time-sensitive operations. To address these pressing issues, we propose a novel Distributed Transaction Sequencing Strategy (DTSS), which combines forking mechanisms and the Analytic Hierarchy Process (AHP) to enforce fair and transparent transaction ordering in a decentralized manner. Our approach is further enhanced by an optimization framework and the introduction of the Normalized Allocation Disparity Metric (NADM), which ensures optimal parameter selection for transaction prioritization. Experimental evaluations demonstrate that DTSS effectively mitigates BEV risks, enhances transaction fairness, and significantly improves the security and transparency of DeFi ecosystems. This work is essential for protecting the future of decentralized finance and promoting its integration into global financial systems.",
        "field": "Decentralized Finance (DeFi)",
        "link": "http://arxiv.org/abs/2503.06279v1"
    },
    {
        "id": "2503.04850v2",
        "title": "Slow is Fast! Dissecting Ethereum's Slow Liquidity Drain Scams",
        "authors": [
            "Minh Trung Tran",
            "Nasrin Sohrabi",
            "Zahir Tari",
            "Qin Wang",
            "Xiaoyu Xia"
        ],
        "published": "2025-03-06T02:24:35Z",
        "summary": "We identify the slow liquidity drain (SLID) scam, an insidious and highly profitable threat to decentralized finance (DeFi), posing a large-scale, persistent, and growing risk to the ecosystem. Unlike traditional scams such as rug pulls or honeypots (USENIX Sec'19, USENIX Sec'23), SLID gradually siphons funds from liquidity pools over extended periods, making detection significantly more challenging. In this paper, we conducted the first large-scale empirical analysis of 319,166 liquidity pools across six major decentralized exchanges (DEXs) since 2018. We identified 3,117 SLID affected liquidity pools, resulting in cumulative losses of more than US$103 million. We propose a rule-based heuristic and an enhanced machine learning model for early detection. Our machine learning model achieves a detection speed 4.77 times faster than the heuristic while maintaining 95% accuracy. Our study establishes a foundation for protecting DeFi investors at an early stage and promoting transparency in the DeFi ecosystem.",
        "field": "Decentralized Finance (DeFi)",
        "link": "http://arxiv.org/abs/2503.04850v2"
    },
    {
        "id": "2503.01944v1",
        "title": "Protecting DeFi Platforms against Non-Price Flash Loan Attacks",
        "authors": [
            "Abdulrahman Alhaidari",
            "Balaji Palanisamy",
            "Prashant Krishnamurthy"
        ],
        "published": "2025-03-03T18:18:05Z",
        "summary": "Smart contracts in Decentralized Finance (DeFi) platforms are attractive targets for attacks as their vulnerabilities can lead to massive amounts of financial losses. Flash loan attacks, in particular, pose a major threat to DeFi protocols that hold a Total Value Locked (TVL) exceeding \\$106 billion. These attacks use the atomicity property of blockchains to drain funds from smart contracts in a single transaction. While existing research primarily focuses on price manipulation attacks, such as oracle manipulation, mitigating non-price flash loan attacks that often exploit smart contracts' zero-day vulnerabilities remains largely unaddressed. These attacks are challenging to detect because of their unique patterns, time sensitivity, and complexity. In this paper, we present FlashGuard, a runtime detection and mitigation method for non-price flash loan attacks. Our approach targets smart contract function signatures to identify attacks in real-time and counterattack by disrupting the attack transaction atomicity by leveraging the short window when transactions are visible in the mempool but not yet confirmed. When FlashGuard detects an attack, it dispatches a stealthy dusting counterattack transaction to miners to change the victim contract's state which disrupts the attack's atomicity and forces the attack transaction to revert. We evaluate our approach using 20 historical attacks and several unseen attacks. FlashGuard achieves an average real-time detection latency of 150.31ms, a detection accuracy of over 99.93\\%, and an average disruption time of 410.92ms. FlashGuard could have potentially rescued over \\$405.71 million in losses if it were deployed prior to these attack instances. FlashGuard demonstrates significant potential as a DeFi security solution to mitigate and handle rising threats of non-price flash loan attacks.",
        "field": "Decentralized Finance (DeFi)",
        "link": "http://arxiv.org/abs/2503.01944v1"
    },
    {
        "id": "2502.11521v1",
        "title": "DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning",
        "authors": [
            "Juantao Zhong",
            "Daoyuan Wu",
            "Ye Liu",
            "Maoyi Xie",
            "Yang Liu",
            "Yi Li",
            "Ning Liu"
        ],
        "published": "2025-02-17T07:45:03Z",
        "summary": "DeFi (Decentralized Finance) is one of the most important applications of today's cryptocurrencies and smart contracts. It manages hundreds of billions in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi price manipulation attacks. Despite state-of-the-art (SOTA) systems like DeFiRanger and DeFort, we found that they are less effective to non-standard price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi price manipulation attacks reported over the past three years. In this paper, we introduce the first LLM-based approach, DeFiScope, for detecting DeFi price manipulation attacks in both standard and custom price models. Our insight is that large language models (LLMs) have certain intelligence to abstract price calculation from code and infer the trend of token price changes based on the extracted price models. To further strengthen LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it to fine-tune a DeFi price-specific LLM. Together with the high-level DeFi operations recovered from low-level transaction data, DeFiScope detects various DeFi price manipulations according to systematically mined patterns. Experimental results show that DeFiScope achieves a high precision of 96% and a recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by helping our industry partner confirm 147 real-world price manipulation attacks, including discovering 81 previously unknown historical incidents.",
        "field": "Decentralized Finance (DeFi)",
        "link": "http://arxiv.org/abs/2502.11521v1"
    },
    {
        "id": "2502.13167v1",
        "title": "SmartLLM: Smart Contract Auditing using Custom Generative AI",
        "authors": [
            "Jun Kevin",
            "Pujianto Yugopuspito"
        ],
        "published": "2025-02-17T06:22:05Z",
        "summary": "Smart contracts are essential to decentralized finance (DeFi) and blockchain ecosystems but are increasingly vulnerable to exploits due to coding errors and complex attack vectors. Traditional static analysis tools and existing vulnerability detection methods often fail to address these challenges comprehensively, leading to high false-positive rates and an inability to detect dynamic vulnerabilities. This paper introduces SmartLLM, a novel approach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented Generation (RAG) to enhance the accuracy and efficiency of smart contract auditing. By integrating domain-specific knowledge from ERC standards and employing advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM achieves superior performance compared to static analysis tools like Mythril and Slither, as well as zero-shot large language model (LLM) prompting methods such as GPT-3.5 and GPT-4. Experimental results demonstrate a perfect recall of 100% and an accuracy score of 70%, highlighting the model's robustness in identifying vulnerabilities, including reentrancy and access control issues. This research advances smart contract security by offering a scalable and effective auditing solution, supporting the secure adoption of decentralized applications.",
        "field": "Decentralized Finance (DeFi)",
        "link": "http://arxiv.org/abs/2502.13167v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Artificial Intelligence (AI) in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Artificial Intelligence (AI) in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Artificial Intelligence (AI) in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Artificial Intelligence (AI) in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Artificial Intelligence (AI) in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2412.04051v1",
        "title": "How to design a Public Key Infrastructure for a Central Bank Digital Currency",
        "authors": [
            "Makan Rafiee",
            "Lars Hupel"
        ],
        "published": "2024-12-05T10:41:38Z",
        "summary": "Central Bank Digital Currency (CBDC) is a new form of money, issued by a country's or region's central bank, that can be used for a variety of payment scenarios. Depending on its concrete implementation, there are many participants in a production CBDC ecosystem, including the central bank, commercial banks, merchants, individuals, and wallet providers. There is a need for robust and scalable Public Key Infrastructure (PKI) for CBDC to ensure the continued trust of all entities in the system. This paper discusses the criteria that should flow into the design of a PKI and proposes a certificate hierarchy, together with a rollover concept ensuring continuous operation of the system. We further consider several peculiarities, such as the circulation of offline-capable hardware wallets.",
        "field": "Central Bank Digital Currencies (CBDCs)",
        "link": "http://arxiv.org/abs/2412.04051v1"
    },
    {
        "id": "2411.06362v1",
        "title": "Will Central Bank Digital Currencies (CBDC) and Blockchain Cryptocurrencies Coexist in the Post Quantum Era?",
        "authors": [
            "Abraham Itzhak Weinberg",
            "Pythagoras Petratos",
            "Alessio Faccia"
        ],
        "published": "2024-11-10T05:05:55Z",
        "summary": "This paper explores the coexistence possibilities of Central Bank Digital Currencies (CBDCs) and blockchain-based cryptocurrencies within a post-quantum computing landscape. It examines the implications of emerging quantum algorithms and cryptographic techniques such as Multi-Party Computation (MPC) and Oblivious Transfer (OT). While exploring how CBDCs and cryptocurrencies might integrate defenses like post-quantum cryptography, it highlights the substantial hurdles in transitioning legacy systems and fostering widespread adoption of new standards. The paper includes comprehensive evaluations of CBDCs in a quantum context. It also features comparisons to alternative cryptocurrency models. Additionally, the paper provides insightful analyses of pertinent quantum methodologies. Examinations of interfaces between these methods and blockchain architectures are also included. The paper carries out considered appraisals of quantum threats and their relevance for cryptocurrency schemes. Furthermore, it features discussions of the influence of anticipated advances in quantum computing on algorithms and their applications. The paper renders the judicious conclusion that long-term coexistence is viable provided challenges are constructively addressed through ongoing collaborative efforts to validate solutions and guide evolving policies.",
        "field": "Central Bank Digital Currencies (CBDCs)",
        "link": "http://arxiv.org/abs/2411.06362v1"
    },
    {
        "id": "2408.06956v1",
        "title": "PayOff: A Regulated Central Bank Digital Currency with Private Offline Payments",
        "authors": [
            "Carolin Beer",
            "Sheila Zingg",
            "Kari Kostiainen",
            "Karl WÃ¼st",
            "Vedran Capkun",
            "Srdjan Capkun"
        ],
        "published": "2024-08-13T15:15:06Z",
        "summary": "The European Central Bank is preparing for the potential issuance of a central bank digital currency (CBDC), called the digital euro. A recent regulatory proposal by the European Commission defines several requirements for the digital euro, such as support for both online and offline payments. Offline payments are expected to enable cash-like privacy, local payment settlement, and the enforcement of holding limits. While other central banks have expressed similar desired functionality, achieving such offline payments poses a novel technical challenge. We observe that none of the existing research solutions, including offline E-cash schemes, are fully compliant. Proposed solutions based on secure elements offer no guarantees in case of compromise and can therefore lead to significant payment fraud. The main contribution of this paper is PayOff, a novel CBDC design motivated by the digital euro regulation, which focuses on offline payments. We analyze the security implications of local payment settlement and identify new security objectives. PayOff protects user privacy, supports complex regulations such as holding limits, and implements safeguards to increase robustness against secure element failure. Our analysis shows that PayOff provides strong privacy and identifies residual leakages that may arise in real-world deployments. Our evaluation shows that offline payments can be fast and that the central bank can handle high payment loads with moderate computing resources. However, the main limitation of PayOff is that offline payment messages and storage requirements grow in the number of payments that the sender makes or receives without going online in between.",
        "field": "Central Bank Digital Currencies (CBDCs)",
        "link": "http://arxiv.org/abs/2408.06956v1"
    },
    {
        "id": "2407.13776v1",
        "title": "Offline Digital Euro: a Minimum Viable CBDC using Groth-Sahai proofs",
        "authors": [
            "Leon Kempen",
            "Johan Pouwelse"
        ],
        "published": "2024-07-01T09:55:14Z",
        "summary": "Current digital payment solutions are fragile and offer less privacy than traditional cash. Their critical dependency on an online service used to perform and validate transactions makes them void if this service is unreachable. Moreover, no transaction can be executed during server malfunctions or power outages. Due to climate change, the likelihood of extreme weather increases. As extreme weather is a major cause of power outages, the frequency of power outages is expected to increase. The lack of privacy is an inherent result of their account-based design or the use of a public ledger. The critical dependency and lack of privacy can be resolved with a Central Bank Digital Currency that can be used offline. This thesis proposes a design and a first implementation for an offline-first digital euro. The protocol offers complete privacy during transactions using zero-knowledge proofs. Furthermore, transactions can be executed offline without third parties and retroactive double-spending detection is facilitated. To protect the users' privacy, but also guard against money laundering, we have added the following privacy-guarding mechanism. The bank and trusted third parties for law enforcement must collaborate to decrypt transactions, revealing the digital pseudonym used in the transaction. Importantly, the transaction can be decrypted without decrypting prior transactions attached to the digital euro. The protocol has a working initial implementation showcasing its usability and demonstrating functionality.",
        "field": "Central Bank Digital Currencies (CBDCs)",
        "link": "http://arxiv.org/abs/2407.13776v1"
    },
    {
        "id": "2405.10678v1",
        "title": "IT Strategic alignment in the decentralized finance (DeFi): CBDC and digital currencies",
        "authors": [
            "Carlos Alberto Durigan Junior",
            "Fernando Jose Barbin Laurindo"
        ],
        "published": "2024-05-17T10:19:20Z",
        "summary": "Cryptocurrency can be understood as a digital asset transacted among participants in the crypto economy. Every cryptocurrency must have an associated Blockchain. Blockchain is a Distributed Ledger Technology (DLT) which supports cryptocurrencies, this may be considered as the most promising disruptive technology in the industry 4.0 context. Decentralized finance (DeFi) is a Blockchain-based financial infrastructure, the term generally refers to an open, permissionless, and highly interoperable protocol stack built on public smart contract platforms, such as the Ethereum Blockchain. It replicates existing financial services in a more open and transparent way. DeFi does not rely on intermediaries and centralized institutions. Instead, it is based on open protocols and decentralized applications (Dapps). Considering that there are many digital coins, stablecoins and central bank digital currencies (CBDCs), these currencies should interact among each other sometime. For this interaction the Information Technology elements play an important whole as enablers and IT strategic alignment. This paper considers the strategic alignment model proposed by Henderson and Venkatraman (1993) and Luftman (1996). This paper seeks to answer two main questions 1) What are the common IT elements in the DeFi? And 2) How the elements connect to the IT strategic alignment in DeFi? Through a Systematic Literature Review (SLR). Results point out that there are many IT elements already mentioned by literature, however there is a lack in the literature about the connection between IT elements and IT strategic alignment in a Decentralized Finance (DeFi) architectural network. After final considerations, limitations and future research agenda are presented. Keywords: IT Strategic alignment, Decentralized Finance (DeFi), Cryptocurrency, Digital Economy.",
        "field": "Central Bank Digital Currencies (CBDCs)",
        "link": "http://arxiv.org/abs/2405.10678v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Cybersecurity in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Cybersecurity in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Cybersecurity in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Cybersecurity in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Cybersecurity in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Biometrics in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Edge Computing in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Internet of Things (IoT) in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Internet of Things (IoT) in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Internet of Things (IoT) in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Internet of Things (IoT) in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Internet of Things (IoT) in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "5G Technology in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "5G Technology in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "5G Technology in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "5G Technology in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "5G Technology in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "Digital Identity Verification",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "Digital Identity Verification",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09513v1",
        "title": "RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment",
        "authors": [
            "Md Morshed Alam",
            "Lokesh Chandra Das",
            "Sandip Roy",
            "Sachin Shetty",
            "Weichao Wang"
        ],
        "published": "2025-03-12T16:23:14Z",
        "summary": "Internet of Things (IoT) platforms with trigger-action capability allow event conditions to trigger actions in IoT devices autonomously by creating a chain of interactions. Adversaries exploit this chain of interactions to maliciously inject fake event conditions into IoT hubs, triggering unauthorized actions on target IoT devices to implement remote injection attacks. Existing defense mechanisms focus mainly on the verification of event transactions using physical event fingerprints to enforce the security policies to block unsafe event transactions. These approaches are designed to provide offline defense against injection attacks. The state-of-the-art online defense mechanisms offer real-time defense, but extensive reliability on the inference of attack impacts on the IoT network limits the generalization capability of these approaches. In this paper, we propose a platform-independent multi-agent online defense system, namely RESTRAIN, to counter remote injection attacks at runtime. RESTRAIN allows the defense agent to profile attack actions at runtime and leverages reinforcement learning to optimize a defense policy that complies with the security requirements of the IoT network. The experimental results show that the defense agent effectively takes real-time defense actions against complex and dynamic remote injection attacks and maximizes the security gain with minimal computational overhead.",
        "field": "Digital Identity Verification",
        "link": "http://arxiv.org/abs/2503.09513v1"
    },
    {
        "id": "2503.09433v1",
        "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection",
        "authors": [
            "Richard A. Dubniczky",
            "Krisztofer ZoltÃ¡n HorvÃ¡t",
            "TamÃ¡s Bisztray",
            "Mohamed Amine Ferrag",
            "Lucas C. Cordeiro",
            "Norbert Tihanyi"
        ],
        "published": "2025-03-12T14:30:05Z",
        "summary": "Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at https://github.com/CASTLE-Benchmark.",
        "field": "Digital Identity Verification",
        "link": "http://arxiv.org/abs/2503.09433v1"
    },
    {
        "id": "2503.08923v1",
        "title": "Enhancing Large Language Models for Hardware Verification: A Novel SystemVerilog Assertion Dataset",
        "authors": [
            "Anand Menon",
            "Samit S Miftah",
            "Shamik Kundu",
            "Souvik Kundu",
            "Amisha Srivastava",
            "Arnab Raha",
            "Gabriel Theodor Sonnenschein",
            "Suvadeep Banerjee",
            "Deepak Mathaikutty",
            "Kanad Basu"
        ],
        "published": "2025-03-11T22:13:26Z",
        "summary": "Hardware verification is crucial in modern SoC design, consuming around 70% of development time. SystemVerilog assertions ensure correct functionality. However, existing industrial practices rely on manual efforts for assertion generation, which becomes increasingly untenable as hardware systems become complex. Recent research shows that Large Language Models (LLMs) can automate this process. However, proprietary SOTA models like GPT-4o often generate inaccurate assertions and require expensive licenses, while smaller open-source LLMs need fine-tuning to manage HDL code complexities. To address these issues, we introduce **VERT**, an open-source dataset designed to enhance SystemVerilog assertion generation using LLMs. VERT enables researchers in academia and industry to fine-tune open-source models, outperforming larger proprietary ones in both accuracy and efficiency while ensuring data privacy through local fine-tuning and eliminating costly licenses. The dataset is curated by systematically augmenting variables from open-source HDL repositories to generate synthetic code snippets paired with corresponding assertions. Experimental results demonstrate that fine-tuned models like Deepseek Coder 6.7B and Llama 3.1 8B outperform GPT-4o, achieving up to 96.88% improvement over base models and 24.14% over GPT-4o on platforms including OpenTitan, CVA6, OpenPiton and Pulpissimo. VERT is available at https://github.com/AnandMenon12/VERT.",
        "field": "Digital Identity Verification",
        "link": "http://arxiv.org/abs/2503.08923v1"
    },
    {
        "id": "2503.11053v1",
        "title": "Pricing American Parisian Options under General Time-Inhomogeneous Markov Models",
        "authors": [
            "Yuhao Liu",
            "Nian Yang",
            "Gongqiu Zhang"
        ],
        "published": "2025-03-14T03:45:18Z",
        "summary": "This paper develops general approaches for pricing various types of American-style Parisian options (down-in/-out, perpetual/finite-maturity) with general payoff functions based on continuous-time Markov chain (CTMC) approximation under general 1D time-inhomogeneous Markov models. For the down-in types, by conditioning on the Parisian stopping time, we reduce the pricing problem to that of a series of vanilla American options with different maturities and their prices integrated with the distribution function of the Parisian stopping time yield the American Parisian down-in option price. This facilitates an efficient application of CTMC approximation to obtain the approximate option price by calculating the required quantities. For the perpetual down-in cases under time-homogeneous models, significant computational cost can be reduced. The down-out cases are more complicated, for which we use the state augmentation approach to record the excursion duration and then the approximate option price is obtained by solving a series of variational inequalities recursively with the Lemke's pivoting method. We show the convergence of CTMC approximation for all the types of American Parisian options under general time-inhomogeneous Markov models, and the accuracy and efficiency of our algorithms are confirmed with extensive numerical experiments.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.11053v1"
    },
    {
        "id": "2503.09988v1",
        "title": "Label Unbalance in High-frequency Trading",
        "authors": [
            "Zijian Zhao",
            "Xuming Chen",
            "Jiayu Wen",
            "Mingwen Liu",
            "Xiaoteng Ma"
        ],
        "published": "2025-03-13T02:55:06Z",
        "summary": "In financial trading, return prediction is one of the foundation for a successful trading system. By the fast development of the deep learning in various areas such as graphical processing, natural language, it has also demonstrate significant edge in handling with financial data. While the success of the deep learning relies on huge amount of labeled sample, labeling each time/event as profitable or unprofitable, under the transaction cost, especially in the high-frequency trading world, suffers from serious label imbalance issue.In this paper, we adopts rigurious end-to-end deep learning framework with comprehensive label imbalance adjustment methods and succeed in predicting in high-frequency return in the Chinese future market. The code for our method is publicly available at https://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.09988v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.06707v1",
        "title": "Axes that matter: PCA with a difference",
        "authors": [
            "Brian Huge",
            "Antoine Savine"
        ],
        "published": "2025-03-09T17:47:25Z",
        "summary": "We extend the scope of differential machine learning and introduce a new breed of supervised principal component analysis to reduce dimensionality of Derivatives problems. Applications include the specification and calibration of pricing models, the identification of regression features in least-square Monte-Carlo, and the pre-processing of simulated datasets for (differential) machine learning.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.06707v1"
    },
    {
        "id": "2503.06279v1",
        "title": "Mitigating Blockchain extractable value (BEV) threats by Distributed Transaction Sequencing in Blockchains",
        "authors": [
            "Xiongfei Zhao",
            "Hou-Wan Long",
            "Zhengzhe Li",
            "Jiangchuan Liu",
            "Yain-Whar Si"
        ],
        "published": "2025-03-08T16:55:52Z",
        "summary": "The rapid growth of Blockchain and Decentralized Finance (DeFi) has introduced new challenges and vulnerabilities that threaten the integrity and efficiency of the ecosystem. This study identifies critical issues such as Transaction Order Dependence (TOD), Blockchain Extractable Value (BEV), and Transaction Importance Diversity (TID), which collectively undermine the fairness and security of DeFi systems. BEV-related activities, including Sandwich attacks, Liquidations, and Transaction Replay, have emerged as significant threats, collectively generating $540.54 million in losses over 32 months across 11,289 addresses, involving 49,691 cryptocurrencies and 60,830 on-chain markets. These attacks exploit transaction mechanics to manipulate asset prices and extract value at the expense of other participants, with Sandwich attacks being particularly impactful. Additionally, the growing adoption of Blockchain in traditional finance highlights the challenge of TID, where high transaction volumes can strain systems and compromise time-sensitive operations. To address these pressing issues, we propose a novel Distributed Transaction Sequencing Strategy (DTSS), which combines forking mechanisms and the Analytic Hierarchy Process (AHP) to enforce fair and transparent transaction ordering in a decentralized manner. Our approach is further enhanced by an optimization framework and the introduction of the Normalized Allocation Disparity Metric (NADM), which ensures optimal parameter selection for transaction prioritization. Experimental evaluations demonstrate that DTSS effectively mitigates BEV risks, enhances transaction fairness, and significantly improves the security and transparency of DeFi ecosystems. This work is essential for protecting the future of decentralized finance and promoting its integration into global financial systems.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.06279v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Synthetic Data in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Synthetic Data in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Synthetic Data in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Synthetic Data in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Synthetic Data in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09327v1",
        "title": "Heuristic-Based Address Clustering in Cardano Blockchain",
        "authors": [
            "Mostafa Chegenizadeh",
            "Sina Rafati Niya",
            "Claudio J. Tessone"
        ],
        "published": "2025-03-12T12:22:26Z",
        "summary": "Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.09327v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Digital Twin Technology in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Digital Twin Technology in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Digital Twin Technology in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Digital Twin Technology in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Digital Twin Technology in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Quantum Machine Learning in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Quantum Machine Learning in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Quantum Machine Learning in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Quantum Machine Learning in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Quantum Machine Learning in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Augmented Reality (AR) in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Augmented Reality (AR) in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Augmented Reality (AR) in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Augmented Reality (AR) in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Augmented Reality (AR) in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Federated Learning in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Federated Learning in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Federated Learning in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Federated Learning in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Federated Learning in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "1603.00991v2",
        "title": "Financial Services, Economic Growth and Well-Being: A Four-Pronged Study",
        "authors": [
            "Ravi Kashyap"
        ],
        "published": "2016-03-03T06:35:43Z",
        "summary": "A four-pronged approach to dealing with Social Science Phenomenon is outlined. This methodology is applied to Financial Services, Economic Growth and Well-Being. The four prongs are like the four directions for an army general looking for victory. Just like the four directions, we need to be aware that there is a degree of interconnectedness in the below four prongs. -Uncertainty Principle of the Social Sciences -Responsibilities of Fiscal Janitors -Need for Smaller Organizations -Redirecting Growth that Generates Garbage The importance of gaining a more profound comprehension of welfare and delineating its components into those that result from an increase in goods and services, and hence can be attributed to economic growth, and into those that are not related to economic growth but lead to a better quality of life, is highlighted. The reasoning being that economic growth alone is an inadequate indicator of well-being. Hand in hand with a better understanding of the characteristics of welfare, comes the need to consider the metrics we currently have that gauge economic growth and supplement those with measures that capture well-being more holistically.",
        "field": "Digital Therapeutics in Financial Well-being",
        "link": "http://arxiv.org/abs/1603.00991v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Blockchain Interoperability in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Blockchain Interoperability in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Blockchain Interoperability in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Blockchain Interoperability in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Blockchain Interoperability in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Metaverse Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Metaverse Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Metaverse Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Metaverse Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Metaverse Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Quantum Cryptography in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Quantum Cryptography in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Quantum Cryptography in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Quantum Cryptography in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Quantum Cryptography in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.09433v1",
        "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection",
        "authors": [
            "Richard A. Dubniczky",
            "Krisztofer ZoltÃ¡n HorvÃ¡t",
            "TamÃ¡s Bisztray",
            "Mohamed Amine Ferrag",
            "Lucas C. Cordeiro",
            "Norbert Tihanyi"
        ],
        "published": "2025-03-12T14:30:05Z",
        "summary": "Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at https://github.com/CASTLE-Benchmark.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.09433v1"
    },
    {
        "id": "2503.09317v1",
        "title": "RaceTEE: A Practical Privacy-Preserving Off-Chain Smart Contract Execution Architecture",
        "authors": [
            "Keyu Zhang",
            "Andrew Martin"
        ],
        "published": "2025-03-12T12:10:02Z",
        "summary": "Decentralized on-chain smart contracts enable trustless collaboration, yet their inherent data transparency and execution overhead hinder widespread adoption. Existing cryptographic approaches incur high computational costs and lack generality. Meanwhile, prior TEE-based solutions suffer from practical limitations, such as the inability to support inter-contract interactions, reliance on unbreakable TEEs, and compromised usability. We introduce RaceTEE, a practical and privacy-preserving off-chain execution architecture for smart contracts that leverages Trusted Execution Environments (TEEs). RaceTEE decouples transaction ordering (on-chain) from execution (off-chain), with computations performed competitively in TEEs, ensuring confidentiality and minimizing overhead. It further enhances practicality through three key improvements: supporting secure inter-contract interactions, providing a key rotation scheme that enforces forward and backward secrecy even in the event of TEE breaches, and enabling full compatibility with existing blockchains without altering the user interaction model. To validate its feasibility, we prototype RaceTEE using Intel SGX and Ethereum, demonstrating its applicability across various use cases and evaluating its performance.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.09317v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "RegTech in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "RegTech in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "RegTech in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "RegTech in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "RegTech in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Voice Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Voice Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Voice Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Voice Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Voice Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "the current frontier of banking technology",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "the current frontier of banking technology",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "the current frontier of banking technology",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "the current frontier of banking technology",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09327v1",
        "title": "Heuristic-Based Address Clustering in Cardano Blockchain",
        "authors": [
            "Mostafa Chegenizadeh",
            "Sina Rafati Niya",
            "Claudio J. Tessone"
        ],
        "published": "2025-03-12T12:22:26Z",
        "summary": "Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.",
        "field": "the current frontier of banking technology",
        "link": "http://arxiv.org/abs/2503.09327v1"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "Blockchain Technology",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "Blockchain Technology",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "Blockchain Technology",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "Blockchain Technology",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09327v1",
        "title": "Heuristic-Based Address Clustering in Cardano Blockchain",
        "authors": [
            "Mostafa Chegenizadeh",
            "Sina Rafati Niya",
            "Claudio J. Tessone"
        ],
        "published": "2025-03-12T12:22:26Z",
        "summary": "Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.",
        "field": "Blockchain Technology",
        "link": "http://arxiv.org/abs/2503.09327v1"
    },
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "Edge Computing",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Edge Computing",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Edge Computing",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "Edge Computing",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "Edge Computing",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "5G Technology",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "5G Technology",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "5G Technology",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "5G Technology",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09327v1",
        "title": "Heuristic-Based Address Clustering in Cardano Blockchain",
        "authors": [
            "Mostafa Chegenizadeh",
            "Sina Rafati Niya",
            "Claudio J. Tessone"
        ],
        "published": "2025-03-12T12:22:26Z",
        "summary": "Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.",
        "field": "5G Technology",
        "link": "http://arxiv.org/abs/2503.09327v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "Internet of Things (IoT)",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09513v1",
        "title": "RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment",
        "authors": [
            "Md Morshed Alam",
            "Lokesh Chandra Das",
            "Sandip Roy",
            "Sachin Shetty",
            "Weichao Wang"
        ],
        "published": "2025-03-12T16:23:14Z",
        "summary": "Internet of Things (IoT) platforms with trigger-action capability allow event conditions to trigger actions in IoT devices autonomously by creating a chain of interactions. Adversaries exploit this chain of interactions to maliciously inject fake event conditions into IoT hubs, triggering unauthorized actions on target IoT devices to implement remote injection attacks. Existing defense mechanisms focus mainly on the verification of event transactions using physical event fingerprints to enforce the security policies to block unsafe event transactions. These approaches are designed to provide offline defense against injection attacks. The state-of-the-art online defense mechanisms offer real-time defense, but extensive reliability on the inference of attack impacts on the IoT network limits the generalization capability of these approaches. In this paper, we propose a platform-independent multi-agent online defense system, namely RESTRAIN, to counter remote injection attacks at runtime. RESTRAIN allows the defense agent to profile attack actions at runtime and leverages reinforcement learning to optimize a defense policy that complies with the security requirements of the IoT network. The experimental results show that the defense agent effectively takes real-time defense actions against complex and dynamic remote injection attacks and maximizes the security gain with minimal computational overhead.",
        "field": "Internet of Things (IoT)",
        "link": "http://arxiv.org/abs/2503.09513v1"
    },
    {
        "id": "2503.09038v1",
        "title": "Image Encryption Using DNA Encoding, Snake Permutation and Chaotic Substitution Techniques",
        "authors": [
            "Waleed Ahmed Farooqui",
            "Jawad Ahmad",
            "Nadeem Kureshi",
            "Fawad Ahmed",
            "Aizaz Ahmad Khattak",
            "Muhammad Shahbaz Khan"
        ],
        "published": "2025-03-12T03:54:37Z",
        "summary": "Securing image data in IoT networks and other insecure information channels is a matter of critical concern. This paper presents a new image encryption scheme using DNA encoding, snake permutation and chaotic substitution techniques that ensures robust security of the image data with reduced computational overhead. The DNA encoding and snake permutation modules ensure effective scrambling of the pixels and result in efficient diffusion in the plaintext image. For the confusion part, the chaotic substitution technique is implemented, which substitutes the pixel values chosen randomly from 3 S-boxes. Extensive security analysis validate the efficacy of the image encryption algorithm proposed in this paper and results demonstrate that the encrypted images have an ideal information entropy of 7.9895 and an almost zero correlation coefficient of -0.001660. These results indicate a high degree of randomness and no correlation in the encrypted image.",
        "field": "Internet of Things (IoT)",
        "link": "http://arxiv.org/abs/2503.09038v1"
    },
    {
        "id": "2503.08607v1",
        "title": "A Fair and Lightweight Consensus Algorithm for IoT",
        "authors": [
            "Sokratis Vavilis",
            "Harris Niavis",
            "Konstantinos Loupos"
        ],
        "published": "2025-03-11T16:45:51Z",
        "summary": "As hyperconnected devices and decentralized data architectures expand, securing IoT transactions becomes increasingly challenging. Blockchain offers a promising solution, but its effectiveness relies on the underlying consensus algorithm. Traditional mechanisms like PoW and PoS are often impractical for resource-constrained IoT environments. To address these limitations, this work introduces a fair and lightweight hybrid consensus algorithm tailored for IoT. The proposed approach minimizes resource demands on the nodes while ensuring a secure and fair agreement process. Specifically, it leverages a distributed lottery mechanism to fairly propose blocks without requiring specialized hardware. In addition, a reputation-based block voting mechanism is incorporated to enhance trust and establish finality. Finally, experimental evaluation was conducted to validate the key features of the consensus algorithm.",
        "field": "Internet of Things (IoT)",
        "link": "http://arxiv.org/abs/2503.08607v1"
    },
    {
        "id": "2503.08293v1",
        "title": "A systematic literature review of unsupervised learning algorithms for anomalous traffic detection based on flows",
        "authors": [
            "Alberto Miguel-Diez",
            "AdriÃ¡n Campazas-Vega",
            "Claudia Ãlvarez-Aparicio",
            "Gonzalo Esteban-Costales",
            "Ãngel Manuel Guerrero-Higueras"
        ],
        "published": "2025-03-11T11:06:00Z",
        "summary": "The constant increase of devices connected to the Internet, and therefore of cyber-attacks, makes it necessary to analyze network traffic in order to recognize malicious activity. Traditional packet-based analysis methods are insufficient because in large networks the amount of traffic is so high that it is unfeasible to review all communications. For this reason, flows is a suitable approach for this situation, which in future 5G networks will have to be used, as the number of packets will increase dramatically. If this is also combined with unsupervised learning models, it can detect new threats for which it has not been trained. This paper presents a systematic review of the literature on unsupervised learning algorithms for detecting anomalies in network flows, following the PRISMA guideline. A total of 63 scientific articles have been reviewed, analyzing 13 of them in depth. The results obtained show that autoencoder is the most used option, followed by SVM, ALAD, or SOM. On the other hand, all the datasets used for anomaly detection have been collected, including some specialised in IoT or with real data collected from honeypots.",
        "field": "Internet of Things (IoT)",
        "link": "http://arxiv.org/abs/2503.08293v1"
    },
    {
        "id": "2502.20359v1",
        "title": "Evaluating the long-term viability of eye-tracking for continuous authentication in virtual reality",
        "authors": [
            "Sai Ganesh Grandhi",
            "Saeed Samet"
        ],
        "published": "2025-02-27T18:32:13Z",
        "summary": "Traditional authentication methods, such as passwords and biometrics, verify a user's identity only at the start of a session, leaving systems vulnerable to session hijacking. Continuous authentication, however, ensures ongoing verification by monitoring user behavior. This study investigates the long-term feasibility of eye-tracking as a behavioral biometric for continuous authentication in virtual reality (VR) environments, using data from the GazebaseVR dataset. Our approach evaluates three architectures, Transformer Encoder, DenseNet, and XGBoost, on short and long-term data to determine their efficacy in user identification tasks. Initial results indicate that both Transformer Encoder and DenseNet models achieve high accuracy rates of up to 97% in short-term settings, effectively capturing unique gaze patterns. However, when tested on data collected 26 months later, model accuracy declined significantly, with rates as low as 1.78% for some tasks. To address this, we propose periodic model updates incorporating recent data, restoring accuracy to over 95%. These findings highlight the adaptability required for gaze-based continuous authentication systems and underscore the need for model retraining to manage evolving user behavior. Our study provides insights into the efficacy and limitations of eye-tracking as a biometric for VR authentication, paving the way for adaptive, secure VR user experiences.",
        "field": "Augmented Reality (AR) and Virtual Reality (VR)",
        "link": "http://arxiv.org/abs/2502.20359v1"
    },
    {
        "id": "2501.19223v1",
        "title": "Through the Looking Glass: LLM-Based Analysis of AR/VR Android Applications Privacy Policies",
        "authors": [
            "Abdulaziz Alghamdi",
            "David Mohaisen"
        ],
        "published": "2025-01-31T15:30:14Z",
        "summary": "\\begin{abstract} This paper comprehensively analyzes privacy policies in AR/VR applications, leveraging BERT, a state-of-the-art text classification model, to evaluate the clarity and thoroughness of these policies. By comparing the privacy policies of AR/VR applications with those of free and premium websites, this study provides a broad perspective on the current state of privacy practices within the AR/VR industry. Our findings indicate that AR/VR applications generally offer a higher percentage of positive segments than free content but lower than premium websites. The analysis of highlighted segments and words revealed that AR/VR applications strategically emphasize critical privacy practices and key terms. This enhances privacy policies' clarity and effectiveness.",
        "field": "Augmented Reality (AR) and Virtual Reality (VR)",
        "link": "http://arxiv.org/abs/2501.19223v1"
    },
    {
        "id": "2501.15313v1",
        "title": "I Know What You Did Last Summer: Identifying VR User Activity Through VR Network Traffic",
        "authors": [
            "Sheikh Samit Muhaimin",
            "Spyridon Mastorakis"
        ],
        "published": "2025-01-25T19:58:29Z",
        "summary": "Virtual Reality (VR) technology has gained substantial traction and has the potential to transform a number of industries, including education, entertainment, and professional sectors. Nevertheless, concerns have arisen about the security and privacy implications of VR applications and the impact that they might have on users. In this paper, we investigate the following overarching research question: can VR applications and VR user activities in the context of such applications (e.g., manipulating virtual objects, walking, talking, flying) be identified based on the (potentially encrypted) network traffic that is generated by VR headsets during the operation of VR applications? To answer this question, we collect network traffic data from 25 VR applications running on the Meta Quest Pro headset and identify characteristics of the generated network traffic, which we subsequently use to train off-the-shelf Machine Learning (ML) models. Our results indicate that through the use of ML models, we can identify the VR applications being used with an accuracy of 92.4F% and the VR user activities performed with an accuracy of 91%. Furthermore, our results demonstrate that an attacker does not need to collect large amounts of network traffic data for each VR application to carry out such an attack. Specifically, an attacker only needs to collect less than 10 minutes of network traffic data for each VR application in order to identify applications with an accuracy higher than 90% and VR user activities with an accuracy higher than 88%.",
        "field": "Augmented Reality (AR) and Virtual Reality (VR)",
        "link": "http://arxiv.org/abs/2501.15313v1"
    },
    {
        "id": "2412.14815v1",
        "title": "Non-intrusive and Unconstrained Keystroke Inference in VR Platforms via Infrared Side Channel",
        "authors": [
            "Tao Ni",
            "Yuefeng Du",
            "Qingchuan Zhao",
            "Cong Wang"
        ],
        "published": "2024-12-19T13:09:46Z",
        "summary": "Virtual Reality (VR) technologies are increasingly employed in numerous applications across various areas. Therefore, it is essential to ensure the security of interactions between users and VR devices. In this paper, we disclose a new side-channel leakage in the constellation tracking system of mainstream VR platforms, where the infrared (IR) signals emitted from the VR controllers for controller-headset interactions can be maliciously exploited to reconstruct unconstrained input keystrokes on the virtual keyboard non-intrusively. We propose a novel keystroke inference attack named VRecKey to demonstrate the feasibility and practicality of this novel infrared side channel. Specifically, VRecKey leverages a customized 2D IR sensor array to intercept ambient IR signals emitted from VR controllers and subsequently infers (i) character-level key presses on the virtual keyboard and (ii) word-level keystrokes along with their typing trajectories. We extensively evaluate the effectiveness of VRecKey with two commercial VR devices, and the results indicate that it can achieve over 94.2% and 90.5% top-3 accuracy in inferring character-level and word-level keystrokes with varying lengths, respectively. In addition, empirical results show that VRecKey is resilient to several practical impact factors and presents effectiveness in various real-world scenarios, which provides a complementary and orthogonal attack surface for the exploration of keystroke inference attacks in VR platforms.",
        "field": "Augmented Reality (AR) and Virtual Reality (VR)",
        "link": "http://arxiv.org/abs/2412.14815v1"
    },
    {
        "id": "2412.06759v2",
        "title": "XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR) Applications",
        "authors": [
            "Shuqing Li",
            "Chenran Zhang",
            "Cuiyun Gao",
            "Michael R. Lyu"
        ],
        "published": "2024-12-09T18:49:27Z",
        "summary": "The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR) and spatial computing technologies forms a foundational layer for the emerging Metaverse, enabling innovative applications across healthcare, education, manufacturing, and entertainment. However, research in this area is often limited by the lack of large, representative, and highquality application datasets that can support empirical studies and the development of new approaches benefiting XR software processes. In this paper, we introduce XRZoo, a comprehensive and curated dataset of XR applications designed to bridge this gap. XRZoo contains 12,528 free XR applications, spanning nine app stores, across all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed metadata on key aspects such as application descriptions, application categories, release dates, user review numbers, and hardware specifications, etc. By making XRZoo publicly available, we aim to foster reproducible XR software engineering and security research, enable cross-disciplinary investigations, and also support the development of advanced XR systems by providing examples to developers. Our dataset serves as a valuable resource for researchers and practitioners interested in improving the scalability, usability, and effectiveness of XR applications. XRZoo will be released and actively maintained.",
        "field": "Augmented Reality (AR) and Virtual Reality (VR)",
        "link": "http://arxiv.org/abs/2412.06759v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Natural Language Processing (NLP) in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Natural Language Processing (NLP) in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Natural Language Processing (NLP) in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Natural Language Processing (NLP) in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Natural Language Processing (NLP) in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "Digital Twin Technology",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "Digital Twin Technology",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "Digital Twin Technology",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "Digital Twin Technology",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09327v1",
        "title": "Heuristic-Based Address Clustering in Cardano Blockchain",
        "authors": [
            "Mostafa Chegenizadeh",
            "Sina Rafati Niya",
            "Claudio J. Tessone"
        ],
        "published": "2025-03-12T12:22:26Z",
        "summary": "Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.",
        "field": "Digital Twin Technology",
        "link": "http://arxiv.org/abs/2503.09327v1"
    },
    {
        "id": "2503.11508v1",
        "title": "Leveraging Angle of Arrival Estimation against Impersonation Attacks in Physical Layer Authentication",
        "authors": [
            "Thuy M. Pham",
            "Linda Senigagliesi",
            "Marco Baldi",
            "Rafael F. Schaefer",
            "Gerhard P. Fettweis",
            "Arsenia Chorti"
        ],
        "published": "2025-03-14T15:29:55Z",
        "summary": "In this paper, we investigate the utilization of the angle of arrival (AoA) as a feature for robust physical layer authentication (PLA). While most of the existing approaches to PLA focus on common features of the physical layer of communication channels, such as channel frequency response, channel impulse response or received signal strength, the use of AoA in this domain has not yet been studied in depth, particularly regarding the ability to thwart impersonation attacks. In this work, we demonstrate that an impersonation attack targeting AoA based PLA is only feasible under strict conditions on the attacker's location and hardware capabilities, which highlights the AoA's potential as a strong feature for PLA. We extend previous works considering a single-antenna attacker to the case of a multiple-antenna attacker, and we develop a theoretical characterization of the conditions in which a successful impersonation attack can be mounted. Furthermore, we leverage extensive simulations in support of theoretical analyses, to validate the robustness of AoA-based PLA.",
        "field": "Biometric Authentication",
        "link": "http://arxiv.org/abs/2503.11508v1"
    },
    {
        "id": "2503.08632v1",
        "title": "Secret-Key Generation from Private Identifiers under Channel Uncertainty",
        "authors": [
            "Vamoua Yachongka",
            "RÃ©mi A. Chou"
        ],
        "published": "2025-03-11T17:20:48Z",
        "summary": "This study investigates secret-key generation for device authentication using physical identifiers, such as responses from physical unclonable functions (PUFs). The system includes two legitimate terminals (encoder and decoder) and an eavesdropper (Eve), each with access to different measurements of the identifier. From the device identifier, the encoder generates a secret key, which is securely stored in a private database, along with helper data that is saved in a public database accessible by the decoder for key reconstruction. Eve, who also has access to the public database, may use both her own measurements and the helper data to attempt to estimate the secret key and identifier. Our setup focuses on authentication scenarios where channel statistics are uncertain, with the involved parties employing multiple antennas to enhance signal reception. Our contributions include deriving inner and outer bounds on the optimal trade-off among secret-key, storage, and privacy-leakage rates for general discrete sources, and showing that these bounds are tight for Gaussian sources.",
        "field": "Biometric Authentication",
        "link": "http://arxiv.org/abs/2503.08632v1"
    },
    {
        "id": "2503.08256v1",
        "title": "SoK: A cloudy view on trust relationships of CVMs -- How Confidential Virtual Machines are falling short in Public Cloud",
        "authors": [
            "Jana Eisoldt",
            "Anna Galanou",
            "Andrey Ruzhanskiy",
            "Nils KÃ¼chenmeister",
            "Yewgenij Baburkin",
            "Tianxiang Dai",
            "Ivan Gudymenko",
            "Stefan KÃ¶psell",
            "RÃ¼diger Kapitza"
        ],
        "published": "2025-03-11T10:21:29Z",
        "summary": "Confidential computing in the public cloud intends to safeguard workload privacy while outsourcing infrastructure management to a cloud provider. This is achieved by executing customer workloads within so called Trusted Execution Environments (TEEs), such as Confidential Virtual Machines (CVMs), which protect them from unauthorized access by cloud administrators and privileged system software. At the core of confidential computing lies remote attestation -- a mechanism that enables workload owners to verify the initial state of their workload and furthermore authenticate the underlying hardware. hile this represents a significant advancement in cloud security, this SoK critically examines the confidential computing offerings of market-leading cloud providers to assess whether they genuinely adhere to its core principles. We develop a taxonomy based on carefully selected criteria to systematically evaluate these offerings, enabling us to analyse the components responsible for remote attestation, the evidence provided at each stage, the extent of cloud provider influence and whether this undermines the threat model of confidential computing. Specifically, we investigate how CVMs are deployed in the public cloud infrastructures, the extent to which customers can request and verify attestation evidence, and their ability to define and enforce configuration and attestation requirements. This analysis provides insight into whether confidential computing guarantees -- namely confidentiality and integrity -- are genuinely upheld. Our findings reveal that all major cloud providers retain control over critical parts of the trusted software stack and, in some cases, intervene in the standard remote attestation process. This directly contradicts their claims of delivering confidential computing, as the model fundamentally excludes the cloud provider from the set of trusted entities.",
        "field": "Biometric Authentication",
        "link": "http://arxiv.org/abs/2503.08256v1"
    },
    {
        "id": "2503.07857v1",
        "title": "Efficient Resource Management for Secure and Low-Latency O-RAN Communication",
        "authors": [
            "Zaineh Abughazzah",
            "Emna Baccour",
            "Ahmed Refaey",
            "Amr Mohamed",
            "Mounir Hamdi"
        ],
        "published": "2025-03-10T21:03:48Z",
        "summary": "Open Radio Access Networks (O-RAN) are transforming telecommunications by shifting from centralized to distributed architectures, promoting flexibility, interoperability, and innovation through open interfaces and multi-vendor environments. However, O-RAN's reliance on cloud-based architecture and enhanced observability introduces significant security and resource management challenges. Efficient resource management is crucial for secure and reliable communication in O-RAN, within the resource-constrained environment and heterogeneity of requirements, where multiple User Equipment (UE) and O-RAN Radio Units (O-RUs) coexist. This paper develops a framework to manage these aspects, ensuring each O-RU is associated with UEs based on their communication channel qualities and computational resources, and selecting appropriate encryption algorithms to safeguard data confidentiality, integrity, and authentication. A Multi-objective Optimization Problem (MOP) is formulated to minimize latency and maximize security within resource constraints. Different approaches are proposed to relax the complexity of the problem and achieve near-optimal performance, facilitating trade-offs between latency, security, and solution complexity. Simulation results demonstrate that the proposed approaches are close enough to the optimal solution, proving that our approach is both effective and efficient.",
        "field": "Biometric Authentication",
        "link": "http://arxiv.org/abs/2503.07857v1"
    },
    {
        "id": "2503.05839v1",
        "title": "Enhancing AUTOSAR-Based Firmware Over-the-Air Updates in the Automotive Industry with a Practical Implementation on a Steering System",
        "authors": [
            "Mostafa Ahmed Mostafa Ahmed",
            "Mohamed Khaled Mohamed Elsayed",
            "Radwa Waheed Ezzat Abdelmohsen"
        ],
        "published": "2025-03-06T23:54:40Z",
        "summary": "The automotive industry is increasingly reliant on software to manage complex vehicle functionalities, making efficient and secure firmware updates essential. Traditional firmware update methods, requiring physical connections through On-Board Diagnostics (OBD) ports, are inconvenient, costly, and time-consuming. Firmware Over-the-Air (FOTA) technology offers a revolutionary solution by enabling wireless updates, reducing operational costs, and enhancing the user experience. This project aims to design and implement an advanced FOTA system tailored for modern vehicles, incorporating the AUTOSAR architecture for scalability and standardization, and utilizing delta updating to minimize firmware update sizes, thereby improving bandwidth efficiency and reducing flashing times. To ensure security, the system integrates the UDS 0x27 protocol for authentication and data integrity during the update process. Communication between Electronic Control Units (ECUs) is achieved using the CAN protocol, while the ESP8266 module and the master ECU communicate via SPI for data transfer. The system's architecture includes key components such as a bootloader, boot manager, and bootloader updater to facilitate seamless firmware updates. The functionality of the system is demonstrated through two applications: a blinking LED and a Lane Keeping Assist (LKA) system, showcasing its versatility in handling critical automotive features. This project represents a significant step forward in automotive technology, offering a user-centric, efficient, and secure solution for automotive firmware management.",
        "field": "Biometric Authentication",
        "link": "http://arxiv.org/abs/2503.05839v1"
    },
    {
        "id": "2503.10945v1",
        "title": "$(\\varepsilon, Î´)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees",
        "authors": [
            "Juan Felipe Gomez",
            "Bogdan Kulynych",
            "Georgios Kaissis",
            "Jamie Hayes",
            "Borja Balle",
            "Antti Honkela"
        ],
        "published": "2025-03-13T23:06:30Z",
        "summary": "Current practices for reporting the level of differential privacy (DP) guarantees for machine learning (ML) algorithms provide an incomplete and potentially misleading picture of the guarantees and make it difficult to compare privacy levels across different settings. We argue for using Gaussian differential privacy (GDP) as the primary means of communicating DP guarantees in ML, with the full privacy profile as a secondary option in case GDP is too inaccurate. Unlike other widely used alternatives, GDP has only one parameter, which ensures easy comparability of guarantees, and it can accurately capture the full privacy profile of many important ML applications. To support our claims, we investigate the privacy profiles of state-of-the-art DP large-scale image classification, and the TopDown algorithm for the U.S. Decennial Census, observing that GDP fits the profiles remarkably well in all three cases. Although GDP is ideal for reporting the final guarantees, other formalisms (e.g., privacy loss random variables) are needed for accurate privacy accounting. We show that such intermediate representations can be efficiently converted to GDP with minimal loss in tightness.",
        "field": "Federated Learning",
        "link": "http://arxiv.org/abs/2503.10945v1"
    },
    {
        "id": "2503.10944v1",
        "title": "Phishsense-1B: A Technical Perspective on an AI-Powered Phishing Detection Model",
        "authors": [
            "SE Blake"
        ],
        "published": "2025-03-13T23:03:09Z",
        "summary": "Phishing is a persistent cybersecurity threat in today's digital landscape. This paper introduces Phishsense-1B, a refined version of the Llama-Guard-3-1B model, specifically tailored for phishing detection and reasoning. This adaptation utilizes Low-Rank Adaptation (LoRA) and the GuardReasoner finetuning methodology. We outline our LoRA-based fine-tuning process, describe the balanced dataset comprising phishing and benign emails, and highlight significant performance improvements over the original model. Our findings indicate that Phishsense-1B achieves an impressive 97.5% accuracy on a custom dataset and maintains strong performance with 70% accuracy on a challenging real-world dataset. This performance notably surpasses both unadapted models and BERT-based detectors. Additionally, we examine current state-of-the-art detection methods, compare prompt-engineering with fine-tuning strategies, and explore potential deployment scenarios.",
        "field": "Federated Learning",
        "link": "http://arxiv.org/abs/2503.10944v1"
    },
    {
        "id": "2503.10809v1",
        "title": "Attacking Multimodal OS Agents with Malicious Image Patches",
        "authors": [
            "Lukas Aichberger",
            "Alasdair Paren",
            "Yarin Gal",
            "Philip Torr",
            "Adel Bibi"
        ],
        "published": "2025-03-13T18:59:12Z",
        "summary": "Recent advances in operating system (OS) agents enable vision-language models to interact directly with the graphical user interface of an OS. These multimodal OS agents autonomously perform computer-based tasks in response to a single prompt via application programming interfaces (APIs). Such APIs typically support low-level operations, including mouse clicks, keyboard inputs, and screenshot captures. We introduce a novel attack vector: malicious image patches (MIPs) that have been adversarially perturbed so that, when captured in a screenshot, they cause an OS agent to perform harmful actions by exploiting specific APIs. For instance, MIPs embedded in desktop backgrounds or shared on social media can redirect an agent to a malicious website, enabling further exploitation. These MIPs generalise across different user requests and screen layouts, and remain effective for multiple OS agents. The existence of such attacks highlights critical security vulnerabilities in OS agents, which should be carefully addressed before their widespread adoption.",
        "field": "Federated Learning",
        "link": "http://arxiv.org/abs/2503.10809v1"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "Federated Learning",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10218v1",
        "title": "Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning with Heterogeneous Models",
        "authors": [
            "Yifeng Cai",
            "Ziqi Zhang",
            "Ding Li",
            "Yao Guo",
            "Xiangqun Chen"
        ],
        "published": "2025-03-13T10:00:58Z",
        "summary": "Modern Federated Learning (FL) has become increasingly essential for handling highly heterogeneous mobile devices. Current approaches adopt a partial model aggregation paradigm that leads to sub-optimal model accuracy and higher training overhead. In this paper, we challenge the prevailing notion of partial-model aggregation and propose a novel \"full-weight aggregation\" method named Moss, which aggregates all weights within heterogeneous models to preserve comprehensive knowledge. Evaluation across various applications demonstrates that Moss significantly accelerates training, reduces on-device training time and energy consumption, enhances accuracy, and minimizes network bandwidth utilization when compared to state-of-the-art baselines.",
        "field": "Federated Learning",
        "link": "http://arxiv.org/abs/2503.10218v1"
    },
    {
        "id": "2502.13513v1",
        "title": "Phantom Events: Demystifying the Issues of Log Forgery in Blockchain",
        "authors": [
            "Yixuan Liu",
            "Yuxin Dong",
            "Ye Liu",
            "Xiapu Luo",
            "Yi Li"
        ],
        "published": "2025-02-19T08:07:26Z",
        "summary": "With the rapid development of blockchain technology, transaction logs play a central role in various applications, including decentralized exchanges, wallets, cross-chain bridges, and other third-party services. However, these logs, particularly those based on smart contract events, are highly susceptible to manipulation and forgery, creating substantial security risks across the ecosystem. To address this issue, we present the first in-depth security analysis of transaction log forgery in EVM-based blockchains, a phenomenon we term Phantom Events. We systematically model five types of attacks and propose a tool designed to detect event forgery vulnerabilities in smart contracts. Our evaluation demonstrates that our approach outperforms existing tools in identifying potential phantom events. Furthermore, we have successfully identified real-world instances for all five types of attacks across multiple decentralized applications. Finally, we call on community developers to take proactive steps to address these critical security vulnerabilities.",
        "field": "Digital Wallets",
        "link": "http://arxiv.org/abs/2502.13513v1"
    },
    {
        "id": "2502.03247v1",
        "title": "Thetacrypt: A Distributed Service for Threshold Cryptography",
        "authors": [
            "Mariarosaria Barbaraci",
            "Noah Schmid",
            "Orestis Alpos",
            "Michael Senn",
            "Christian Cachin"
        ],
        "published": "2025-02-05T15:03:59Z",
        "summary": "Threshold cryptography is a powerful and well-known technique with many applications to systems relying on distributed trust. It has recently emerged also as a solution to challenges in blockchain: frontrunning prevention, managing wallet keys, and generating randomness. This work presents Thetacrypt, a versatile library for integrating many threshold schemes into one codebase. It offers a way to easily build distributed systems using threshold cryptography and is agnostic to their implementation language. The architecture of Thetacrypt supports diverse protocols uniformly. The library currently includes six cryptographic schemes that span ciphers, signatures, and randomness generation. The library additionally contains a flexible adapter to an underlying networking layer that provides peer-to-peer communication and a total-order broadcast channel; the latter can be implemented by distributed ledgers, for instance. Thetacrypt serves as a controlled testbed for evaluating the performance of multiple threshold-cryptographic schemes under consistent conditions, showing how the traditional micro benchmarking approach neglects the distributed nature of the protocols and its relevance when considering system performance.",
        "field": "Digital Wallets",
        "link": "http://arxiv.org/abs/2502.03247v1"
    },
    {
        "id": "2501.17089v1",
        "title": "CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else",
        "authors": [
            "Felix Hoops",
            "Jonas Gebele",
            "Florian Matthes"
        ],
        "published": "2025-01-28T17:23:45Z",
        "summary": "Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics. For instance, exact staff fluctuation through issuance and revocation of employee IDs. We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade. Padding is used to provide deniability for issuer metrics. Issuers periodically publish this filter cascade on a decentralized storage system. Relying Parties (RPs) can download it to perform any number of revocation checks locally. Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally. At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications. We present a prototype using the Ethereum blockchain as decentralized storage. The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain. We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols. Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades.",
        "field": "Digital Wallets",
        "link": "http://arxiv.org/abs/2501.17089v1"
    },
    {
        "id": "2501.16681v1",
        "title": "Blockchain Address Poisoning",
        "authors": [
            "Taro Tsuchiya",
            "Jin-Dong Dong",
            "Kyle Soska",
            "Nicolas Christin"
        ],
        "published": "2025-01-28T03:34:59Z",
        "summary": "In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on Ethereum and BSC. We identify 13 times the number of attack attempts reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address-generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.",
        "field": "Digital Wallets",
        "link": "http://arxiv.org/abs/2501.16681v1"
    },
    {
        "id": "2501.11798v1",
        "title": "Blockchain Security Risk Assessment in Quantum Era, Migration Strategies and Proactive Defense",
        "authors": [
            "Yaser Baseri",
            "Abdelhakim Hafid",
            "Yahya Shahsavari",
            "Dimitrios Makrakis",
            "Hassan Khodaiemehr"
        ],
        "published": "2025-01-21T00:27:41Z",
        "summary": "The emergence of quantum computing presents a formidable challenge to the security of blockchain systems. Traditional cryptographic algorithms, foundational to digital signatures, message encryption, and hashing functions, become vulnerable to the immense computational power of quantum computers. This paper conducts a thorough risk assessment of transitioning to quantum-resistant blockchains, comprehensively analyzing potential threats targeting vital blockchain components: the network, mining pools, transaction verification mechanisms, smart contracts, and user wallets. By elucidating the intricate challenges and strategic considerations inherent in transitioning to quantum-resistant algorithms, the paper evaluates risks and highlights obstacles in securing blockchain components with quantum-resistant cryptography. It offers a hybrid migration strategy to facilitate a smooth transition from classical to quantum-resistant cryptography. The analysis extends to prominent blockchains such as Bitcoin, Ethereum, Ripple, Litecoin, and Zcash, assessing vulnerable components, potential impacts, and associated STRIDE threats, thereby identifying areas susceptible to quantum attacks. Beyond analysis, the paper provides actionable guidance for designing secure and resilient blockchain ecosystems in the quantum computing era. Recognizing the looming threat of quantum computers, this research advocates for a proactive transition to quantum-resistant blockchain networks. It proposes a tailored security blueprint that strategically fortifies each component against the evolving landscape of quantum-induced cyber threats. Emphasizing the critical need for blockchain stakeholders to adopt proactive measures and implement quantum-resistant solutions, the paper underscores the importance of embracing these insights to navigate the complexities of the quantum era with resilience and confidence.",
        "field": "Digital Wallets",
        "link": "http://arxiv.org/abs/2501.11798v1"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.11634v1",
        "title": "Translating Between the Common Haar Random State Model and the Unitary Model",
        "authors": [
            "Eli Goldin",
            "Mark Zhandry"
        ],
        "published": "2025-03-14T17:52:48Z",
        "summary": "Black-box separations are a cornerstone of cryptography, indicating barriers to various goals. A recent line of work has explored black-box separations for quantum cryptographic primitives. Namely, a number of separations are known in the Common Haar Random State (CHRS) model, though this model is not considered a complete separation, but rather a starting point. A few very recent works have attempted to lift these separations to a unitary separation, which are considered complete separations. Unfortunately, we find significant errors in some of these lifting results. We prove general conditions under which CHRS separations can be generically lifted, thereby giving simple, modular, and bug-free proofs of complete unitary separations between various quantum primitives. Our techniques allow for simpler proofs of existing separations as well as new separations that were previously only known in the CHRS model.",
        "field": "Synthetic Data Generation",
        "link": "http://arxiv.org/abs/2503.11634v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Explainable AI (XAI) in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Explainable AI (XAI) in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Explainable AI (XAI) in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Explainable AI (XAI) in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Explainable AI (XAI) in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "Privacy-Enhancing Computation",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Privacy-Enhancing Computation",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Privacy-Enhancing Computation",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "Privacy-Enhancing Computation",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "Privacy-Enhancing Computation",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Generative AI in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Generative AI in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Generative AI in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Generative AI in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Generative AI in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Autonomous Banking Systems",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.10809v1",
        "title": "Attacking Multimodal OS Agents with Malicious Image Patches",
        "authors": [
            "Lukas Aichberger",
            "Alasdair Paren",
            "Yarin Gal",
            "Philip Torr",
            "Adel Bibi"
        ],
        "published": "2025-03-13T18:59:12Z",
        "summary": "Recent advances in operating system (OS) agents enable vision-language models to interact directly with the graphical user interface of an OS. These multimodal OS agents autonomously perform computer-based tasks in response to a single prompt via application programming interfaces (APIs). Such APIs typically support low-level operations, including mouse clicks, keyboard inputs, and screenshot captures. We introduce a novel attack vector: malicious image patches (MIPs) that have been adversarially perturbed so that, when captured in a screenshot, they cause an OS agent to perform harmful actions by exploiting specific APIs. For instance, MIPs embedded in desktop backgrounds or shared on social media can redirect an agent to a malicious website, enabling further exploitation. These MIPs generalise across different user requests and screen layouts, and remain effective for multiple OS agents. The existence of such attacks highlights critical security vulnerabilities in OS agents, which should be carefully addressed before their widespread adoption.",
        "field": "Autonomous Banking Systems",
        "link": "http://arxiv.org/abs/2503.10809v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "Autonomous Banking Systems",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.10411v1",
        "title": "Public Channel-Based Fair Exchange Protocols with Advertising",
        "authors": [
            "Pierpaolo Della Monica",
            "Ivan Visconti",
            "Andrea Vitaletti",
            "Marco Zecchini"
        ],
        "published": "2025-03-13T14:35:32Z",
        "summary": "Before a fair exchange takes place, there is typically an advertisement phase with the goal of increasing the appeal of possessing a digital asset while keeping it sufficiently hidden. In this work, we give a definition that explicitly combines a fair-exchange protocol with a prior advertising phase. Then, we construct such a fair exchange protocol with aids using zk-SNARKs and relying on mainstream decentralized platforms (i.e., a blockchain with smart contracts like Ethereum and a decentralized storage system like IPFS). Experimental results confirm the practical relevance of our decentralized approach, paving the road towards building decentralized marketplaces where users can, even anonymously, and without direct off-chain communications, effectively advertise and exchange their digital assets as part of a system of enhanced NFTs.",
        "field": "Autonomous Banking Systems",
        "link": "http://arxiv.org/abs/2503.10411v1"
    },
    {
        "id": "2503.10320v1",
        "title": "Combinatorial Designs and Cellular Automata: A Survey",
        "authors": [
            "Luca Manzoni",
            "Luca Mariot",
            "Giuliamaria Menara"
        ],
        "published": "2025-03-13T12:54:49Z",
        "summary": "Cellular Automata (CA) are commonly investigated as a particular type of dynamical systems, defined by shift-invariant local rules. In this paper, we consider instead CA as algebraic systems, focusing on the combinatorial designs induced by their short-term behavior. Specifically, we review the main results published in the literature concerning the construction of mutually orthogonal Latin squares via bipermutive CA, considering both the linear and nonlinear cases. We then survey some significant applications of these results to cryptography, and conclude with a discussion of open problems to be addressed in future research on CA-based combinatorial designs.",
        "field": "Autonomous Banking Systems",
        "link": "http://arxiv.org/abs/2503.10320v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Human-Centric AI in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Human-Centric AI in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Human-Centric AI in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Human-Centric AI in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Human-Centric AI in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Digital Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Digital Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Digital Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Digital Biometrics in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Digital Biometrics in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "Quantum Networking",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10238v1",
        "title": "Post Quantum Migration of Tor",
        "authors": [
            "Denis Berger",
            "Mouad Lemoudden",
            "William J Buchanan"
        ],
        "published": "2025-03-13T10:28:03Z",
        "summary": "Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as \\emph{harvest now, decrypt later} attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.",
        "field": "Quantum Networking",
        "link": "http://arxiv.org/abs/2503.10238v1"
    },
    {
        "id": "2503.10218v1",
        "title": "Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning with Heterogeneous Models",
        "authors": [
            "Yifeng Cai",
            "Ziqi Zhang",
            "Ding Li",
            "Yao Guo",
            "Xiangqun Chen"
        ],
        "published": "2025-03-13T10:00:58Z",
        "summary": "Modern Federated Learning (FL) has become increasingly essential for handling highly heterogeneous mobile devices. Current approaches adopt a partial model aggregation paradigm that leads to sub-optimal model accuracy and higher training overhead. In this paper, we challenge the prevailing notion of partial-model aggregation and propose a novel \"full-weight aggregation\" method named Moss, which aggregates all weights within heterogeneous models to preserve comprehensive knowledge. Evaluation across various applications demonstrates that Moss significantly accelerates training, reduces on-device training time and energy consumption, enhances accuracy, and minimizes network bandwidth utilization when compared to state-of-the-art baselines.",
        "field": "Quantum Networking",
        "link": "http://arxiv.org/abs/2503.10218v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "Quantum Networking",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09726v1",
        "title": "How Feasible is Augmenting Fake Nodes with Learnable Features as a Counter-strategy against Link Stealing Attacks?",
        "authors": [
            "Mir Imtiaz Mostafiz",
            "Imtiaz Karim",
            "Elisa Bertino"
        ],
        "published": "2025-03-12T18:16:37Z",
        "summary": "Graph Neural Networks (GNNs) are widely used and deployed for graph-based prediction tasks. However, as good as GNNs are for learning graph data, they also come with the risk of privacy leakage. For instance, an attacker can run carefully crafted queries on the GNNs and, from the responses, can infer the existence of an edge between a pair of nodes. This attack, dubbed as a \"link-stealing\" attack, can jeopardize the user's privacy by leaking potentially sensitive information. To protect against this attack, we propose an approach called \"$(N)$ode $(A)$ugmentation for $(R)$estricting $(G)$raphs from $(I)$nsinuating their $(S)$tructure\" ($NARGIS$) and study its feasibility. $NARGIS$ is focused on reshaping the graph embedding space so that the posterior from the GNN model will still provide utility for the prediction task but will introduce ambiguity for the link-stealing attackers. To this end, $NARGIS$ applies spectral clustering on the given graph to facilitate it being augmented with new nodes -- that have learned features instead of fixed ones. It utilizes tri-level optimization for learning parameters for the GNN model, surrogate attacker model, and our defense model (i.e. learnable node features). We extensively evaluate $NARGIS$ on three benchmark citation datasets over eight knowledge availability settings for the attackers. We also evaluate the model fidelity and defense performance on influence-based link inference attacks. Through our studies, we have figured out the best feature of $NARGIS$ -- its superior fidelity-privacy performance trade-off in a significant number of cases. We also have discovered in which cases the model needs to be improved, and proposed ways to integrate different schemes to make the model more robust against link stealing attacks.",
        "field": "Quantum Networking",
        "link": "http://arxiv.org/abs/2503.09726v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Zero-Knowledge Proofs in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Zero-Knowledge Proofs in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Zero-Knowledge Proofs in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Zero-Knowledge Proofs in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Zero-Knowledge Proofs in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.11634v1",
        "title": "Translating Between the Common Haar Random State Model and the Unitary Model",
        "authors": [
            "Eli Goldin",
            "Mark Zhandry"
        ],
        "published": "2025-03-14T17:52:48Z",
        "summary": "Black-box separations are a cornerstone of cryptography, indicating barriers to various goals. A recent line of work has explored black-box separations for quantum cryptographic primitives. Namely, a number of separations are known in the Common Haar Random State (CHRS) model, though this model is not considered a complete separation, but rather a starting point. A few very recent works have attempted to lift these separations to a unitary separation, which are considered complete separations. Unfortunately, we find significant errors in some of these lifting results. We prove general conditions under which CHRS separations can be generically lifted, thereby giving simple, modular, and bug-free proofs of complete unitary separations between various quantum primitives. Our techniques allow for simpler proofs of existing separations as well as new separations that were previously only known in the CHRS model.",
        "field": "Quantum-Resistant Cryptography",
        "link": "http://arxiv.org/abs/2503.11634v1"
    },
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "Quantum-Resistant Cryptography",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Quantum-Resistant Cryptography",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11508v1",
        "title": "Leveraging Angle of Arrival Estimation against Impersonation Attacks in Physical Layer Authentication",
        "authors": [
            "Thuy M. Pham",
            "Linda Senigagliesi",
            "Marco Baldi",
            "Rafael F. Schaefer",
            "Gerhard P. Fettweis",
            "Arsenia Chorti"
        ],
        "published": "2025-03-14T15:29:55Z",
        "summary": "In this paper, we investigate the utilization of the angle of arrival (AoA) as a feature for robust physical layer authentication (PLA). While most of the existing approaches to PLA focus on common features of the physical layer of communication channels, such as channel frequency response, channel impulse response or received signal strength, the use of AoA in this domain has not yet been studied in depth, particularly regarding the ability to thwart impersonation attacks. In this work, we demonstrate that an impersonation attack targeting AoA based PLA is only feasible under strict conditions on the attacker's location and hardware capabilities, which highlights the AoA's potential as a strong feature for PLA. We extend previous works considering a single-antenna attacker to the case of a multiple-antenna attacker, and we develop a theoretical characterization of the conditions in which a successful impersonation attack can be mounted. Furthermore, we leverage extensive simulations in support of theoretical analyses, to validate the robustness of AoA-based PLA.",
        "field": "Quantum-Resistant Cryptography",
        "link": "http://arxiv.org/abs/2503.11508v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Quantum-Resistant Cryptography",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "AI-Driven Fraud Detection",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.10944v1",
        "title": "Phishsense-1B: A Technical Perspective on an AI-Powered Phishing Detection Model",
        "authors": [
            "SE Blake"
        ],
        "published": "2025-03-13T23:03:09Z",
        "summary": "Phishing is a persistent cybersecurity threat in today's digital landscape. This paper introduces Phishsense-1B, a refined version of the Llama-Guard-3-1B model, specifically tailored for phishing detection and reasoning. This adaptation utilizes Low-Rank Adaptation (LoRA) and the GuardReasoner finetuning methodology. We outline our LoRA-based fine-tuning process, describe the balanced dataset comprising phishing and benign emails, and highlight significant performance improvements over the original model. Our findings indicate that Phishsense-1B achieves an impressive 97.5% accuracy on a custom dataset and maintains strong performance with 70% accuracy on a challenging real-world dataset. This performance notably surpasses both unadapted models and BERT-based detectors. Additionally, we examine current state-of-the-art detection methods, compare prompt-engineering with fine-tuning strategies, and explore potential deployment scenarios.",
        "field": "AI-Driven Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10944v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Driven Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "AI-Driven Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10255v1",
        "title": "An Open-RAN Testbed for Detecting and Mitigating Radio-Access Anomalies",
        "authors": [
            "Hanna Bogucka",
            "Marcin Hoffmann",
            "PaweÅ Kryszkiewicz",
            "Åukasz KuÅacz"
        ],
        "published": "2025-03-13T11:10:29Z",
        "summary": "This paper presents the Open Radio Access Net-work (O-RAN) testbed for secure radio access. We discuss radio-originating attack detection and mitigation methods based on anomaly detection and how they can be implemented as specialized applications (xApps) in this testbed. We also pre-sent illustrating results of the methods applied in real-world scenarios and implementations.",
        "field": "AI-Driven Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10255v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Synthetic Data Generation",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "Synthetic Data Generation",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.11053v1",
        "title": "Pricing American Parisian Options under General Time-Inhomogeneous Markov Models",
        "authors": [
            "Yuhao Liu",
            "Nian Yang",
            "Gongqiu Zhang"
        ],
        "published": "2025-03-14T03:45:18Z",
        "summary": "This paper develops general approaches for pricing various types of American-style Parisian options (down-in/-out, perpetual/finite-maturity) with general payoff functions based on continuous-time Markov chain (CTMC) approximation under general 1D time-inhomogeneous Markov models. For the down-in types, by conditioning on the Parisian stopping time, we reduce the pricing problem to that of a series of vanilla American options with different maturities and their prices integrated with the distribution function of the Parisian stopping time yield the American Parisian down-in option price. This facilitates an efficient application of CTMC approximation to obtain the approximate option price by calculating the required quantities. For the perpetual down-in cases under time-homogeneous models, significant computational cost can be reduced. The down-out cases are more complicated, for which we use the state augmentation approach to record the excursion duration and then the approximate option price is obtained by solving a series of variational inequalities recursively with the Lemke's pivoting method. We show the convergence of CTMC approximation for all the types of American Parisian options under general time-inhomogeneous Markov models, and the accuracy and efficiency of our algorithms are confirmed with extensive numerical experiments.",
        "field": "Synthetic Data Generation",
        "link": "http://arxiv.org/abs/2503.11053v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "Synthetic Data Generation",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Edge Computing in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Edge Computing in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Edge Computing in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Edge Computing in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10238v1",
        "title": "Post Quantum Migration of Tor",
        "authors": [
            "Denis Berger",
            "Mouad Lemoudden",
            "William J Buchanan"
        ],
        "published": "2025-03-13T10:28:03Z",
        "summary": "Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as \\emph{harvest now, decrypt later} attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.10238v1"
    },
    {
        "id": "2503.10218v1",
        "title": "Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning with Heterogeneous Models",
        "authors": [
            "Yifeng Cai",
            "Ziqi Zhang",
            "Ding Li",
            "Yao Guo",
            "Xiangqun Chen"
        ],
        "published": "2025-03-13T10:00:58Z",
        "summary": "Modern Federated Learning (FL) has become increasingly essential for handling highly heterogeneous mobile devices. Current approaches adopt a partial model aggregation paradigm that leads to sub-optimal model accuracy and higher training overhead. In this paper, we challenge the prevailing notion of partial-model aggregation and propose a novel \"full-weight aggregation\" method named Moss, which aggregates all weights within heterogeneous models to preserve comprehensive knowledge. Evaluation across various applications demonstrates that Moss significantly accelerates training, reduces on-device training time and energy consumption, enhances accuracy, and minimizes network bandwidth utilization when compared to state-of-the-art baselines.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.10218v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09726v1",
        "title": "How Feasible is Augmenting Fake Nodes with Learnable Features as a Counter-strategy against Link Stealing Attacks?",
        "authors": [
            "Mir Imtiaz Mostafiz",
            "Imtiaz Karim",
            "Elisa Bertino"
        ],
        "published": "2025-03-12T18:16:37Z",
        "summary": "Graph Neural Networks (GNNs) are widely used and deployed for graph-based prediction tasks. However, as good as GNNs are for learning graph data, they also come with the risk of privacy leakage. For instance, an attacker can run carefully crafted queries on the GNNs and, from the responses, can infer the existence of an edge between a pair of nodes. This attack, dubbed as a \"link-stealing\" attack, can jeopardize the user's privacy by leaking potentially sensitive information. To protect against this attack, we propose an approach called \"$(N)$ode $(A)$ugmentation for $(R)$estricting $(G)$raphs from $(I)$nsinuating their $(S)$tructure\" ($NARGIS$) and study its feasibility. $NARGIS$ is focused on reshaping the graph embedding space so that the posterior from the GNN model will still provide utility for the prediction task but will introduce ambiguity for the link-stealing attackers. To this end, $NARGIS$ applies spectral clustering on the given graph to facilitate it being augmented with new nodes -- that have learned features instead of fixed ones. It utilizes tri-level optimization for learning parameters for the GNN model, surrogate attacker model, and our defense model (i.e. learnable node features). We extensively evaluate $NARGIS$ on three benchmark citation datasets over eight knowledge availability settings for the attackers. We also evaluate the model fidelity and defense performance on influence-based link inference attacks. Through our studies, we have figured out the best feature of $NARGIS$ -- its superior fidelity-privacy performance trade-off in a significant number of cases. We also have discovered in which cases the model needs to be improved, and proposed ways to integrate different schemes to make the model more robust against link stealing attacks.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.09726v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "Digital Twins",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.03539v1",
        "title": "Data Sharing, Privacy and Security Considerations in the Energy Sector: A Review from Technical Landscape to Regulatory Specifications",
        "authors": [
            "Shiliang Zhang",
            "Sabita Maharjan",
            "Lee Andrew Bygrave",
            "Shui Yu"
        ],
        "published": "2025-03-05T14:23:56Z",
        "summary": "Decarbonization, decentralization and digitalization are the three key elements driving the twin energy transition. The energy system is evolving to a more data driven ecosystem, leading to the need of communication and storage of large amount of data of different resolution from the prosumers and other stakeholders in the energy ecosystem. While the energy system is certainly advancing, this paradigm shift is bringing in new privacy and security issues related to collection, processing and storage of data - not only from the technical dimension, but also from the regulatory perspective. Understanding data privacy and security in the evolving energy system, regarding regulatory compliance, is an immature field of research. Contextualized knowledge of how related issues are regulated is still in its infancy, and the practical and technical basis for the regulatory framework for data privacy and security is not clear. To fill this gap, this paper conducts a comprehensive review of the data-related issues for the energy system by integrating both technical and regulatory dimensions. We start by reviewing open-access data, data communication and data-processing techniques for the energy system, and use it as the basis to connect the analysis of data-related issues from the integrated perspective. We classify the issues into three categories: (i) data-sharing among energy end users and stakeholders (ii) privacy of end users, and (iii) cyber security, and then explore these issues from a regulatory perspective. We analyze the evolution of related regulations, and introduce the relevant regulatory initiatives for the categorized issues in terms of regulatory definitions, concepts, principles, rights and obligations in the context of energy systems. Finally, we provide reflections on the gaps that still exist, and guidelines for regulatory frameworks for a truly participatory energy system.",
        "field": "Digital Twins",
        "link": "http://arxiv.org/abs/2503.03539v1"
    },
    {
        "id": "2502.19341v1",
        "title": "Unveiling Wireless Users' Locations via Modulation Classification-based Passive Attack",
        "authors": [
            "Ali Hanif",
            "Abdulrahman Katranji",
            "Nour Kouzayha",
            "Muhammad Mahboob Ur Rahman",
            "Tareq Y. Al-Naffouri"
        ],
        "published": "2025-02-26T17:32:38Z",
        "summary": "The broadcast nature of the wireless medium and openness of wireless standards, e.g., 3GPP releases 16-20, invite adversaries to launch various active and passive attacks on cellular and other wireless networks. This work identifies one such loose end of wireless standards and presents a novel passive attack method enabling an eavesdropper (Eve) to localize a line of sight wireless user (Bob) who is communicating with a base station or WiFi access point (Alice). The proposed attack involves two phases. In the first phase, Eve performs modulation classification by intercepting the downlink channel between Alice and Bob. This enables Eve to utilize the publicly available modulation and coding scheme (MCS) tables to do pesudo-ranging, i.e., the Eve determines the ring within which Bob is located, which drastically reduces the search space. In the second phase, Eve sniffs the uplink channel, and employs multiple strategies to further refine Bob's location within the ring. Towards the end, we present our thoughts on how this attack can be extended to non-line-of-sight scenarios, and how this attack could act as a scaffolding to construct a malicious digital twin map.",
        "field": "Digital Twins",
        "link": "http://arxiv.org/abs/2502.19341v1"
    },
    {
        "id": "2502.03403v1",
        "title": "Lightweight Authenticated Task Offloading in 6G-Cloud Vehicular Twin Networks",
        "authors": [
            "Sarah Al-Shareeda",
            "Fusun Ozguner",
            "Keith Redmill",
            "Trung Q. Duong",
            "Berk Canberk"
        ],
        "published": "2025-02-05T17:43:55Z",
        "summary": "Task offloading management in 6G vehicular networks is crucial for maintaining network efficiency, particularly as vehicles generate substantial data. Integrating secure communication through authentication introduces additional computational and communication overhead, significantly impacting offloading efficiency and latency. This paper presents a unified framework incorporating lightweight Identity-Based Cryptographic (IBC) authentication into task offloading within cloud-based 6G Vehicular Twin Networks (VTNs). Utilizing Proximal Policy Optimization (PPO) in Deep Reinforcement Learning (DRL), our approach optimizes authenticated offloading decisions to minimize latency and enhance resource allocation. Performance evaluation under varying network sizes, task sizes, and data rates reveals that IBC authentication can reduce offloading efficiency by up to 50% due to the added overhead. Besides, increasing network size and task size can further reduce offloading efficiency by up to 91.7%. As a countermeasure, increasing the transmission data rate can improve the offloading performance by as much as 63%, even in the presence of authentication overhead. The code for the simulations and experiments detailed in this paper is available on GitHub for further reference and reproducibility [1].",
        "field": "Digital Twins",
        "link": "http://arxiv.org/abs/2502.03403v1"
    },
    {
        "id": "2501.09802v1",
        "title": "W3ID: A Quantum Computing-Secure Digital Identity System Redefining Standards for Web3 and Digital Twins",
        "authors": [
            "Joseph Yun",
            "Eli Lifton",
            "Eunseo Lee",
            "Yohan Yun",
            "Abigail Song",
            "Joshua Lee",
            "Cristian Jimenez-Bert",
            "Benedict Song",
            "Yejun Lee",
            "Alex Seo",
            "Sijung Yun"
        ],
        "published": "2025-01-16T19:16:08Z",
        "summary": "The rapid advancements in quantum computing present significant threats to existing encryption standards and internet security. Simultaneously, the advent of Web 3.0 marks a transformative era in internet history, emphasizing enhanced data security, decentralization, and user ownership. This white paper introduces the W3ID, an abbreviation of Web3 standard meeting universal digital ID, which is a Universal Digital Identity (UDI) model designed to meet Web3 standards while addressing vulnerabilities posed by quantum computing. W3ID innovatively generates secure Digital Object Identifiers (DOIs) tailored for the decentralized Web 3.0 ecosystem. Additionally, W3ID employs a dual-key system for secure authentication, enhancing both public and private verification mechanisms. To further enhance encryption strength and authentication integrity in the quantum computing era, W3ID incorporates an advanced security mechanism. By requiring quadruple application of SHA-256, with consecutive matches for validation, the system expands the number of possibilities to 256^4, which is approximately 4.3 billion times the current SHA-256 capacity. This dramatic increase in computational complexity ensures that even advanced quantum computing systems would face significant challenges in executing brute-force attacks. W3ID redefines digital identity standards for Web 3.0 and the quantum computing era, setting a new benchmark for security, scalability, and decentralization in the global digital twin ecosystem.",
        "field": "Digital Twins",
        "link": "http://arxiv.org/abs/2501.09802v1"
    },
    {
        "id": "2503.10944v1",
        "title": "Phishsense-1B: A Technical Perspective on an AI-Powered Phishing Detection Model",
        "authors": [
            "SE Blake"
        ],
        "published": "2025-03-13T23:03:09Z",
        "summary": "Phishing is a persistent cybersecurity threat in today's digital landscape. This paper introduces Phishsense-1B, a refined version of the Llama-Guard-3-1B model, specifically tailored for phishing detection and reasoning. This adaptation utilizes Low-Rank Adaptation (LoRA) and the GuardReasoner finetuning methodology. We outline our LoRA-based fine-tuning process, describe the balanced dataset comprising phishing and benign emails, and highlight significant performance improvements over the original model. Our findings indicate that Phishsense-1B achieves an impressive 97.5% accuracy on a custom dataset and maintains strong performance with 70% accuracy on a challenging real-world dataset. This performance notably surpasses both unadapted models and BERT-based detectors. Additionally, we examine current state-of-the-art detection methods, compare prompt-engineering with fine-tuning strategies, and explore potential deployment scenarios.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.10944v1"
    },
    {
        "id": "2503.09964v1",
        "title": "ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist Content",
        "authors": [
            "Bhavik Chandna",
            "Mariam Aboujenane",
            "Usman Naseem"
        ],
        "published": "2025-03-13T02:10:29Z",
        "summary": "Large Multimodal Models (LMMs) are increasingly vulnerable to AI-generated extremist content, including photorealistic images and text, which can be used to bypass safety mechanisms and generate harmful outputs. However, existing datasets for evaluating LMM robustness offer limited exploration of extremist content, often lacking AI-generated images, diverse image generation models, and comprehensive coverage of historical events, which hinders a complete assessment of model vulnerabilities. To fill this gap, we introduce ExtremeAIGC, a benchmark dataset and evaluation framework designed to assess LMM vulnerabilities against such content. ExtremeAIGC simulates real-world events and malicious use cases by curating diverse text- and image-based examples crafted using state-of-the-art image generation techniques. Our study reveals alarming weaknesses in LMMs, demonstrating that even cutting-edge safety measures fail to prevent the generation of extremist material. We systematically quantify the success rates of various attack strategies, exposing critical gaps in current defenses and emphasizing the need for more robust mitigation strategies.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.09964v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.09460v1",
        "title": "Automatic Association of Quality Requirements and Quantifiable Metrics for Cloud Security Certification",
        "authors": [
            "John Bianchi",
            "Shuya Dong",
            "Luca Petrillo",
            "Marinella Petrocchi"
        ],
        "published": "2025-03-12T15:06:45Z",
        "summary": "The European Cybersecurity Certification Scheme for Cloud Services (EUCS) is one of the first cybersecurity schemes in Europe, defined by the European Union Agency for Cybersecurity (ENISA). It aims to encourage cloud providers to strengthen their cybersecurity policies in order to receive an official seal of approval from European authorities. EUCS defines a set of security requirements that the cloud provider must meet, in whole or in part, in order to achieve the security certification. The requirements are written in natural language and cover every aspect of security in the cloud environment, from logging access to protecting the system with anti-malware tools to training staff. Operationally, each requirement is associated with one or more evaluable metrics. For example, a requirement to monitor access attempts to a service will have associated metrics that take into account the number of accesses, the number of access attempts, who is accessing, and what resources are being used. Partners in the European project Medina, which ended in October 2023, defined 163 metrics and manually mapped them to 70 EUCS requirements. Manual mapping is intuitively a long and costly process in terms of human resources. This paper proposes an approach based on Sentence Transformers to automatically associate requirements and metrics. In terms of correctness of associations, the proposed method achieves a Normalized Discounted Cumulative Gain of 0.640, improving a previous experiment by 0.146 points.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.09460v1"
    },
    {
        "id": "2503.09302v1",
        "title": "Detecting and Preventing Data Poisoning Attacks on AI Models",
        "authors": [
            "Halima I. Kure",
            "Pradipta Sarkar",
            "Ahmed B. Ndanusa",
            "Augustine O. Nwajana"
        ],
        "published": "2025-03-12T11:55:01Z",
        "summary": "This paper investigates the critical issue of data poisoning attacks on AI models, a growing concern in the ever-evolving landscape of artificial intelligence and cybersecurity. As advanced technology systems become increasingly prevalent across various sectors, the need for robust defence mechanisms against adversarial attacks becomes paramount. The study aims to develop and evaluate novel techniques for detecting and preventing data poisoning attacks, focusing on both theoretical frameworks and practical applications. Through a comprehensive literature review, experimental validation using the CIFAR-10 and Insurance Claims datasets, and the development of innovative algorithms, this paper seeks to enhance the resilience of AI models against malicious data manipulation. The study explores various methods, including anomaly detection, robust optimization strategies, and ensemble learning, to identify and mitigate the effects of poisoned data during model training. Experimental results indicate that data poisoning significantly degrades model performance, reducing classification accuracy by up to 27% in image recognition tasks (CIFAR-10) and 22% in fraud detection models (Insurance Claims dataset). The proposed defence mechanisms, including statistical anomaly detection and adversarial training, successfully mitigated poisoning effects, improving model robustness and restoring accuracy levels by an average of 15-20%. The findings further demonstrate that ensemble learning techniques provide an additional layer of resilience, reducing false positives and false negatives caused by adversarial data injections.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.09302v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.09433v1",
        "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection",
        "authors": [
            "Richard A. Dubniczky",
            "Krisztofer ZoltÃ¡n HorvÃ¡t",
            "TamÃ¡s Bisztray",
            "Mohamed Amine Ferrag",
            "Lucas C. Cordeiro",
            "Norbert Tihanyi"
        ],
        "published": "2025-03-12T14:30:05Z",
        "summary": "Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at https://github.com/CASTLE-Benchmark.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.09433v1"
    },
    {
        "id": "2503.09317v1",
        "title": "RaceTEE: A Practical Privacy-Preserving Off-Chain Smart Contract Execution Architecture",
        "authors": [
            "Keyu Zhang",
            "Andrew Martin"
        ],
        "published": "2025-03-12T12:10:02Z",
        "summary": "Decentralized on-chain smart contracts enable trustless collaboration, yet their inherent data transparency and execution overhead hinder widespread adoption. Existing cryptographic approaches incur high computational costs and lack generality. Meanwhile, prior TEE-based solutions suffer from practical limitations, such as the inability to support inter-contract interactions, reliance on unbreakable TEEs, and compromised usability. We introduce RaceTEE, a practical and privacy-preserving off-chain execution architecture for smart contracts that leverages Trusted Execution Environments (TEEs). RaceTEE decouples transaction ordering (on-chain) from execution (off-chain), with computations performed competitively in TEEs, ensuring confidentiality and minimizing overhead. It further enhances practicality through three key improvements: supporting secure inter-contract interactions, providing a key rotation scheme that enforces forward and backward secrecy even in the event of TEE breaches, and enabling full compatibility with existing blockchains without altering the user interaction model. To validate its feasibility, we prototype RaceTEE using Intel SGX and Ethereum, demonstrating its applicability across various use cases and evaluating its performance.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.09317v1"
    },
    {
        "id": "2503.11634v1",
        "title": "Translating Between the Common Haar Random State Model and the Unitary Model",
        "authors": [
            "Eli Goldin",
            "Mark Zhandry"
        ],
        "published": "2025-03-14T17:52:48Z",
        "summary": "Black-box separations are a cornerstone of cryptography, indicating barriers to various goals. A recent line of work has explored black-box separations for quantum cryptographic primitives. Namely, a number of separations are known in the Common Haar Random State (CHRS) model, though this model is not considered a complete separation, but rather a starting point. A few very recent works have attempted to lift these separations to a unitary separation, which are considered complete separations. Unfortunately, we find significant errors in some of these lifting results. We prove general conditions under which CHRS separations can be generically lifted, thereby giving simple, modular, and bug-free proofs of complete unitary separations between various quantum primitives. Our techniques allow for simpler proofs of existing separations as well as new separations that were previously only known in the CHRS model.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.11634v1"
    },
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11508v1",
        "title": "Leveraging Angle of Arrival Estimation against Impersonation Attacks in Physical Layer Authentication",
        "authors": [
            "Thuy M. Pham",
            "Linda Senigagliesi",
            "Marco Baldi",
            "Rafael F. Schaefer",
            "Gerhard P. Fettweis",
            "Arsenia Chorti"
        ],
        "published": "2025-03-14T15:29:55Z",
        "summary": "In this paper, we investigate the utilization of the angle of arrival (AoA) as a feature for robust physical layer authentication (PLA). While most of the existing approaches to PLA focus on common features of the physical layer of communication channels, such as channel frequency response, channel impulse response or received signal strength, the use of AoA in this domain has not yet been studied in depth, particularly regarding the ability to thwart impersonation attacks. In this work, we demonstrate that an impersonation attack targeting AoA based PLA is only feasible under strict conditions on the attacker's location and hardware capabilities, which highlights the AoA's potential as a strong feature for PLA. We extend previous works considering a single-antenna attacker to the case of a multiple-antenna attacker, and we develop a theoretical characterization of the conditions in which a successful impersonation attack can be mounted. Furthermore, we leverage extensive simulations in support of theoretical analyses, to validate the robustness of AoA-based PLA.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.11508v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Ambient Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Ambient Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Ambient Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Ambient Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Ambient Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.10809v1",
        "title": "Attacking Multimodal OS Agents with Malicious Image Patches",
        "authors": [
            "Lukas Aichberger",
            "Alasdair Paren",
            "Yarin Gal",
            "Philip Torr",
            "Adel Bibi"
        ],
        "published": "2025-03-13T18:59:12Z",
        "summary": "Recent advances in operating system (OS) agents enable vision-language models to interact directly with the graphical user interface of an OS. These multimodal OS agents autonomously perform computer-based tasks in response to a single prompt via application programming interfaces (APIs). Such APIs typically support low-level operations, including mouse clicks, keyboard inputs, and screenshot captures. We introduce a novel attack vector: malicious image patches (MIPs) that have been adversarially perturbed so that, when captured in a screenshot, they cause an OS agent to perform harmful actions by exploiting specific APIs. For instance, MIPs embedded in desktop backgrounds or shared on social media can redirect an agent to a malicious website, enabling further exploitation. These MIPs generalise across different user requests and screen layouts, and remain effective for multiple OS agents. The existence of such attacks highlights critical security vulnerabilities in OS agents, which should be carefully addressed before their widespread adoption.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.10809v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.09513v1",
        "title": "RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment",
        "authors": [
            "Md Morshed Alam",
            "Lokesh Chandra Das",
            "Sandip Roy",
            "Sachin Shetty",
            "Weichao Wang"
        ],
        "published": "2025-03-12T16:23:14Z",
        "summary": "Internet of Things (IoT) platforms with trigger-action capability allow event conditions to trigger actions in IoT devices autonomously by creating a chain of interactions. Adversaries exploit this chain of interactions to maliciously inject fake event conditions into IoT hubs, triggering unauthorized actions on target IoT devices to implement remote injection attacks. Existing defense mechanisms focus mainly on the verification of event transactions using physical event fingerprints to enforce the security policies to block unsafe event transactions. These approaches are designed to provide offline defense against injection attacks. The state-of-the-art online defense mechanisms offer real-time defense, but extensive reliability on the inference of attack impacts on the IoT network limits the generalization capability of these approaches. In this paper, we propose a platform-independent multi-agent online defense system, namely RESTRAIN, to counter remote injection attacks at runtime. RESTRAIN allows the defense agent to profile attack actions at runtime and leverages reinforcement learning to optimize a defense policy that complies with the security requirements of the IoT network. The experimental results show that the defense agent effectively takes real-time defense actions against complex and dynamic remote injection attacks and maximizes the security gain with minimal computational overhead.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.09513v1"
    },
    {
        "id": "2503.09381v2",
        "title": "Faithful and Privacy-Preserving Implementation of Average Consensus",
        "authors": [
            "Kaoru Teranishi",
            "Kiminao Kogiso",
            "Takashi Tanaka"
        ],
        "published": "2025-03-12T13:28:22Z",
        "summary": "We propose a protocol based on mechanism design theory and encrypted control to solve average consensus problems among rational and strategic agents while preserving their privacy. The proposed protocol provides a mechanism that incentivizes the agents to faithfully implement the intended behavior specified in the protocol. Furthermore, the protocol runs over encrypted data using homomorphic encryption and secret sharing to protect the privacy of agents. We also analyze the security of the proposed protocol using a simulation paradigm in secure multi-party computation. The proposed protocol demonstrates that mechanism design and encrypted control can complement each other to achieve security under rational adversaries.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.09381v2"
    },
    {
        "id": "2503.04954v1",
        "title": "Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator",
        "authors": [
            "R. Spencer Hallyburton",
            "Miroslav Pajic"
        ],
        "published": "2025-03-06T20:33:25Z",
        "summary": "Lacking security awareness, sensor fusion in systems with multi-agent networks such as smart cities is vulnerable to attacks. To guard against recent threats, we design security-aware sensor fusion that is based on the estimates of distributions over trust. Trust estimation can be cast as a hidden Markov model, and we solve it by mapping sensor data to trust pseudomeasurements (PSMs) that recursively update trust posteriors in a Bayesian context. Trust then feeds sensor fusion to facilitate trust-weighted updates to situational awareness. Essential to security-awareness are a novel field of view estimator, logic to map sensor data into PSMs, and the derivation of efficient Bayesian updates. We evaluate security-aware fusion under attacks on agents using case studies and Monte Carlo simulation in the physics-based Unreal Engine simulator, CARLA. A mix of novel and classical security-relevant metrics show that our security-aware fusion enables building trustworthy situational awareness even in hostile conditions.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.04954v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "Smart Contracts in Banking",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09586v1",
        "title": "Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot",
        "authors": [
            "Andrew Crossman",
            "Andrew R. Plummer",
            "Chandra Sekharudu",
            "Deepak Warrier",
            "Mohammad Yekrangian"
        ],
        "published": "2025-03-12T17:54:18Z",
        "summary": "We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.",
        "field": "Smart Contracts in Banking",
        "link": "http://arxiv.org/abs/2503.09586v1"
    },
    {
        "id": "2503.00070v1",
        "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
        "authors": [
            "Tue Nhi Tran"
        ],
        "published": "2025-02-27T14:17:06Z",
        "summary": "Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.",
        "field": "Smart Contracts in Banking",
        "link": "http://arxiv.org/abs/2503.00070v1"
    },
    {
        "id": "2503.10644v1",
        "title": "Combined climate stress testing of supply-chain networks and the financial system with nation-wide firm-level emission estimates",
        "authors": [
            "Zlata TabachovÃ¡",
            "Christian Diem",
            "Johannes Stangl",
            "AndrÃ¡s Borsos",
            "Stefan Thurner"
        ],
        "published": "2025-02-25T20:25:47Z",
        "summary": "On the way towards carbon neutrality, climate stress testing provides estimates for the physical and transition risks that climate change poses to the economy and the financial system. Missing firm-level CO2 emissions data severely impedes the assessment of transition risks originating from carbon pricing. Based on the individual emissions of all Hungarian firms (410,523), as estimated from their fossil fuel purchases, we conduct a stress test of both actual and hypothetical carbon pricing policies. Using a simple 1:1 economic ABM and introducing the new carbon-to-profit ratio, we identify firms that become unprofitable and default, and estimate the respective loan write-offs. We find that 45% of all companies are directly exposed to carbon pricing. At a price of 45 EUR/t, direct economic losses of 1.3% of total sales and bank equity losses of 1.2% are expected. Secondary default cascades in supply chain networks could increase these losses by 300% to 4000%, depending on firms' ability to substitute essential inputs. To reduce transition risks, firms should reduce their dependence on essential inputs from supply chains with high CO2 exposure. We discuss the implications of different policy implementations on these transition risks.",
        "field": "Smart Contracts in Banking",
        "link": "http://arxiv.org/abs/2503.10644v1"
    },
    {
        "id": "2502.14766v2",
        "title": "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and Convergence Analysis",
        "authors": [
            "Kristoffer Andersson",
            "Alessandro Gnoatto"
        ],
        "published": "2025-02-20T17:41:55Z",
        "summary": "We propose a structural default model for portfolio-wide valuation adjustments (xVAs) and represent it as a system of coupled backward stochastic differential equations. The framework is divided into four layers, each capturing a key component: (i) clean values, (ii) initial margin and Collateral Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments (CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding Valuation Adjustment (FVA). Because these layers depend on one another through collateral and default effects, a naive Monte Carlo approach would require deeply nested simulations, making the problem computationally intractable. To address this challenge, we use an iterative deep BSDE approach, handling each layer sequentially so that earlier outputs serve as inputs to the subsequent layers. Initial margin is computed via deep quantile regression to reflect margin requirements over the Margin Period of Risk. We also adopt a change-of-measure method that highlights rare but significant defaults of the bank or counterparty, ensuring that these events are accurately captured in the training process. We further extend Han and Long's (2020) a posteriori error analysis to BSDEs on bounded domains. Due to the random exit from the domain, we obtain an order of convergence of $\\mathcal{O}(h^{1/4-\\epsilon})$ rather than the usual $\\mathcal{O}(h^{1/2})$. Numerical experiments illustrate that this method drastically reduces computational demands and successfully scales to high-dimensional, non-symmetric portfolios. The results confirm its effectiveness and accuracy, offering a practical alternative to nested Monte Carlo simulations in multi-counterparty xVA analyses.",
        "field": "Smart Contracts in Banking",
        "link": "http://arxiv.org/abs/2502.14766v2"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.10944v1",
        "title": "Phishsense-1B: A Technical Perspective on an AI-Powered Phishing Detection Model",
        "authors": [
            "SE Blake"
        ],
        "published": "2025-03-13T23:03:09Z",
        "summary": "Phishing is a persistent cybersecurity threat in today's digital landscape. This paper introduces Phishsense-1B, a refined version of the Llama-Guard-3-1B model, specifically tailored for phishing detection and reasoning. This adaptation utilizes Low-Rank Adaptation (LoRA) and the GuardReasoner finetuning methodology. We outline our LoRA-based fine-tuning process, describe the balanced dataset comprising phishing and benign emails, and highlight significant performance improvements over the original model. Our findings indicate that Phishsense-1B achieves an impressive 97.5% accuracy on a custom dataset and maintains strong performance with 70% accuracy on a challenging real-world dataset. This performance notably surpasses both unadapted models and BERT-based detectors. Additionally, we examine current state-of-the-art detection methods, compare prompt-engineering with fine-tuning strategies, and explore potential deployment scenarios.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10944v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10255v1",
        "title": "An Open-RAN Testbed for Detecting and Mitigating Radio-Access Anomalies",
        "authors": [
            "Hanna Bogucka",
            "Marcin Hoffmann",
            "PaweÅ Kryszkiewicz",
            "Åukasz KuÅacz"
        ],
        "published": "2025-03-13T11:10:29Z",
        "summary": "This paper presents the Open Radio Access Net-work (O-RAN) testbed for secure radio access. We discuss radio-originating attack detection and mitigation methods based on anomaly detection and how they can be implemented as specialized applications (xApps) in this testbed. We also pre-sent illustrating results of the methods applied in real-world scenarios and implementations.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.10255v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "Digital Wallet Interoperability",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09165v1",
        "title": "Blockchain Data Analytics: Review and Challenges",
        "authors": [
            "Rischan Mafrur"
        ],
        "published": "2025-03-12T08:49:51Z",
        "summary": "The integration of blockchain technology with data analytics is essential for extracting insights in the cryptocurrency space. Although academic literature on blockchain data analytics is limited, various industry solutions have emerged to address these needs. This paper provides a comprehensive literature review, drawing from both academic research and industry applications. We classify blockchain analytics tools into categories such as block explorers, on-chain data providers, research platforms, and crypto market data providers. Additionally, we discuss the challenges associated with blockchain data analytics, including data accessibility, scalability, accuracy, and interoperability. Our findings emphasize the importance of bridging academic research and industry innovations to advance blockchain data analytics.",
        "field": "Digital Wallet Interoperability",
        "link": "http://arxiv.org/abs/2503.09165v1"
    },
    {
        "id": "2503.07857v1",
        "title": "Efficient Resource Management for Secure and Low-Latency O-RAN Communication",
        "authors": [
            "Zaineh Abughazzah",
            "Emna Baccour",
            "Ahmed Refaey",
            "Amr Mohamed",
            "Mounir Hamdi"
        ],
        "published": "2025-03-10T21:03:48Z",
        "summary": "Open Radio Access Networks (O-RAN) are transforming telecommunications by shifting from centralized to distributed architectures, promoting flexibility, interoperability, and innovation through open interfaces and multi-vendor environments. However, O-RAN's reliance on cloud-based architecture and enhanced observability introduces significant security and resource management challenges. Efficient resource management is crucial for secure and reliable communication in O-RAN, within the resource-constrained environment and heterogeneity of requirements, where multiple User Equipment (UE) and O-RAN Radio Units (O-RUs) coexist. This paper develops a framework to manage these aspects, ensuring each O-RU is associated with UEs based on their communication channel qualities and computational resources, and selecting appropriate encryption algorithms to safeguard data confidentiality, integrity, and authentication. A Multi-objective Optimization Problem (MOP) is formulated to minimize latency and maximize security within resource constraints. Different approaches are proposed to relax the complexity of the problem and achieve near-optimal performance, facilitating trade-offs between latency, security, and solution complexity. Simulation results demonstrate that the proposed approaches are close enough to the optimal solution, proving that our approach is both effective and efficient.",
        "field": "Digital Wallet Interoperability",
        "link": "http://arxiv.org/abs/2503.07857v1"
    },
    {
        "id": "2503.05206v2",
        "title": "Operationalizing Cybersecurity Knowledge: Design, Implementation & Evaluation of a Knowledge Management System for CACAO Playbooks",
        "authors": [
            "Orestis Tsirakis",
            "Konstantinos Fysarakis",
            "Vasileios Mavroeidis",
            "Ioannis Papaefstathiou"
        ],
        "published": "2025-03-07T07:54:43Z",
        "summary": "Modern cybersecurity threats are growing in complexity, targeting increasingly intricate & interconnected systems. To effectively defend against these evolving threats, security teams utilize automation & orchestration to enhance response efficiency and consistency. In that sense, cybersecurity playbooks are key enablers, providing a structured, reusable, and continuously improving approach to incident response, enabling organizations to codify requirements, domain expertise, and best practices and automate decision-making processes to the extent possible. The emerging Collaborative Automated Course of Action Operations (CACAO) standard defines a common machine-processable schema for cybersecurity playbooks, facilitating interoperability for their exchange and ensuring the ability to orchestrate and automate cybersecurity operations. However, despite its potential and the fact that it is a relatively new standardization work, there is a lack of tools to support its adoption and, in particular, the management & lifecycle development of CACAO playbooks, limiting their practical deployment. Motivated by the above, this work presents the design, development, and evaluation of a Knowledge Management System (KMS) for managing CACAO cybersecurity playbooks throughout their lifecycle, providing essential tools to streamline playbook management. Using open technologies & standards, the proposed approach fosters standards-based interoperability & enhances the usability of state-of-the-art cybersecurity orchestration & automation primitives. To encourage adoption, the resulting implementation is released as open-source, which, to the extent of our knowledge, comprises the first publicly available & documented work in this domain, supporting the broader uptake of CACAO playbooks & promoting the widespread use of interoperable automation and orchestration mechanisms in cybersecurity operations.",
        "field": "Digital Wallet Interoperability",
        "link": "http://arxiv.org/abs/2503.05206v2"
    },
    {
        "id": "2503.00404v1",
        "title": "SecRef*: Securely Sharing Mutable References Between Verified and Unverified Code in F*",
        "authors": [
            "Cezar-Constantin Andrici",
            "Danel Ahman",
            "Catalin Hritcu",
            "Ruxandra Icleanu",
            "Guido MartÃ­nez",
            "Exequiel Rivas",
            "ThÃ©o Winterhalter"
        ],
        "published": "2025-03-01T08:48:39Z",
        "summary": "We introduce SecRef*, a secure compilation framework protecting stateful programs verified in F* against linked unverified code, with which the program dynamically shares ML-style mutable references. To ease program verification in this setting, we propose a way of tracking which references are shareable with the unverified code, and which ones are not shareable and whose contents are thus guaranteed to be unchanged after calling into unverified code. This universal property of non-shareable references is exposed in the interface on which the verified program can rely when calling into unverified code. The remaining refinement types and pre- and post-conditions that the verified code expects from the unverified code are converted into dynamic checks about the shared references by using higher-order contracts. We prove formally in F* that this strategy ensures sound and secure interoperability with unverified code. Since SecRef* is built on top of the Monotonic State effect of F*, these proofs rely on the first monadic representation for this effect, which is a contribution of our work that can be of independent interest. Finally, we use SecRef* to build a simple cooperative multi-threading scheduler that is verified and that securely interacts with unverified threads.",
        "field": "Digital Wallet Interoperability",
        "link": "http://arxiv.org/abs/2503.00404v1"
    },
    {
        "id": "2502.19320v2",
        "title": "Shh, don't say that! Domain Certification in LLMs",
        "authors": [
            "Cornelius Emde",
            "Alasdair Paren",
            "Preetham Arvind",
            "Maxime Kayser",
            "Tom Rainforth",
            "Thomas Lukasiewicz",
            "Bernard Ghanem",
            "Philip H. S. Torr",
            "Adel Bibi"
        ],
        "published": "2025-02-26T17:13:19Z",
        "summary": "Large language models (LLMs) are often deployed to perform constrained tasks, with narrow domains. For example, customer support bots can be built on top of LLMs, relying on their broad language understanding and capabilities to enhance performance. However, these LLMs are adversarially susceptible, potentially generating outputs outside the intended domain. To formalize, assess, and mitigate this risk, we introduce domain certification; a guarantee that accurately characterizes the out-of-domain behavior of language models. We then propose a simple yet effective approach, which we call VALID that provides adversarial bounds as a certificate. Finally, we evaluate our method across a diverse set of datasets, demonstrating that it yields meaningful certificates, which bound the probability of out-of-domain samples tightly with minimum penalty to refusal behavior.",
        "field": "AI-Powered Customer Service Bots",
        "link": "http://arxiv.org/abs/2502.19320v2"
    },
    {
        "id": "2502.16054v1",
        "title": "Human-AI Collaboration in Cloud Security: Cognitive Hierarchy-Driven Deep Reinforcement Learning",
        "authors": [
            "Zahra Aref",
            "Sheng Wei",
            "Narayan B. Mandayam"
        ],
        "published": "2025-02-22T03:19:21Z",
        "summary": "Given the complexity of multi-tenant cloud environments and the need for real-time threat mitigation, Security Operations Centers (SOCs) must integrate AI-driven adaptive defenses against Advanced Persistent Threats (APTs). However, SOC analysts struggle with countering adaptive adversarial tactics, necessitating intelligent decision-support frameworks. To enhance human-AI collaboration in SOCs, we propose a Cognitive Hierarchy Theory-driven Deep Q-Network (CHT-DQN) framework that models SOC analysts' decision-making against AI-driven APT bots. The SOC analyst (defender) operates at cognitive level-1, anticipating attacker strategies, while the APT bot (attacker) follows a level-0 exploitative policy. By incorporating CHT into DQN, our framework enhances SOC defense strategies via Attack Graph (AG)-based reinforcement learning. Simulation experiments across varying AG complexities show that CHT-DQN achieves higher data protection and lower action discrepancies compared to standard DQN. A theoretical lower bound analysis further validates its superior Q-value performance. A human-in-the-loop (HITL) evaluation on Amazon Mechanical Turk (MTurk) reveals that SOC analysts using CHT-DQN-driven transition probabilities align better with adaptive attackers, improving data protection. Additionally, human decision patterns exhibit risk aversion after failure and risk-seeking behavior after success, aligning with Prospect Theory. These findings underscore the potential of integrating cognitive modeling into deep reinforcement learning to enhance SOC operations and develop real-time adaptive cloud security mechanisms.",
        "field": "AI-Powered Customer Service Bots",
        "link": "http://arxiv.org/abs/2502.16054v1"
    },
    {
        "id": "2502.12322v2",
        "title": "VIC: Evasive Video Game Cheating via Virtual Machine Introspection",
        "authors": [
            "Panicos Karkallis",
            "Jorge Blasco"
        ],
        "published": "2025-02-17T20:54:56Z",
        "summary": "Video game cheats modify a video game behaviour to give unfair advantages to some players while bypassing the methods game developers use to detect them. This destroys the experience of online gaming and can result in financial losses for game developers. In this work, we present a new type of game cheat, Virtual machine Introspection Cheat (VIC), that takes advantage of virtual machines to stealthy execute game cheats. VIC employees a hypervisor with introspection enabled to lower the bar of cheating against legacy and modern anti-cheat systems. We demonstrate the feasibility and stealthiness of VIC against three popular games (Fortnite, BlackSquad and Team Fortress 2) that include five different anti-cheats. In particular, we use VIC to implement a cheat radar, a wall-hack cheat and a trigger-bot. To support our claim that this type of cheats can be effectively used, we present the performance impact VICs have on gameplay by monitoring the frames per second (fps) while the cheats are activated. Our experimentation also shows how these cheats are currently undetected by the most popular anti-cheat systems, enabling a new paradigm that can take advantage of cloud infrastructure to offer cheating-as-a-service.",
        "field": "AI-Powered Customer Service Bots",
        "link": "http://arxiv.org/abs/2502.12322v2"
    },
    {
        "id": "2502.05461v2",
        "title": "IllusionCAPTCHA: A CAPTCHA based on Visual Illusion",
        "authors": [
            "Ziqi Ding",
            "Gelei Deng",
            "Yi Liu",
            "Junchen Ding",
            "Jieshan Chen",
            "Yulei Sui",
            "Yuekang Li"
        ],
        "published": "2025-02-08T06:03:03Z",
        "summary": "CAPTCHAs have long been essential tools for protecting applications from automated bots. Initially designed as simple questions to distinguish humans from bots, they have become increasingly complex to keep pace with the proliferation of CAPTCHA-cracking techniques employed by malicious actors. However, with the advent of advanced large language models (LLMs), the effectiveness of existing CAPTCHAs is now being undermined. To address this issue, we have conducted an empirical study to evaluate the performance of multimodal LLMs in solving CAPTCHAs and to assess how many attempts human users typically need to pass them. Our findings reveal that while LLMs can solve most CAPTCHAs, they struggle with those requiring complex reasoning type of CAPTCHA that also presents significant challenges for human users. Interestingly, our user study shows that the majority of human participants require a second attempt to pass these reasoning CAPTCHAs, a finding not reported in previous research. Based on empirical findings, we present IllusionCAPTCHA, a novel security mechanism employing the \"Human-Easy but AI-Hard\" paradigm. This new CAPTCHA employs visual illusions to create tasks that are intuitive for humans but highly confusing for AI models. Furthermore, we developed a structured, step-by-step method that generates misleading options, which particularly guide LLMs towards making incorrect choices and reduce their chances of successfully solving CAPTCHAs. Our evaluation shows that IllusionCAPTCHA can effectively deceive LLMs 100% of the time. Moreover, our structured design significantly increases the likelihood of AI errors when attempting to solve these challenges. Results from our user study indicate that 86.95% of participants successfully passed the CAPTCHA on their first attempt, outperforming other CAPTCHA systems.",
        "field": "AI-Powered Customer Service Bots",
        "link": "http://arxiv.org/abs/2502.05461v2"
    },
    {
        "id": "2502.01608v1",
        "title": "Beyond the Crawl: Unmasking Browser Fingerprinting in Real User Interactions",
        "authors": [
            "Meenatchi Sundaram Muthu Selva Annamalai",
            "Igor Bilogrevic",
            "Emiliano De Cristofaro"
        ],
        "published": "2025-02-03T18:43:34Z",
        "summary": "Browser fingerprinting is a pervasive online tracking technique used increasingly often for profiling and targeted advertising. Prior research on the prevalence of fingerprinting heavily relied on automated web crawls, which inherently struggle to replicate the nuances of human-computer interactions. This raises concerns about the accuracy of current understandings of real-world fingerprinting deployments. As a result, this paper presents a user study involving 30 participants over 10 weeks, capturing telemetry data from real browsing sessions across 3,000 top-ranked websites. Our evaluation reveals that automated crawls miss almost half (45%) of the fingerprinting websites encountered by real users. This discrepancy mainly stems from the crawlers' inability to access authentication-protected pages, circumvent bot detection, and trigger fingerprinting scripts activated by specific user interactions. We also identify potential new fingerprinting vectors present in real user data but absent from automated crawls. Finally, we evaluate the effectiveness of federated learning for training browser fingerprinting detection models on real user data, yielding improved performance than models trained solely on automated crawl data.",
        "field": "AI-Powered Customer Service Bots",
        "link": "http://arxiv.org/abs/2502.01608v1"
    },
    {
        "id": "2503.10207v1",
        "title": "Efficient Implementation of CRYSTALS-KYBER Key Encapsulation Mechanism on ESP32",
        "authors": [
            "Fabian Segatz",
            "Muhammad Ihsan Al Hafiz"
        ],
        "published": "2025-03-13T09:45:31Z",
        "summary": "Kyber, an IND-CCA2-secure lattice-based post-quantum key-encapsulation mechanism, is the winner of the first post-quantum cryptography standardization process of the US National Institute of Standards and Technology. In this work, we provide an efficient implementation of Kyber on ESP32, a very popular microcontroller for Internet of Things applications. We hand-partition the Kyber algorithm to enable utilization of the ESP32 dual-core architecture, which allows us to speed up its execution by 1.21x (keygen), 1.22x (encaps) and 1.20x (decaps). We also explore the possibility of gaining further improvement by utilizing the ESP32 SHA and AES coprocessor and achieve a culminated speed-up of 1.72x (keygen), 1.84x (encaps) and 1.69x (decaps).",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.10207v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.09666v1",
        "title": "Blockchain-Enabled Management Framework for Federated Coalition Networks",
        "authors": [
            "Jorge Ãlvaro GonzÃ¡lez",
            "Ana MarÃ­a Saiz GarcÃ­a",
            "Victor Monzon Baeza"
        ],
        "published": "2025-03-12T16:59:23Z",
        "summary": "In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.09666v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09327v1",
        "title": "Heuristic-Based Address Clustering in Cardano Blockchain",
        "authors": [
            "Mostafa Chegenizadeh",
            "Sina Rafati Niya",
            "Claudio J. Tessone"
        ],
        "published": "2025-03-12T12:22:26Z",
        "summary": "Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.09327v1"
    },
    {
        "id": "2503.11185v1",
        "title": "Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification",
        "authors": [
            "Yingjie Zhang",
            "Tong Liu",
            "Zhe Zhao",
            "Guozhu Meng",
            "Kai Chen"
        ],
        "published": "2025-03-14T08:32:12Z",
        "summary": "Large Language Models (LLMs) are vulnerable to jailbreak attacks, which use crafted prompts to elicit toxic responses. These attacks exploit LLMs' difficulty in dynamically detecting harmful intents during the generation process. Traditional safety alignment methods, often relying on the initial few generation steps, are ineffective due to limited computational budget. This paper proposes DEEPALIGN, a robust defense framework that fine-tunes LLMs to progressively detoxify generated content, significantly improving both the computational budget and effectiveness of mitigating harmful generation. Our approach uses a hybrid loss function operating on hidden states to directly improve LLMs' inherent awareness of toxity during generation. Furthermore, we redefine safe responses by generating semantically relevant answers to harmful queries, thereby increasing robustness against representation-mutation attacks. Evaluations across multiple LLMs demonstrate state-of-the-art defense performance against six different attack types, reducing Attack Success Rates by up to two orders of magnitude compared to previous state-of-the-art defense while preserving utility. This work advances LLM safety by addressing limitations of conventional alignment through dynamic, context-aware mitigation.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.11185v1"
    },
    {
        "id": "2503.10944v1",
        "title": "Phishsense-1B: A Technical Perspective on an AI-Powered Phishing Detection Model",
        "authors": [
            "SE Blake"
        ],
        "published": "2025-03-13T23:03:09Z",
        "summary": "Phishing is a persistent cybersecurity threat in today's digital landscape. This paper introduces Phishsense-1B, a refined version of the Llama-Guard-3-1B model, specifically tailored for phishing detection and reasoning. This adaptation utilizes Low-Rank Adaptation (LoRA) and the GuardReasoner finetuning methodology. We outline our LoRA-based fine-tuning process, describe the balanced dataset comprising phishing and benign emails, and highlight significant performance improvements over the original model. Our findings indicate that Phishsense-1B achieves an impressive 97.5% accuracy on a custom dataset and maintains strong performance with 70% accuracy on a challenging real-world dataset. This performance notably surpasses both unadapted models and BERT-based detectors. Additionally, we examine current state-of-the-art detection methods, compare prompt-engineering with fine-tuning strategies, and explore potential deployment scenarios.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.10944v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.10269v1",
        "title": "Targeted Data Poisoning for Black-Box Audio Datasets Ownership Verification",
        "authors": [
            "Wassim Bouaziz",
            "El-Mahdi El-Mhamdi",
            "Nicolas Usunier"
        ],
        "published": "2025-03-13T11:25:25Z",
        "summary": "Protecting the use of audio datasets is a major concern for data owners, particularly with the recent rise of audio deep learning models. While watermarks can be used to protect the data itself, they do not allow to identify a deep learning model trained on a protected dataset. In this paper, we adapt to audio data the recently introduced data taggants approach. Data taggants is a method to verify if a neural network was trained on a protected image dataset with top-$k$ predictions access to the model only. This method relies on a targeted data poisoning scheme by discreetly altering a small fraction (1%) of the dataset as to induce a harmless behavior on out-of-distribution data called keys. We evaluate our method on the Speechcommands and the ESC50 datasets and state of the art transformer models, and show that we can detect the use of the dataset with high confidence without loss of performance. We also show the robustness of our method against common data augmentation techniques, making it a practical method to protect audio datasets.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.10269v1"
    },
    {
        "id": "2503.10255v1",
        "title": "An Open-RAN Testbed for Detecting and Mitigating Radio-Access Anomalies",
        "authors": [
            "Hanna Bogucka",
            "Marcin Hoffmann",
            "PaweÅ Kryszkiewicz",
            "Åukasz KuÅacz"
        ],
        "published": "2025-03-13T11:10:29Z",
        "summary": "This paper presents the Open Radio Access Net-work (O-RAN) testbed for secure radio access. We discuss radio-originating attack detection and mitigation methods based on anomaly detection and how they can be implemented as specialized applications (xApps) in this testbed. We also pre-sent illustrating results of the methods applied in real-world scenarios and implementations.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.10255v1"
    },
    {
        "id": "2503.11573v1",
        "title": "Synthesizing Access Control Policies using Large Language Models",
        "authors": [
            "Adarsh Vatsa",
            "Pratyush Patel",
            "William Eiers"
        ],
        "published": "2025-03-14T16:40:25Z",
        "summary": "Cloud compute systems allow administrators to write access control policies that govern access to private data. While policies are written in convenient languages, such as AWS Identity and Access Management Policy Language, manually written policies often become complex and error prone. In this paper, we investigate whether and how well Large Language Models (LLMs) can be used to synthesize access control policies. Our investigation focuses on the task of taking an access control request specification and zero-shot prompting LLMs to synthesize a well-formed access control policy which correctly adheres to the request specification. We consider two scenarios, one which the request specification is given as a concrete list of requests to be allowed or denied, and another in which a natural language description is used to specify sets of requests to be allowed or denied. We then argue that for zero-shot prompting, more precise and structured prompts using a syntax based approach are necessary and experimentally show preliminary results validating our approach.",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.11573v1"
    },
    {
        "id": "2503.11404v1",
        "title": "Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models",
        "authors": [
            "Jonas Thietke",
            "Andreas MÃ¼ller",
            "Denis Lukovnikov",
            "Asja Fischer",
            "Erwin Quiring"
        ],
        "published": "2025-03-14T13:45:46Z",
        "summary": "Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality.",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.11404v1"
    },
    {
        "id": "2503.10171v1",
        "title": "Verifiable, Efficient and Confidentiality-Preserving Graph Search with Transparency",
        "authors": [
            "Qiuhao Wang",
            "Xu Yang",
            "Yiwei Liu",
            "Saiyu Qi",
            "Hongguang Zhao",
            "Ke Li",
            "Yong Qi"
        ],
        "published": "2025-03-13T08:53:53Z",
        "summary": "Graph databases have garnered extensive attention and research due to their ability to manage relationships between entities efficiently. Today, many graph search services have been outsourced to a third-party server to facilitate storage and computational support. Nevertheless, the outsourcing paradigm may invade the privacy of graphs. PeGraph is the latest scheme achieving encrypted search over social graphs to address the privacy leakage, which maintains two data structures XSet and TSet motivated by the OXT technology to support encrypted conjunctive search. However, PeGraph still exhibits limitations inherent to the underlying OXT. It does not provide transparent search capabilities, suffers from expensive computation and result pattern leakages, and it fails to support search over dynamic encrypted graph database and results verification. In this paper, we propose SecGraph to address the first two limitations, which adopts a novel system architecture that leverages an SGX-enabled cloud server to provide users with secure and transparent search services since the secret key protection and computational overhead have been offloaded to the cloud server. Besides, we design an LDCF-encoded XSet based on the Logarithmic Dynamic Cuckoo Filter to facilitate efficient plaintext computation in trusted memory, effectively mitigating the risks of result pattern leakage and performance degradation due to exceeding the limited trusted memory capacity. Finally, we design a new dynamic version of TSet named Twin-TSet to enable conjunctive search over dynamic encrypted graph database. In order to support verifiable search, we further propose VSecGraph, which utilizes a procedure-oriented verification method to verify all data structures loaded into the trusted memory, thus bypassing the computational overhead associated with the client's local verification.",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.10171v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.11619v1",
        "title": "Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Ming-Hsuan Yang",
            "Jun Liu",
            "Chengcheng Tang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:39:45Z",
        "summary": "Deploying large vision-language models (LVLMs) introduces a unique vulnerability: susceptibility to malicious attacks via visual inputs. However, existing defense methods suffer from two key limitations: (1) They solely focus on textual defenses, fail to directly address threats in the visual domain where attacks originate, and (2) the additional processing steps often incur significant computational overhead or compromise model performance on benign tasks. Building on these insights, we propose ESIII (Embedding Security Instructions Into Images), a novel methodology for transforming the visual space from a source of vulnerability into an active defense mechanism. Initially, we embed security instructions into defensive images through gradient-based optimization, obtaining security instructions in the visual dimension. Subsequently, we integrate security instructions from visual and textual dimensions with the input query. The collaboration between security instructions from different dimensions ensures comprehensive security protection. Extensive experiments demonstrate that our approach effectively fortifies the robustness of LVLMs against such attacks while preserving their performance on standard benign tasks and incurring an imperceptible increase in time costs.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.11619v1"
    },
    {
        "id": "2503.11053v1",
        "title": "Pricing American Parisian Options under General Time-Inhomogeneous Markov Models",
        "authors": [
            "Yuhao Liu",
            "Nian Yang",
            "Gongqiu Zhang"
        ],
        "published": "2025-03-14T03:45:18Z",
        "summary": "This paper develops general approaches for pricing various types of American-style Parisian options (down-in/-out, perpetual/finite-maturity) with general payoff functions based on continuous-time Markov chain (CTMC) approximation under general 1D time-inhomogeneous Markov models. For the down-in types, by conditioning on the Parisian stopping time, we reduce the pricing problem to that of a series of vanilla American options with different maturities and their prices integrated with the distribution function of the Parisian stopping time yield the American Parisian down-in option price. This facilitates an efficient application of CTMC approximation to obtain the approximate option price by calculating the required quantities. For the perpetual down-in cases under time-homogeneous models, significant computational cost can be reduced. The down-out cases are more complicated, for which we use the state augmentation approach to record the excursion duration and then the approximate option price is obtained by solving a series of variational inequalities recursively with the Lemke's pivoting method. We show the convergence of CTMC approximation for all the types of American Parisian options under general time-inhomogeneous Markov models, and the accuracy and efficiency of our algorithms are confirmed with extensive numerical experiments.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.11053v1"
    },
    {
        "id": "2503.11514v1",
        "title": "Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks",
        "authors": [
            "Pengxin Guo",
            "Runxi Wang",
            "Shuang Zeng",
            "Jinjing Zhu",
            "Haoning Jiang",
            "Yanran Wang",
            "Yuyin Zhou",
            "Feifei Wang",
            "Hui Xiong",
            "Liangqiong Qu"
        ],
        "published": "2025-03-13T08:08:44Z",
        "summary": "Federated Learning (FL) has emerged as a promising privacy-preserving collaborative model training paradigm without sharing raw data. However, recent studies have revealed that private information can still be leaked through shared gradient information and attacked by Gradient Inversion Attacks (GIA). While many GIA methods have been proposed, a detailed analysis, evaluation, and summary of these methods are still lacking. Although various survey papers summarize existing privacy attacks in FL, few studies have conducted extensive experiments to unveil the effectiveness of GIA and their associated limiting factors in this context. To fill this gap, we first undertake a systematic review of GIA and categorize existing methods into three types, i.e., \\textit{optimization-based} GIA (OP-GIA), \\textit{generation-based} GIA (GEN-GIA), and \\textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively analyze and evaluate the three types of GIA in FL, providing insights into the factors that influence their performance, practicality, and potential threats. Our findings indicate that OP-GIA is the most practical attack setting despite its unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA is easily detectable, making them both impractical. Finally, we offer a three-stage defense pipeline to users when designing FL frameworks and protocols for better privacy protection and share some future research directions from the perspectives of attackers and defenders that we believe should be pursued. We hope that our study can help researchers design more robust FL frameworks to defend against these attacks.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.11514v1"
    },
    {
        "id": "2503.09460v1",
        "title": "Automatic Association of Quality Requirements and Quantifiable Metrics for Cloud Security Certification",
        "authors": [
            "John Bianchi",
            "Shuya Dong",
            "Luca Petrillo",
            "Marinella Petrocchi"
        ],
        "published": "2025-03-12T15:06:45Z",
        "summary": "The European Cybersecurity Certification Scheme for Cloud Services (EUCS) is one of the first cybersecurity schemes in Europe, defined by the European Union Agency for Cybersecurity (ENISA). It aims to encourage cloud providers to strengthen their cybersecurity policies in order to receive an official seal of approval from European authorities. EUCS defines a set of security requirements that the cloud provider must meet, in whole or in part, in order to achieve the security certification. The requirements are written in natural language and cover every aspect of security in the cloud environment, from logging access to protecting the system with anti-malware tools to training staff. Operationally, each requirement is associated with one or more evaluable metrics. For example, a requirement to monitor access attempts to a service will have associated metrics that take into account the number of accesses, the number of access attempts, who is accessing, and what resources are being used. Partners in the European project Medina, which ended in October 2023, defined 163 metrics and manually mapped them to 70 EUCS requirements. Manual mapping is intuitively a long and costly process in terms of human resources. This paper proposes an approach based on Sentence Transformers to automatically associate requirements and metrics. In terms of correctness of associations, the proposed method achieves a Normalized Discounted Cumulative Gain of 0.640, improving a previous experiment by 0.146 points.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.09460v1"
    },
    {
        "id": "2503.09446v1",
        "title": "Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models",
        "authors": [
            "Zhihua Tian",
            "Sirun Nan",
            "Ming Xu",
            "Shengfang Zhai",
            "Wenjie Qu",
            "Jian Liu",
            "Kui Ren",
            "Ruoxi Jia",
            "Jiaheng Zhang"
        ],
        "published": "2025-03-12T14:46:40Z",
        "summary": "Text-to-image (T2I) diffusion models have achieved remarkable progress in generating high-quality images but also raise people's concerns about generating harmful or misleading content. While extensive approaches have been proposed to erase unwanted concepts without requiring retraining from scratch, they inadvertently degrade performance on normal generation tasks. In this work, we propose Interpret then Deactivate (ItD), a novel framework to enable precise concept removal in T2I diffusion models while preserving overall performance. ItD first employs a sparse autoencoder (SAE) to interpret each concept as a combination of multiple features. By permanently deactivating the specific features associated with target concepts, we repurpose SAE as a zero-shot classifier that identifies whether the input prompt includes target concepts, allowing selective concept erasure in diffusion models. Moreover, we demonstrate that ItD can be easily extended to erase multiple concepts without requiring further training. Comprehensive experiments across celebrity identities, artistic styles, and explicit content demonstrate ItD's effectiveness in eliminating targeted concepts without interfering with normal concept generation. Additionally, ItD is also robust against adversarial prompts designed to circumvent content filters. Code is available at: https://github.com/NANSirun/Interpret-then-deactivate.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.09446v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.10239v1",
        "title": "I Can Tell Your Secrets: Inferring Privacy Attributes from Mini-app Interaction History in Super-apps",
        "authors": [
            "Yifeng Cai",
            "Ziqi Zhang",
            "Mengyu Yao",
            "Junlin Liu",
            "Xiaoke Zhao",
            "Xinyi Fu",
            "Ruoyu Li",
            "Zhe Li",
            "Xiangqun Chen",
            "Yao Guo",
            "Ding Li"
        ],
        "published": "2025-03-13T10:29:40Z",
        "summary": "Super-apps have emerged as comprehensive platforms integrating various mini-apps to provide diverse services. While super-apps offer convenience and enriched functionality, they can introduce new privacy risks. This paper reveals a new privacy leakage source in super-apps: mini-app interaction history, including mini-app usage history (Mini-H) and operation history (Op-H). Mini-H refers to the history of mini-apps accessed by users, such as their frequency and categories. Op-H captures user interactions within mini-apps, including button clicks, bar drags, and image views. Super-apps can naturally collect these data without instrumentation due to the web-based feature of mini-apps. We identify these data types as novel and unexplored privacy risks through a literature review of 30 papers and an empirical analysis of 31 super-apps. We design a mini-app interaction history-oriented inference attack (THEFT), to exploit this new vulnerability. Using THEFT, the insider threats within the low-privilege business department of the super-app vendor acting as the adversary can achieve more than 95.5% accuracy in inferring privacy attributes of over 16.1% of users. THEFT only requires a small training dataset of 200 users from public breached databases on the Internet. We also engage with super-app vendors and a standards association to increase industry awareness and commitment to protect this data. Our contributions are significant in identifying overlooked privacy risks, demonstrating the effectiveness of a new attack, and influencing industry practices toward better privacy protection in the super-app ecosystem.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.10239v1"
    },
    {
        "id": "2503.10238v1",
        "title": "Post Quantum Migration of Tor",
        "authors": [
            "Denis Berger",
            "Mouad Lemoudden",
            "William J Buchanan"
        ],
        "published": "2025-03-13T10:28:03Z",
        "summary": "Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as \\emph{harvest now, decrypt later} attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.10238v1"
    },
    {
        "id": "2503.11514v1",
        "title": "Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks",
        "authors": [
            "Pengxin Guo",
            "Runxi Wang",
            "Shuang Zeng",
            "Jinjing Zhu",
            "Haoning Jiang",
            "Yanran Wang",
            "Yuyin Zhou",
            "Feifei Wang",
            "Hui Xiong",
            "Liangqiong Qu"
        ],
        "published": "2025-03-13T08:08:44Z",
        "summary": "Federated Learning (FL) has emerged as a promising privacy-preserving collaborative model training paradigm without sharing raw data. However, recent studies have revealed that private information can still be leaked through shared gradient information and attacked by Gradient Inversion Attacks (GIA). While many GIA methods have been proposed, a detailed analysis, evaluation, and summary of these methods are still lacking. Although various survey papers summarize existing privacy attacks in FL, few studies have conducted extensive experiments to unveil the effectiveness of GIA and their associated limiting factors in this context. To fill this gap, we first undertake a systematic review of GIA and categorize existing methods into three types, i.e., \\textit{optimization-based} GIA (OP-GIA), \\textit{generation-based} GIA (GEN-GIA), and \\textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively analyze and evaluate the three types of GIA in FL, providing insights into the factors that influence their performance, practicality, and potential threats. Our findings indicate that OP-GIA is the most practical attack setting despite its unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA is easily detectable, making them both impractical. Finally, we offer a three-stage defense pipeline to users when designing FL frameworks and protocols for better privacy protection and share some future research directions from the perspectives of attackers and defenders that we believe should be pursued. We hope that our study can help researchers design more robust FL frameworks to defend against these attacks.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.11514v1"
    },
    {
        "id": "2503.10238v1",
        "title": "Post Quantum Migration of Tor",
        "authors": [
            "Denis Berger",
            "Mouad Lemoudden",
            "William J Buchanan"
        ],
        "published": "2025-03-13T10:28:03Z",
        "summary": "Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as \\emph{harvest now, decrypt later} attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.10238v1"
    },
    {
        "id": "2503.09964v1",
        "title": "ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist Content",
        "authors": [
            "Bhavik Chandna",
            "Mariam Aboujenane",
            "Usman Naseem"
        ],
        "published": "2025-03-13T02:10:29Z",
        "summary": "Large Multimodal Models (LMMs) are increasingly vulnerable to AI-generated extremist content, including photorealistic images and text, which can be used to bypass safety mechanisms and generate harmful outputs. However, existing datasets for evaluating LMM robustness offer limited exploration of extremist content, often lacking AI-generated images, diverse image generation models, and comprehensive coverage of historical events, which hinders a complete assessment of model vulnerabilities. To fill this gap, we introduce ExtremeAIGC, a benchmark dataset and evaluation framework designed to assess LMM vulnerabilities against such content. ExtremeAIGC simulates real-world events and malicious use cases by curating diverse text- and image-based examples crafted using state-of-the-art image generation techniques. Our study reveals alarming weaknesses in LMMs, demonstrating that even cutting-edge safety measures fail to prevent the generation of extremist material. We systematically quantify the success rates of various attack strategies, exposing critical gaps in current defenses and emphasizing the need for more robust mitigation strategies.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.09964v1"
    },
    {
        "id": "2503.09433v1",
        "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection",
        "authors": [
            "Richard A. Dubniczky",
            "Krisztofer ZoltÃ¡n HorvÃ¡t",
            "TamÃ¡s Bisztray",
            "Mohamed Amine Ferrag",
            "Lucas C. Cordeiro",
            "Norbert Tihanyi"
        ],
        "published": "2025-03-12T14:30:05Z",
        "summary": "Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at https://github.com/CASTLE-Benchmark.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.09433v1"
    },
    {
        "id": "2503.09414v1",
        "title": "Mitigating Membership Inference Vulnerability in Personalized Federated Learning",
        "authors": [
            "Kangsoo Jung",
            "Sayan Biswas",
            "Catuscia Palamidessi"
        ],
        "published": "2025-03-12T14:10:35Z",
        "summary": "Federated Learning (FL) has emerged as a promising paradigm for collaborative model training without the need to share clients' personal data, thereby preserving privacy. However, the non-IID nature of the clients' data introduces major challenges for FL, highlighting the importance of personalized federated learning (PFL) methods. In PFL, models are trained to cater to specific feature distributions present in the population data. A notable method for PFL is the Iterative Federated Clustering Algorithm (IFCA), which mitigates the concerns associated with the non-IID-ness by grouping clients with similar data distributions. While it has been shown that IFCA enhances both accuracy and fairness, its strategy of dividing the population into smaller clusters increases vulnerability to Membership Inference Attacks (MIA), particularly among minorities with limited training samples. In this paper, we introduce IFCA-MIR, an improved version of IFCA that integrates MIA risk assessment into the clustering process. Allowing clients to select clusters based on both model performance and MIA vulnerability, IFCA-MIR achieves an improved performance with respect to accuracy, fairness, and privacy. We demonstrate that IFCA-MIR significantly reduces MIA risk while maintaining comparable model accuracy and fairness as the original IFCA.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.09414v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.10074v1",
        "title": "Demoting Security via Exploitation of Cache Demote Operation in Intel's Latest ISA Extension",
        "authors": [
            "Taehun Kim",
            "Hyerean Jang",
            "Youngjoo Shin"
        ],
        "published": "2025-03-13T05:43:14Z",
        "summary": "ISA extensions are increasingly adopted to boost the performance of specialized workloads without requiring an entire architectural redesign. However, these enhancements can inadvertently expose new attack surfaces in the microarchitecture. In this paper, we investigate Intel's recently introduced cldemote extension, which promotes efficient data sharing by transferring cache lines from upper-level caches to the Last Level Cache (LLC). Despite its performance benefits, we uncover critical properties-unprivileged access, inter-cache state transition, and fault suppression-that render cldemote exploitable for microarchitectural attacks. We propose two new attack primitives, Flush+Demote and Demote+Time, built on our analysis. Flush+Demote constructs a covert channel with a bandwidth of 2.84 Mbps and a bit error rate of 0.018%, while Demote+Time derandomizes the kernel base address in 2.49 ms on Linux. Furthermore, we show that leveraging cldemote accelerates eviction set construction in non-inclusive LLC designs by obviating the need for helper threads or extensive cache conflicts, thereby reducing construction time by 36% yet retaining comparable success rates. Finally, we examine how ISA extensions contribute to broader microarchitectural attacks, identifying five key exploitable characteristics and categorizing four distinct attack types. We also discuss potential countermeasures, highlighting the far-reaching security implications of emerging ISA extensions.",
        "field": "AI-Enhanced Financial Inclusion",
        "link": "http://arxiv.org/abs/2503.10074v1"
    },
    {
        "id": "2503.01591v1",
        "title": "The Role of Deep Learning in Financial Asset Management: A Systematic Review",
        "authors": [
            "Pedro Reis",
            "Ana Paula Serra",
            "JoÃ£o Gama"
        ],
        "published": "2025-03-03T14:29:13Z",
        "summary": "This review systematically examines deep learning applications in financial asset management. Unlike prior reviews, this study focuses on identifying emerging trends, such as the integration of explainable artificial intelligence (XAI) and deep reinforcement learning (DRL), and their transformative potential. It highlights new developments, including hybrid models (e.g., transformer-based architectures) and the growing use of alternative data sources such as ESG indicators and sentiment analysis. These advancements challenge traditional financial paradigms and set the stage for a deeper understanding of the evolving landscape. We use the Scopus database to select the most relevant articles published from 2018 to 2023. The inclusion criteria encompassed articles that explicitly apply deep learning models within financial asset management. We excluded studies focused on physical assets. This review also outlines our methodology for evaluating the relevance and impact of the included studies, including data sources and analytical methods. Our search identified 934 articles, with 612 meeting the inclusion criteria based on their focus and methodology. The synthesis of results from these articles provides insights into the effectiveness of deep learning models in improving portfolio performance and price forecasting accuracy. The review highlights the broad applicability and potential enhancements deep learning offers to financial asset management. Despite some limitations due to the scope of model application and variation in methodological rigour, the overall evidence supports deep learning as a valuable tool in this field. Our systematic review underscores the progressive integration of deep learning in financial asset management, suggesting a trajectory towards more sophisticated and impactful applications.",
        "field": "AI-Enhanced Financial Inclusion",
        "link": "http://arxiv.org/abs/2503.01591v1"
    },
    {
        "id": "2503.00358v1",
        "title": "CRUPL: A Semi-Supervised Cyber Attack Detection with Consistency Regularization and Uncertainty-aware Pseudo-Labeling in Smart Grid",
        "authors": [
            "Smruti P. Dash",
            "Kedar V. Khandeparkar",
            "Nipun Agrawal"
        ],
        "published": "2025-03-01T05:49:23Z",
        "summary": "The modern power grids are integrated with digital technologies and automation systems. The inclusion of digital technologies has made the smart grids vulnerable to cyber-attacks. Cyberattacks on smart grids can compromise data integrity and jeopardize the reliability of the power supply. Traditional intrusion detection systems often need help to effectively detect novel and sophisticated attacks due to their reliance on labeled training data, which may only encompass part of the spectrum of potential threats. This work proposes a semi-supervised method for cyber-attack detection in smart grids by leveraging the labeled and unlabeled measurement data. We implement consistency regularization and pseudo-labeling to identify deviations from expected behavior and predict the attack classes. We use a curriculum learning approach to improve pseudo-labeling performance, capturing the model uncertainty. We demonstrate the efficiency of the proposed method in detecting different types of cyberattacks, minimizing the false positives by implementing them on publicly available datasets. The method proposes a promising solution by improving the detection accuracy to 99% in the presence of unknown samples and significantly reducing false positives.",
        "field": "AI-Enhanced Financial Inclusion",
        "link": "http://arxiv.org/abs/2503.00358v1"
    },
    {
        "id": "2502.16086v1",
        "title": "Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack",
        "authors": [
            "Chenxi Dai",
            "Lin Lu",
            "Pan Zhou"
        ],
        "published": "2025-02-22T05:19:20Z",
        "summary": "Decentralized training has become a resource-efficient framework to democratize the training of large language models (LLMs). However, the privacy risks associated with this framework, particularly due to the potential inclusion of sensitive data in training datasets, remain unexplored. This paper identifies a novel and realistic attack surface: the privacy leakage from training data in decentralized training, and proposes \\textit{activation inversion attack} (AIA) for the first time. AIA first constructs a shadow dataset comprising text labels and corresponding activations using public datasets. Leveraging this dataset, an attack model can be trained to reconstruct the training data from activations in victim decentralized training. We conduct extensive experiments on various LLMs and publicly available datasets to demonstrate the susceptibility of decentralized training to AIA. These findings highlight the urgent need to enhance security measures in decentralized training to mitigate privacy risks in training LLMs.",
        "field": "AI-Enhanced Financial Inclusion",
        "link": "http://arxiv.org/abs/2502.16086v1"
    },
    {
        "id": "2502.15680v1",
        "title": "Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training",
        "authors": [
            "Jaydeep Borkar",
            "Matthew Jagielski",
            "Katherine Lee",
            "Niloofar Mireshghallah",
            "David A. Smith",
            "Christopher A. Choquette-Choo"
        ],
        "published": "2025-02-21T18:59:14Z",
        "summary": "Due to the sensitive nature of personally identifiable information (PII), its owners may have the authority to control its inclusion or request its removal from large-language model (LLM) training. Beyond this, PII may be added or removed from training datasets due to evolving dataset curation techniques, because they were newly scraped for retraining, or because they were included in a new downstream fine-tuning stage. We find that the amount and ease of PII memorization is a dynamic property of a model that evolves throughout training pipelines and depends on commonly altered design choices. We characterize three such novel phenomena: (1) similar-appearing PII seen later in training can elicit memorization of earlier-seen sequences in what we call assisted memorization, and this is a significant factor (in our settings, up to 1/3); (2) adding PII can increase memorization of other PII significantly (in our settings, as much as $\\approx\\!7.5\\times$); and (3) removing PII can lead to other PII being memorized. Model creators should consider these first- and second-order privacy risks when training models to avoid the risk of new PII regurgitation.",
        "field": "AI-Enhanced Financial Inclusion",
        "link": "http://arxiv.org/abs/2502.15680v1"
    },
    {
        "id": "2503.11053v1",
        "title": "Pricing American Parisian Options under General Time-Inhomogeneous Markov Models",
        "authors": [
            "Yuhao Liu",
            "Nian Yang",
            "Gongqiu Zhang"
        ],
        "published": "2025-03-14T03:45:18Z",
        "summary": "This paper develops general approaches for pricing various types of American-style Parisian options (down-in/-out, perpetual/finite-maturity) with general payoff functions based on continuous-time Markov chain (CTMC) approximation under general 1D time-inhomogeneous Markov models. For the down-in types, by conditioning on the Parisian stopping time, we reduce the pricing problem to that of a series of vanilla American options with different maturities and their prices integrated with the distribution function of the Parisian stopping time yield the American Parisian down-in option price. This facilitates an efficient application of CTMC approximation to obtain the approximate option price by calculating the required quantities. For the perpetual down-in cases under time-homogeneous models, significant computational cost can be reduced. The down-out cases are more complicated, for which we use the state augmentation approach to record the excursion duration and then the approximate option price is obtained by solving a series of variational inequalities recursively with the Lemke's pivoting method. We show the convergence of CTMC approximation for all the types of American Parisian options under general time-inhomogeneous Markov models, and the accuracy and efficiency of our algorithms are confirmed with extensive numerical experiments.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.11053v1"
    },
    {
        "id": "2503.09988v1",
        "title": "Label Unbalance in High-frequency Trading",
        "authors": [
            "Zijian Zhao",
            "Xuming Chen",
            "Jiayu Wen",
            "Mingwen Liu",
            "Xiaoteng Ma"
        ],
        "published": "2025-03-13T02:55:06Z",
        "summary": "In financial trading, return prediction is one of the foundation for a successful trading system. By the fast development of the deep learning in various areas such as graphical processing, natural language, it has also demonstrate significant edge in handling with financial data. While the success of the deep learning relies on huge amount of labeled sample, labeling each time/event as profitable or unprofitable, under the transaction cost, especially in the high-frequency trading world, suffers from serious label imbalance issue.In this paper, we adopts rigurious end-to-end deep learning framework with comprehensive label imbalance adjustment methods and succeed in predicting in high-frequency return in the Chinese future market. The code for our method is publicly available at https://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.09988v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2503.06707v1",
        "title": "Axes that matter: PCA with a difference",
        "authors": [
            "Brian Huge",
            "Antoine Savine"
        ],
        "published": "2025-03-09T17:47:25Z",
        "summary": "We extend the scope of differential machine learning and introduce a new breed of supervised principal component analysis to reduce dimensionality of Derivatives problems. Applications include the specification and calibration of pricing models, the identification of regression features in least-square Monte-Carlo, and the pre-processing of simulated datasets for (differential) machine learning.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.06707v1"
    },
    {
        "id": "2503.06279v1",
        "title": "Mitigating Blockchain extractable value (BEV) threats by Distributed Transaction Sequencing in Blockchains",
        "authors": [
            "Xiongfei Zhao",
            "Hou-Wan Long",
            "Zhengzhe Li",
            "Jiangchuan Liu",
            "Yain-Whar Si"
        ],
        "published": "2025-03-08T16:55:52Z",
        "summary": "The rapid growth of Blockchain and Decentralized Finance (DeFi) has introduced new challenges and vulnerabilities that threaten the integrity and efficiency of the ecosystem. This study identifies critical issues such as Transaction Order Dependence (TOD), Blockchain Extractable Value (BEV), and Transaction Importance Diversity (TID), which collectively undermine the fairness and security of DeFi systems. BEV-related activities, including Sandwich attacks, Liquidations, and Transaction Replay, have emerged as significant threats, collectively generating $540.54 million in losses over 32 months across 11,289 addresses, involving 49,691 cryptocurrencies and 60,830 on-chain markets. These attacks exploit transaction mechanics to manipulate asset prices and extract value at the expense of other participants, with Sandwich attacks being particularly impactful. Additionally, the growing adoption of Blockchain in traditional finance highlights the challenge of TID, where high transaction volumes can strain systems and compromise time-sensitive operations. To address these pressing issues, we propose a novel Distributed Transaction Sequencing Strategy (DTSS), which combines forking mechanisms and the Analytic Hierarchy Process (AHP) to enforce fair and transparent transaction ordering in a decentralized manner. Our approach is further enhanced by an optimization framework and the introduction of the Normalized Allocation Disparity Metric (NADM), which ensures optimal parameter selection for transaction prioritization. Experimental evaluations demonstrate that DTSS effectively mitigates BEV risks, enhances transaction fairness, and significantly improves the security and transparency of DeFi ecosystems. This work is essential for protecting the future of decentralized finance and promoting its integration into global financial systems.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.06279v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.09433v1",
        "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection",
        "authors": [
            "Richard A. Dubniczky",
            "Krisztofer ZoltÃ¡n HorvÃ¡t",
            "TamÃ¡s Bisztray",
            "Mohamed Amine Ferrag",
            "Lucas C. Cordeiro",
            "Norbert Tihanyi"
        ],
        "published": "2025-03-12T14:30:05Z",
        "summary": "Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at https://github.com/CASTLE-Benchmark.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.09433v1"
    },
    {
        "id": "2503.09375v1",
        "title": "Quantum Computing and Cybersecurity Education: A Novel Curriculum for Enhancing Graduate STEM Learning",
        "authors": [
            "Suryansh Upadhyay",
            "Koustubh Phalak",
            "Jungeun Lee",
            "Kathleen Mitchell Hill",
            "Swaroop Ghosh"
        ],
        "published": "2025-03-12T13:26:54Z",
        "summary": "Quantum computing is an emerging paradigm with the potential to transform numerous application areas by addressing problems considered intractable in the classical domain. However, its integration into cyberspace introduces significant security and privacy challenges. The exponential rise in cyber attacks, further complicated by quantum capabilities, poses serious risks to financial systems and national security. The scope of quantum threats extends beyond traditional software, operating system, and network vulnerabilities, necessitating a shift in cybersecurity education. Traditional cybersecurity education, often reliant on didactic methods, lacks hands on, student centered learning experiences necessary to prepare students for these evolving challenges. There is an urgent need for curricula that address both classical and quantum security threats through experiential learning. In this work, we present the design and evaluation of EE 597: Introduction to Hardware Security, a graduate level course integrating hands-on quantum security learning with classical security concepts through simulations and cloud-based quantum hardware. Unlike conventional courses focused on quantum threats to cryptographic systems, EE 597 explores security challenges specific to quantum computing itself. We employ a mixed-methods evaluation using pre and post surveys to assess student learning outcomes and engagement. Results indicate significant improvements in students' understanding of quantum and hardware security, with strong positive feedback on course structure and remote instruction (mean scores: 3.33 to 3.83 on a 4 point scale).",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.09375v1"
    },
    {
        "id": "2503.09334v1",
        "title": "CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs Using Cyber Security Data",
        "authors": [
            "Adel ElZemity",
            "Budi Arief",
            "Shujun Li"
        ],
        "published": "2025-03-12T12:29:27Z",
        "summary": "The integration of large language models (LLMs) into cyber security applications presents significant opportunities, such as enhancing threat analysis and malware detection, but can also introduce critical risks and safety concerns, including personal data leakage and automated generation of new malware. To address these challenges, we developed CyberLLMInstruct, a dataset of 54,928 instruction-response pairs spanning cyber security tasks such as malware analysis, phishing simulations, and zero-day vulnerabilities. The dataset was constructed through a multi-stage process. This involved sourcing data from multiple resources, filtering and structuring it into instruction-response pairs, and aligning it with real-world scenarios to enhance its applicability. Seven open-source LLMs were chosen to test the usefulness of CyberLLMInstruct: Phi 3 Mini 3.8B, Mistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B. In our primary example, we rigorously assess the safety of fine-tuned models using the OWASP top 10 framework, finding that fine-tuning reduces safety resilience across all tested LLMs and every adversarial attack (e.g., the security score of Llama 3.1 8B against prompt injection drops from 0.95 to 0.15). In our second example, we show that these same fine-tuned models can also achieve up to 92.50 percent accuracy on the CyberMetric benchmark. These findings highlight a trade-off between performance and safety, showing the importance of adversarial testing and further research into fine-tuning methodologies that can mitigate safety risks while still improving performance across diverse datasets and domains. All scripts required to reproduce the dataset, along with examples and relevant resources for replicating our results, will be made available upon the paper's acceptance.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.09334v1"
    },
    {
        "id": "2503.08908v1",
        "title": "Interpreting the Repeated Token Phenomenon in Large Language Models",
        "authors": [
            "Itay Yona",
            "Ilia Shumailov",
            "Jamie Hayes",
            "Federico Barbero",
            "Yossi Gandelsman"
        ],
        "published": "2025-03-11T21:40:58Z",
        "summary": "Large Language Models (LLMs), despite their impressive capabilities, often fail to accurately repeat a single word when prompted to, and instead output unrelated text. This unexplained failure mode represents a vulnerability, allowing even end-users to diverge models away from their intended behavior. We aim to explain the causes for this phenomenon and link it to the concept of ``attention sinks'', an emergent LLM behavior crucial for fluency, in which the initial token receives disproportionately high attention scores. Our investigation identifies the neural circuit responsible for attention sinks and shows how long repetitions disrupt this circuit. We extend this finding to other non-repeating sequences that exhibit similar circuit disruptions. To address this, we propose a targeted patch that effectively resolves the issue without negatively impacting the model's overall performance. This study provides a mechanistic explanation for an LLM vulnerability, demonstrating how interpretability can diagnose and address issues, and offering insights that pave the way for more secure and reliable models.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.08908v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.10239v1",
        "title": "I Can Tell Your Secrets: Inferring Privacy Attributes from Mini-app Interaction History in Super-apps",
        "authors": [
            "Yifeng Cai",
            "Ziqi Zhang",
            "Mengyu Yao",
            "Junlin Liu",
            "Xiaoke Zhao",
            "Xinyi Fu",
            "Ruoyu Li",
            "Zhe Li",
            "Xiangqun Chen",
            "Yao Guo",
            "Ding Li"
        ],
        "published": "2025-03-13T10:29:40Z",
        "summary": "Super-apps have emerged as comprehensive platforms integrating various mini-apps to provide diverse services. While super-apps offer convenience and enriched functionality, they can introduce new privacy risks. This paper reveals a new privacy leakage source in super-apps: mini-app interaction history, including mini-app usage history (Mini-H) and operation history (Op-H). Mini-H refers to the history of mini-apps accessed by users, such as their frequency and categories. Op-H captures user interactions within mini-apps, including button clicks, bar drags, and image views. Super-apps can naturally collect these data without instrumentation due to the web-based feature of mini-apps. We identify these data types as novel and unexplored privacy risks through a literature review of 30 papers and an empirical analysis of 31 super-apps. We design a mini-app interaction history-oriented inference attack (THEFT), to exploit this new vulnerability. Using THEFT, the insider threats within the low-privilege business department of the super-app vendor acting as the adversary can achieve more than 95.5% accuracy in inferring privacy attributes of over 16.1% of users. THEFT only requires a small training dataset of 200 users from public breached databases on the Internet. We also engage with super-app vendors and a standards association to increase industry awareness and commitment to protect this data. Our contributions are significant in identifying overlooked privacy risks, demonstrating the effectiveness of a new attack, and influencing industry practices toward better privacy protection in the super-app ecosystem.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.10239v1"
    },
    {
        "id": "2503.10238v1",
        "title": "Post Quantum Migration of Tor",
        "authors": [
            "Denis Berger",
            "Mouad Lemoudden",
            "William J Buchanan"
        ],
        "published": "2025-03-13T10:28:03Z",
        "summary": "Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as \\emph{harvest now, decrypt later} attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.10238v1"
    },
    {
        "id": "2503.11514v1",
        "title": "Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks",
        "authors": [
            "Pengxin Guo",
            "Runxi Wang",
            "Shuang Zeng",
            "Jinjing Zhu",
            "Haoning Jiang",
            "Yanran Wang",
            "Yuyin Zhou",
            "Feifei Wang",
            "Hui Xiong",
            "Liangqiong Qu"
        ],
        "published": "2025-03-13T08:08:44Z",
        "summary": "Federated Learning (FL) has emerged as a promising privacy-preserving collaborative model training paradigm without sharing raw data. However, recent studies have revealed that private information can still be leaked through shared gradient information and attacked by Gradient Inversion Attacks (GIA). While many GIA methods have been proposed, a detailed analysis, evaluation, and summary of these methods are still lacking. Although various survey papers summarize existing privacy attacks in FL, few studies have conducted extensive experiments to unveil the effectiveness of GIA and their associated limiting factors in this context. To fill this gap, we first undertake a systematic review of GIA and categorize existing methods into three types, i.e., \\textit{optimization-based} GIA (OP-GIA), \\textit{generation-based} GIA (GEN-GIA), and \\textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively analyze and evaluate the three types of GIA in FL, providing insights into the factors that influence their performance, practicality, and potential threats. Our findings indicate that OP-GIA is the most practical attack setting despite its unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA is easily detectable, making them both impractical. Finally, we offer a three-stage defense pipeline to users when designing FL frameworks and protocols for better privacy protection and share some future research directions from the perspectives of attackers and defenders that we believe should be pursued. We hope that our study can help researchers design more robust FL frameworks to defend against these attacks.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.11514v1"
    },
    {
        "id": "2503.09953v1",
        "title": "X-Cross: Image Encryption Featuring Novel Dual-Layer Block Permutation and Dynamic Substitution Techniques",
        "authors": [
            "Hansa Ahsan",
            "Safee Ullah",
            "Jawad Ahmad",
            "Aizaz Ahmad Khattak",
            "Muhammad Ali",
            "Muhammad Shahbaz Khan"
        ],
        "published": "2025-03-13T01:56:22Z",
        "summary": "In this digital age, ensuring the security of digital data, especially the image data is critically important. Image encryption plays an important role in securing the online transmission/storage of images from unauthorized access. In this regard, this paper presents a novel diffusion-confusion-based image encryption algorithm named as X-CROSS. The diffusion phase involves a dual-layer block permutation. It involves a bit-level permutation termed Inter-Bit Transference (IBT) using a Bit-Extraction key, and pixel permutation with a unique X-crosspermutation algorithm to effectively scramble the pixels within an image. The proposed algorithm utilizes a resilient 2D chaotic map with non-linear dynamical behavior, assisting in generating complex Extraction Keys. After the permutation phase, the confusion phase proceeds with a dynamic substitution technique on the permuted images, establishing the final encryption layer. This combination of novel permutation and confusion results in the removal of the image's inherent patterns and increases its resistance to cyber-attacks. The close to ideal statistical security results for information entropy, correlation, homogeneity, contrast, and energy validate the proposed scheme's effectiveness in hiding the information within the image.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.09953v1"
    },
    {
        "id": "2503.09939v1",
        "title": "A Chaotic Image Encryption Scheme Using Novel Geometric Block Permutation and Dynamic Substitution",
        "authors": [
            "Muhammad Ali",
            "Jawad Ahmad",
            "Muhammad Abdullah Hussain Khan",
            "Safee Ullah",
            "Mujeeb Ur Rehman",
            "Syed Aziz Shah",
            "Muhammad Shahbaz Khan"
        ],
        "published": "2025-03-13T01:25:04Z",
        "summary": "In this digital era, ensuring the security of digital data during transmission and storage is crucial. Digital data, particularly image data, needs to be protected against unauthorized access. To address this, this paper presents a novel image encryption scheme based on a confusion diffusion architecture. The diffusion module introduces a novel geometric block permutation technique, which effectively scrambles the pixels based on geometric shape extraction of pixels. The image is converted into four blocks, and pixels are extracted from these blocks using L-shape, U-shape, square-shape, and inverted U-shape patterns for each block, respectively. This robust extraction and permutation effectively disrupts the correlation within the image. Furthermore, the confusion module utilises bit-XOR and dynamic substitution techniques. For the bit-XOR operation, 2D Henon map has been utilised to generate a chaotic seed matrix, which is bit-XORed with the scrambled image. The resultant image then undergoes the dynamic substitution process to complete confusion phase. A statistical security analysis demonstrates the superior security of the proposed scheme, with being high uncertainty and unpredictability, achieving an entropy of 7.9974 and a correlation coefficient of 0.0014. These results validate the proposed scheme's effectiveness in securing digital images.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.09939v1"
    },
    {
        "id": "2503.09460v1",
        "title": "Automatic Association of Quality Requirements and Quantifiable Metrics for Cloud Security Certification",
        "authors": [
            "John Bianchi",
            "Shuya Dong",
            "Luca Petrillo",
            "Marinella Petrocchi"
        ],
        "published": "2025-03-12T15:06:45Z",
        "summary": "The European Cybersecurity Certification Scheme for Cloud Services (EUCS) is one of the first cybersecurity schemes in Europe, defined by the European Union Agency for Cybersecurity (ENISA). It aims to encourage cloud providers to strengthen their cybersecurity policies in order to receive an official seal of approval from European authorities. EUCS defines a set of security requirements that the cloud provider must meet, in whole or in part, in order to achieve the security certification. The requirements are written in natural language and cover every aspect of security in the cloud environment, from logging access to protecting the system with anti-malware tools to training staff. Operationally, each requirement is associated with one or more evaluable metrics. For example, a requirement to monitor access attempts to a service will have associated metrics that take into account the number of accesses, the number of access attempts, who is accessing, and what resources are being used. Partners in the European project Medina, which ended in October 2023, defined 163 metrics and manually mapped them to 70 EUCS requirements. Manual mapping is intuitively a long and costly process in terms of human resources. This paper proposes an approach based on Sentence Transformers to automatically associate requirements and metrics. In terms of correctness of associations, the proposed method achieves a Normalized Discounted Cumulative Gain of 0.640, improving a previous experiment by 0.146 points.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.09460v1"
    },
    {
        "id": "2503.08968v1",
        "title": "CIPHERMATCH: Accelerating Homomorphic Encryption-Based String Matching via Memory-Efficient Data Packing and In-Flash Processing",
        "authors": [
            "Mayank Kabra",
            "Rakesh Nadig",
            "Harshita Gupta",
            "Rahul Bera",
            "Manos Frouzakis",
            "Vamanan Arulchelvan",
            "Yu Liang",
            "Haiyu Mao",
            "Mohammad Sadrosadati",
            "Onur Mutlu"
        ],
        "published": "2025-03-12T00:25:58Z",
        "summary": "Homomorphic encryption (HE) allows secure computation on encrypted data without revealing the original data, providing significant benefits for privacy-sensitive applications. Many cloud computing applications (e.g., DNA read mapping, biometric matching, web search) use exact string matching as a key operation. However, prior string matching algorithms that use homomorphic encryption are limited by high computational latency caused by the use of complex operations and data movement bottlenecks due to the large encrypted data size. In this work, we provide an efficient algorithm-hardware codesign to accelerate HE-based secure exact string matching. We propose CIPHERMATCH, which (i) reduces the increase in memory footprint after encryption using an optimized software-based data packing scheme, (ii) eliminates the use of costly homomorphic operations (e.g., multiplication and rotation), and (iii) reduces data movement by designing a new in-flash processing (IFP) architecture. We demonstrate the benefits of CIPHERMATCH using two case studies: (1) Exact DNA string matching and (2) encrypted database search. Our pure software-based CIPHERMATCH implementation that uses our memory-efficient data packing scheme improves performance and reduces energy consumption by 42.9X and 17.6X, respectively, compared to the state-of-the-art software baseline. Integrating CIPHERMATCH with IFP improves performance and reduces energy consumption by 136.9X and 256.4X, respectively, compared to the software-based CIPHERMATCH implementation.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.08968v1"
    },
    {
        "id": "2503.07464v1",
        "title": "Learning to Localize Leakage of Cryptographic Sensitive Variables",
        "authors": [
            "Jimmy Gammell",
            "Anand Raghunathan",
            "Abolfazl Hashemi",
            "Kaushik Roy"
        ],
        "published": "2025-03-10T15:42:30Z",
        "summary": "While cryptographic algorithms such as the ubiquitous Advanced Encryption Standard (AES) are secure, *physical implementations* of these algorithms in hardware inevitably 'leak' sensitive data such as cryptographic keys. A particularly insidious form of leakage arises from the fact that hardware consumes power and emits radiation in a manner that is statistically associated with the data it processes and the instructions it executes. Supervised deep learning has emerged as a state-of-the-art tool for carrying out *side-channel attacks*, which exploit this leakage by learning to map power/radiation measurements throughout encryption to the sensitive data operated on during that encryption. In this work we develop a principled deep learning framework for determining the relative leakage due to measurements recorded at different points in time, in order to inform *defense* against such attacks. This information is invaluable to cryptographic hardware designers for understanding *why* their hardware leaks and how they can mitigate it (e.g. by indicating the particular sections of code or electronic components which are responsible). Our framework is based on an adversarial game between a family of classifiers trained to estimate the conditional distributions of sensitive data given subsets of measurements, and a budget-constrained noise distribution which probabilistically erases individual measurements to maximize the loss of these classifiers. We demonstrate our method's efficacy and ability to overcome limitations of prior work through extensive experimental comparison with 8 baseline methods using 3 evaluation metrics and 6 publicly-available power/EM trace datasets from AES, ECC and RSA implementations. We provide an open-source PyTorch implementation of these experiments.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.07464v1"
    },
    {
        "id": "2412.05321v1",
        "title": "Collaborative and parametric insurance on the Ethereum blockchain",
        "authors": [
            "Pierre-Olivier Goffard",
            "StÃ©phane Loisel"
        ],
        "published": "2024-12-03T20:03:40Z",
        "summary": "This paper introduces a blockchain-based insurance scheme that integrates parametric and collaborative elements. A pool of investors, referred to as surplus providers, locks funds in a smart contract, enabling blockchain users to underwrite parametric insurance contracts. These contracts automatically trigger compensation when predefined conditions are met. The collaborative aspect is embodied in the generation of tokens, which are distributed to both surplus providers and policyholders. These tokens represent each participant's share of the surplus and grant voting rights for management decisions. The smart contract is developed in Solidity, a high-level programming language for the Ethereum blockchain, and deployed on the Sepolia testnet, with data processing and analysis conducted using Python. In addition, open-source code is provided and main research challenges are identified, so that further research can be carried out to overcome limitations of this first proof of concept.",
        "field": "AI-Powered Loan Underwriting",
        "link": "http://arxiv.org/abs/2412.05321v1"
    },
    {
        "id": "2406.15197v1",
        "title": "Fiduciary Duty in the Municipal Bonds Market",
        "authors": [
            "Baridhi Malakar"
        ],
        "published": "2024-06-21T14:36:57Z",
        "summary": "I examine whether the imposition of fiduciary duty on municipal advisors affects bond yields and advising fees. Using a difference-in-differences analysis, I show that bond yields reduce by $\\sim$9\\% after the imposition of the SEC Municipal Advisor Rule due to lower underwriting spreads. Larger municipalities are more likely to recruit advisors after the rule is effective and experience a greater reduction in yields. However, smaller issuers do not experience a reduction in offering yields after the SEC Rule. Instead, their borrowing cost increases if their primary advisor exits the market. Using novel hand-collected data, I find that the average advising fees paid by issuers does not increase after the regulation. Overall, my results suggest that while fiduciary duty may mitigate the principal-agent problem between some issuers and advisors, there is heterogeneity among issuers.",
        "field": "AI-Powered Loan Underwriting",
        "link": "http://arxiv.org/abs/2406.15197v1"
    },
    {
        "id": "2307.05581v1",
        "title": "Exploring the Dynamics of the Specialty Insurance Market Using a Novel Discrete Event Simulation Framework: a Lloyd's of London Case Study",
        "authors": [
            "Sedar Olmez",
            "Akhil Ahmed",
            "Keith Kam",
            "Zhe Feng",
            "Alan Tua"
        ],
        "published": "2023-07-10T14:26:53Z",
        "summary": "This research presents a novel Discrete Event Simulation (DES) of the Lloyd's of London specialty insurance market, exploring complex market dynamics that have not been previously studied quantitatively. The proof-of-concept model allows for the simulation of various scenarios that capture important market phenomena such as the underwriting cycle, the impact of risk syndication, and the importance of appropriate exposure management. Despite minimal calibration, our model has shown that it is a valuable tool for understanding and analysing the Lloyd's of London specialty insurance market, particularly in terms of identifying areas for further investigation for regulators and participants of the market alike. The results generate the expected behaviours that, syndicates (insurers) are less likely to go insolvent if they adopt sophisticated exposure management practices, catastrophe events lead to more defined patterns of cyclicality and cause syndicates to substantially increase their premiums offered. Lastly, syndication enhances the accuracy of actuarial price estimates and narrows the divergence among syndicates. Overall, this research offers a new perspective on the Lloyd's of London market and demonstrates the potential of individual-based modelling (IBM) for understanding complex financial systems.",
        "field": "AI-Powered Loan Underwriting",
        "link": "http://arxiv.org/abs/2307.05581v1"
    },
    {
        "id": "2305.09961v2",
        "title": "Blockchain-enabled Parametric Solar Energy Insurance via Remote Sensing",
        "authors": [
            "Mingyu Hao",
            "Keyang Qian",
            "Sid Chi-Kin Chau"
        ],
        "published": "2023-05-17T05:41:35Z",
        "summary": "Despite its popularity, the nature of solar energy is highly uncertain and weather dependent, affecting the business viability and investment of solar energy generation, especially for household users. To stabilize the income from solar energy generation, there have been limited traditional options, such as using energy storage to pool excessive solar energy in off-peak periods or financial derivatives from future markets to hedge energy prices. In this paper, we explore a novel idea of \"parametric solar energy insurance\", by which solar panel owners can insure their solar energy generation based on a verifiable geographically specific index (surface solar irradiation). Parametric solar energy insurance offers opportunities of financial subsidies for insufficient solar energy generation and amortizes the fluctuations of renewable energy generation geographically. Furthermore, we propose to leverage blockchain and remote sensing (satellite imagery) to provide a publicly verifiable platform for solar energy insurance, which not only automates the underwriting and claims of a solar energy insurance policy, but also improves its accountability and transparency. We utilize the state-of-the-art succinct zero-knowledge proofs (zk-SNARK) to realize privacy-preserving blockchain-based solar energy insurance on real-world permissionless blockchain platform Ethereum.",
        "field": "AI-Powered Loan Underwriting",
        "link": "http://arxiv.org/abs/2305.09961v2"
    },
    {
        "id": "2305.08384v1",
        "title": "Privacy-preserving Blockchain-enabled Parametric Insurance via Remote Sensing and IoT",
        "authors": [
            "Mingyu Hao",
            "Keyang Qian",
            "Sid Chi-Kin Chau"
        ],
        "published": "2023-05-15T06:45:26Z",
        "summary": "Traditional Insurance, a popular approach of financial risk management, has suffered from the issues of high operational costs, opaqueness, inefficiency and a lack of trust. Recently, blockchain-enabled \"parametric insurance\" through authorized data sources (e.g., remote sensing and IoT) aims to overcome these issues by automating the underwriting and claim processes of insurance policies on a blockchain. However, the openness of blockchain platforms raises a concern of user privacy, as the private user data in insurance claims on a blockchain may be exposed to outsiders. In this paper, we propose a privacy-preserving parametric insurance framework based on succinct zero-knowledge proofs (zk-SNARKs), whereby an insuree submits a zero-knowledge proof (without revealing any private data) for the validity of an insurance claim and the authenticity of its data sources to a blockchain for transparent verification. Moreover, we extend the recent zk-SNARKs to support robust privacy protection for multiple heterogeneous data sources and improve its efficiency to cut the incurred gas cost by 80%. As a proof-of-concept, we implemented a working prototype of bushfire parametric insurance on real-world blockchain platform Ethereum, and present extensive empirical evaluations.",
        "field": "AI-Powered Loan Underwriting",
        "link": "http://arxiv.org/abs/2305.08384v1"
    },
    {
        "id": "2503.10619v1",
        "title": "Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search",
        "authors": [
            "Andy Zhou"
        ],
        "published": "2025-03-13T17:57:32Z",
        "summary": "We introduce Siege, a multi-turn adversarial framework that models the gradual erosion of Large Language Model (LLM) safety through a tree search perspective. Unlike single-turn jailbreaks that rely on one meticulously engineered prompt, Siege expands the conversation at each turn in a breadth-first fashion, branching out multiple adversarial prompts that exploit partial compliance from previous responses. By tracking these incremental policy leaks and re-injecting them into subsequent queries, Siege reveals how minor concessions can accumulate into fully disallowed outputs. Evaluations on the JailbreakBench dataset show that Siege achieves a 100% success rate on GPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries than baselines such as Crescendo or GOAT. This tree search methodology offers an in-depth view of how model safeguards degrade over successive dialogue turns, underscoring the urgency of robust multi-turn testing procedures for language models.",
        "field": "AI-Enhanced Regulatory Compliance",
        "link": "http://arxiv.org/abs/2503.10619v1"
    },
    {
        "id": "2503.08956v1",
        "title": "Leaky Batteries: A Novel Set of Side-Channel Attacks on Electric Vehicles",
        "authors": [
            "Francesco Marchiori",
            "Mauro Conti"
        ],
        "published": "2025-03-11T23:18:26Z",
        "summary": "Advancements in battery technology have accelerated the adoption of Electric Vehicles (EVs) due to their environmental benefits. However, their growing sophistication introduces security and privacy challenges. Often seen as mere operational data, battery consumption patterns can unintentionally reveal critical information exploitable for malicious purposes. These risks go beyond privacy, impacting vehicle security and regulatory compliance. Despite these concerns, current research has largely overlooked the broader implications of battery consumption data exposure. As EVs integrate further into smart transportation networks, addressing these gaps is crucial to ensure their safety, reliability, and resilience. In this work, we introduce a novel class of side-channel attacks that exploit EV battery data to extract sensitive user information. Leveraging only battery consumption patterns, we demonstrate a methodology to accurately identify the EV driver and their driving style, determine the number of occupants, and infer the vehicle's start and end locations when user habits are known. We utilize several machine learning models and feature extraction techniques to analyze EV power consumption patterns, validating our approach on simulated and real-world datasets collected from actual drivers. Our attacks achieve an average success rate of 95.4% across all attack objectives. Our findings highlight the privacy risks associated with EV battery data, emphasizing the need for stronger protections to safeguard user privacy and vehicle security.",
        "field": "AI-Enhanced Regulatory Compliance",
        "link": "http://arxiv.org/abs/2503.08956v1"
    },
    {
        "id": "2503.08568v1",
        "title": "Privacy Law Enforcement Under Centralized Governance: A Qualitative Analysis of Four Years' Special Privacy Rectification Campaigns",
        "authors": [
            "Tao Jing",
            "Yao Li",
            "Jingzhou Ye",
            "Jie Wang",
            "Xueqiang Wang"
        ],
        "published": "2025-03-11T15:56:09Z",
        "summary": "In recent years, major privacy laws like the GDPR have brought about positive changes. However, challenges remain in enforcing the laws, particularly due to under-resourced regulators facing a large number of potential privacy-violating software applications (apps) and the high costs of investigating them. Since 2019, China has launched a series of privacy enforcement campaigns known as Special Privacy Rectification Campaigns (SPRCs) to address widespread privacy violations in its mobile application (app) ecosystem. Unlike the enforcement of the GDPR, SPRCs are characterized by large-scale privacy reviews and strict sanctions, under the strong control of central authorities. In SPRCs, central government authorities issue administrative orders to mobilize various resources for market-wide privacy reviews of mobile apps. They enforce strict sanctions by requiring privacy-violating apps to rectify issues within a short timeframe or face removal from app stores. While there are a few reports on SPRCs, the effectiveness and potential problems of this campaign-style privacy enforcement approach remain unclear to the community. In this study, we conducted 18 semi-structured interviews with app-related engineers involved in SPRCs to better understand the campaign-style privacy enforcement. Based on the interviews, we reported our findings on a variety of aspects of SPRCs, such as the processes that app engineers regularly follow to achieve privacy compliance in SPRCs, the challenges they encounter, the solutions they adopt to address these challenges, and the impacts of SPRCs, etc. We found that app engineers face a series of challenges in achieving privacy compliance in their apps...",
        "field": "AI-Enhanced Regulatory Compliance",
        "link": "http://arxiv.org/abs/2503.08568v1"
    },
    {
        "id": "2503.08734v1",
        "title": "Zero-to-One IDV: A Conceptual Model for AI-Powered Identity Verification",
        "authors": [
            "Aniket Vaidya",
            "Anurag Awasthi"
        ],
        "published": "2025-03-11T04:20:02Z",
        "summary": "In today's increasingly digital interactions, robust Identity Verification (IDV) is crucial for security and trust. Artificial Intelligence (AI) is transforming IDV, enhancing accuracy and fraud detection. This paper introduces ``Zero to One,'' a holistic conceptual framework for developing AI-powered IDV products. This paper outlines the foundational problem and research objectives that necessitate a new framework for IDV in the age of AI. It details the evolution of identity verification and the current regulatory landscape to contextualize the need for a robust conceptual model. The core of the paper is the presentation of the ``Zero to One'' framework itself, dissecting its four essential components: Document Verification, Biometric Verification, Risk Assessment, and Orchestration. The paper concludes by discussing the implications of this conceptual model and suggesting future research directions focused on the framework's further development and application. The framework addresses security, privacy, UX, and regulatory compliance, offering a structured approach to building effective IDV solutions. Successful IDV platforms require a balanced conceptual understanding of verification methods, risk management, and operational scalability, with AI as a key enabler. This paper presents the ``Zero to One'' framework as a refined conceptual model, detailing verification layers, and AI's transformative role in shaping next-generation IDV products.",
        "field": "AI-Enhanced Regulatory Compliance",
        "link": "http://arxiv.org/abs/2503.08734v1"
    },
    {
        "id": "2503.07568v1",
        "title": "Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters",
        "authors": [
            "Habibur Rahaman",
            "Atri Chatterjee",
            "Swarup Bhunia"
        ],
        "published": "2025-03-10T17:38:42Z",
        "summary": "Rapid adoption of AI technologies raises several major security concerns, including the risks of adversarial perturbations, which threaten the confidentiality and integrity of AI applications. Protecting AI hardware from misuse and diverse security threats is a challenging task. To address this challenge, we propose SAMURAI, a novel framework for safeguarding against malicious usage of AI hardware and its resilience to attacks. SAMURAI introduces an AI Performance Counter (APC) for tracking dynamic behavior of an AI model coupled with an on-chip Machine Learning (ML) analysis engine, known as TANTO (Trained Anomaly Inspection Through Trace Observation). APC records the runtime profile of the low-level hardware events of different AI operations. Subsequently, the summary information recorded by the APC is processed by TANTO to efficiently identify potential security breaches and ensure secure, responsible use of AI. SAMURAI enables real-time detection of security threats and misuse without relying on traditional software-based solutions that require model integration. Experimental results demonstrate that SAMURAI achieves up to 97% accuracy in detecting adversarial attacks with moderate overhead on various AI models, significantly outperforming conventional software-based approaches. It enhances security and regulatory compliance, providing a comprehensive solution for safeguarding AI against emergent threats.",
        "field": "AI-Enhanced Regulatory Compliance",
        "link": "http://arxiv.org/abs/2503.07568v1"
    },
    {
        "id": "2503.10944v1",
        "title": "Phishsense-1B: A Technical Perspective on an AI-Powered Phishing Detection Model",
        "authors": [
            "SE Blake"
        ],
        "published": "2025-03-13T23:03:09Z",
        "summary": "Phishing is a persistent cybersecurity threat in today's digital landscape. This paper introduces Phishsense-1B, a refined version of the Llama-Guard-3-1B model, specifically tailored for phishing detection and reasoning. This adaptation utilizes Low-Rank Adaptation (LoRA) and the GuardReasoner finetuning methodology. We outline our LoRA-based fine-tuning process, describe the balanced dataset comprising phishing and benign emails, and highlight significant performance improvements over the original model. Our findings indicate that Phishsense-1B achieves an impressive 97.5% accuracy on a custom dataset and maintains strong performance with 70% accuracy on a challenging real-world dataset. This performance notably surpasses both unadapted models and BERT-based detectors. Additionally, we examine current state-of-the-art detection methods, compare prompt-engineering with fine-tuning strategies, and explore potential deployment scenarios.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.10944v1"
    },
    {
        "id": "2503.10081v1",
        "title": "AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial Attention Disruption",
        "authors": [
            "Joonsung Jeon",
            "Woo Jae Kim",
            "Suhyeon Ha",
            "Sooel Son",
            "Sung-eui Yoon"
        ],
        "published": "2025-03-13T06:05:40Z",
        "summary": "The outstanding capability of diffusion models in generating high-quality images poses significant threats when misused by adversaries. In particular, we assume malicious adversaries exploiting diffusion models for inpainting tasks, such as replacing a specific region with a celebrity. While existing methods for protecting images from manipulation in diffusion-based generative models have primarily focused on image-to-image and text-to-image tasks, the challenge of preventing unauthorized inpainting has been rarely addressed, often resulting in suboptimal protection performance. To mitigate inpainting abuses, we propose ADVPAINT, a novel defensive framework that generates adversarial perturbations that effectively disrupt the adversary's inpainting tasks. ADVPAINT targets the self- and cross-attention blocks in a target diffusion inpainting model to distract semantic understanding and prompt interactions during image generation. ADVPAINT also employs a two-stage perturbation strategy, dividing the perturbation region based on an enlarged bounding box around the object, enhancing robustness across diverse masks of varying shapes and sizes. Our experimental results demonstrate that ADVPAINT's perturbations are highly effective in disrupting the adversary's inpainting tasks, outperforming existing methods; ADVPAINT attains over a 100-point increase in FID and substantial decreases in precision.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.10081v1"
    },
    {
        "id": "2503.10063v1",
        "title": "Provably Secure Covert Messaging Using Image-based Diffusion Processes",
        "authors": [
            "Luke A. Bauer",
            "Wenxuan Bao",
            "Vincent Bindschaedler"
        ],
        "published": "2025-03-13T05:24:40Z",
        "summary": "We consider the problem of securely and robustly embedding covert messages into an image-based diffusion model's output. The sender and receiver want to exchange the maximum amount of information possible per diffusion sampled image while remaining undetected. The adversary wants to detect that such communication is taking place by identifying those diffusion samples that contain covert messages. To maximize robustness to transformations of the diffusion sample, a strategy is for the sender and the receiver to embed the message in the initial latents. We first show that prior work that attempted this is easily broken because their embedding technique alters the latents' distribution. We then propose a straightforward method to embed covert messages in the initial latent {\\em without} altering the distribution. We prove that our construction achieves indistinguishability to any probabilistic polynomial time adversary. Finally, we discuss and analyze empirically the tradeoffs between embedding capacity, message recovery rates, and robustness. We find that optimizing the inversion method for error correction is crucial for reliability.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.10063v1"
    },
    {
        "id": "2503.09964v1",
        "title": "ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist Content",
        "authors": [
            "Bhavik Chandna",
            "Mariam Aboujenane",
            "Usman Naseem"
        ],
        "published": "2025-03-13T02:10:29Z",
        "summary": "Large Multimodal Models (LMMs) are increasingly vulnerable to AI-generated extremist content, including photorealistic images and text, which can be used to bypass safety mechanisms and generate harmful outputs. However, existing datasets for evaluating LMM robustness offer limited exploration of extremist content, often lacking AI-generated images, diverse image generation models, and comprehensive coverage of historical events, which hinders a complete assessment of model vulnerabilities. To fill this gap, we introduce ExtremeAIGC, a benchmark dataset and evaluation framework designed to assess LMM vulnerabilities against such content. ExtremeAIGC simulates real-world events and malicious use cases by curating diverse text- and image-based examples crafted using state-of-the-art image generation techniques. Our study reveals alarming weaknesses in LMMs, demonstrating that even cutting-edge safety measures fail to prevent the generation of extremist material. We systematically quantify the success rates of various attack strategies, exposing critical gaps in current defenses and emphasizing the need for more robust mitigation strategies.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.09964v1"
    },
    {
        "id": "2503.09726v1",
        "title": "How Feasible is Augmenting Fake Nodes with Learnable Features as a Counter-strategy against Link Stealing Attacks?",
        "authors": [
            "Mir Imtiaz Mostafiz",
            "Imtiaz Karim",
            "Elisa Bertino"
        ],
        "published": "2025-03-12T18:16:37Z",
        "summary": "Graph Neural Networks (GNNs) are widely used and deployed for graph-based prediction tasks. However, as good as GNNs are for learning graph data, they also come with the risk of privacy leakage. For instance, an attacker can run carefully crafted queries on the GNNs and, from the responses, can infer the existence of an edge between a pair of nodes. This attack, dubbed as a \"link-stealing\" attack, can jeopardize the user's privacy by leaking potentially sensitive information. To protect against this attack, we propose an approach called \"$(N)$ode $(A)$ugmentation for $(R)$estricting $(G)$raphs from $(I)$nsinuating their $(S)$tructure\" ($NARGIS$) and study its feasibility. $NARGIS$ is focused on reshaping the graph embedding space so that the posterior from the GNN model will still provide utility for the prediction task but will introduce ambiguity for the link-stealing attackers. To this end, $NARGIS$ applies spectral clustering on the given graph to facilitate it being augmented with new nodes -- that have learned features instead of fixed ones. It utilizes tri-level optimization for learning parameters for the GNN model, surrogate attacker model, and our defense model (i.e. learnable node features). We extensively evaluate $NARGIS$ on three benchmark citation datasets over eight knowledge availability settings for the attackers. We also evaluate the model fidelity and defense performance on influence-based link inference attacks. Through our studies, we have figured out the best feature of $NARGIS$ -- its superior fidelity-privacy performance trade-off in a significant number of cases. We also have discovered in which cases the model needs to be improved, and proposed ways to integrate different schemes to make the model more robust against link stealing attacks.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.09726v1"
    },
    {
        "id": "2503.09712v1",
        "title": "Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain",
        "authors": [
            "Yuanmin Huang",
            "Mi Zhang",
            "Zhaoxiang Wang",
            "Wenxuan Li",
            "Min Yang"
        ],
        "published": "2025-03-12T18:05:32Z",
        "summary": "Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack. Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.09712v1"
    },
    {
        "id": "2503.09460v1",
        "title": "Automatic Association of Quality Requirements and Quantifiable Metrics for Cloud Security Certification",
        "authors": [
            "John Bianchi",
            "Shuya Dong",
            "Luca Petrillo",
            "Marinella Petrocchi"
        ],
        "published": "2025-03-12T15:06:45Z",
        "summary": "The European Cybersecurity Certification Scheme for Cloud Services (EUCS) is one of the first cybersecurity schemes in Europe, defined by the European Union Agency for Cybersecurity (ENISA). It aims to encourage cloud providers to strengthen their cybersecurity policies in order to receive an official seal of approval from European authorities. EUCS defines a set of security requirements that the cloud provider must meet, in whole or in part, in order to achieve the security certification. The requirements are written in natural language and cover every aspect of security in the cloud environment, from logging access to protecting the system with anti-malware tools to training staff. Operationally, each requirement is associated with one or more evaluable metrics. For example, a requirement to monitor access attempts to a service will have associated metrics that take into account the number of accesses, the number of access attempts, who is accessing, and what resources are being used. Partners in the European project Medina, which ended in October 2023, defined 163 metrics and manually mapped them to 70 EUCS requirements. Manual mapping is intuitively a long and costly process in terms of human resources. This paper proposes an approach based on Sentence Transformers to automatically associate requirements and metrics. In terms of correctness of associations, the proposed method achieves a Normalized Discounted Cumulative Gain of 0.640, improving a previous experiment by 0.146 points.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.09460v1"
    },
    {
        "id": "2503.08707v1",
        "title": "A Secure Blockchain-Assisted Framework for Real-Time Maritime Environmental Compliance Monitoring",
        "authors": [
            "William C. Quigley",
            "Mohamed Rahouti",
            "Gary M. Weiss"
        ],
        "published": "2025-03-10T00:38:34Z",
        "summary": "The maritime industry is governed by stringent environmental regulations, most notably the International Convention for the Prevention of Pollution from Ships (MARPOL). Ensuring compliance with these regulations is difficult due to low inspection rates and the risk of data fabrication. To address these issues, this paper proposes a secure blockchain-assisted framework for real-time maritime environmental compliance monitoring. By integrating IoT and shipboard sensors with blockchain technology, the framework ensures immutable and transparent record-keeping of environmental data. Smart contracts automate compliance verification and notify relevant authorities in case of non-compliance. A proof-of-concept case study on sulfur emissions demonstrates the framework's efficacy in enhancing MARPOL enforcement through real-time data integrity and regulatory adherence. The proposed system leverages the Polygon blockchain for scalability and efficiency, providing a robust solution for maritime environmental protection. The evaluation results demonstrate that the proposed blockchain-enhanced compliance monitoring system effectively and securely ensures real-time regulatory adherence with high scalability, efficiency, and cost-effectiveness, leveraging the robust capabilities of the Polygon blockchain.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.08707v1"
    },
    {
        "id": "2503.05045v1",
        "title": "Semi-Quantum Conference Key Agreement with GHZ-type states",
        "authors": [
            "RÃºben Barreiro",
            "Walter O. Krawec",
            "Paulo Mateus",
            "Nikola PaunkoviÄ",
            "AndrÃ© Souto"
        ],
        "published": "2025-03-06T23:45:21Z",
        "summary": "We propose a semi-quantum conference key agreement (SQCKA) protocol that leverages on GHZ states. We provide a comprehensive security analysis for our protocol that does not rely on a trusted mediator party. We present information-theoretic security proof, addressing collective attacks within the asymptotic limit of infinitely many rounds. This assumption is practical, as participants can monitor and abort the protocol if deviations from expected noise patterns occur. This advancement enhances the feasibility of SQCKA protocols for real-world applications, ensuring strong security without complex network topologies or third-party trust.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.05045v1"
    },
    {
        "id": "2503.04178v1",
        "title": "Unsupervised anomaly detection on cybersecurity data streams: a case with BETH dataset",
        "authors": [
            "Evgeniy Eremin"
        ],
        "published": "2025-03-06T07:45:48Z",
        "summary": "In modern world the importance of cybersecurity of various systems is increasing from year to year. The number of information security events generated by information security tools grows up with the development of the IT infrastructure. At the same time, the cyber threat landscape does not remain constant, and monitoring should take into account both already known attack indicators and those for which there are no signature rules in information security products of various classes yet. Detecting anomalies in large cybersecurity data streams is a complex task that, if properly addressed, can allow for timely response to atypical and previously unknown cyber threats. The possibilities of using of offline algorithms may be limited for a number of reasons related to the time of training and the frequency of retraining. Using stream learning algorithms for solving this task is capable of providing near-real-time data processing. This article examines the results of ten algorithms from three Python stream machine-learning libraries on BETH dataset with cybersecurity events, which contains information about the creation, cloning, and destruction of operating system processes collected using extended eBPF. ROC-AUC metric and total processing time of processing with these algorithms are presented. Several combinations of features and the order of events are considered. In conclusion, some mentions are given about the most promising algorithms and possible directions for further research are outlined.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.04178v1"
    },
    {
        "id": "2503.10809v1",
        "title": "Attacking Multimodal OS Agents with Malicious Image Patches",
        "authors": [
            "Lukas Aichberger",
            "Alasdair Paren",
            "Yarin Gal",
            "Philip Torr",
            "Adel Bibi"
        ],
        "published": "2025-03-13T18:59:12Z",
        "summary": "Recent advances in operating system (OS) agents enable vision-language models to interact directly with the graphical user interface of an OS. These multimodal OS agents autonomously perform computer-based tasks in response to a single prompt via application programming interfaces (APIs). Such APIs typically support low-level operations, including mouse clicks, keyboard inputs, and screenshot captures. We introduce a novel attack vector: malicious image patches (MIPs) that have been adversarially perturbed so that, when captured in a screenshot, they cause an OS agent to perform harmful actions by exploiting specific APIs. For instance, MIPs embedded in desktop backgrounds or shared on social media can redirect an agent to a malicious website, enabling further exploitation. These MIPs generalise across different user requests and screen layouts, and remain effective for multiple OS agents. The existence of such attacks highlights critical security vulnerabilities in OS agents, which should be carefully addressed before their widespread adoption.",
        "field": "AI-Enhanced Financial Literacy Programs",
        "link": "http://arxiv.org/abs/2503.10809v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Enhanced Financial Literacy Programs",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.09433v1",
        "title": "CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection",
        "authors": [
            "Richard A. Dubniczky",
            "Krisztofer ZoltÃ¡n HorvÃ¡t",
            "TamÃ¡s Bisztray",
            "Mohamed Amine Ferrag",
            "Lucas C. Cordeiro",
            "Norbert Tihanyi"
        ],
        "published": "2025-03-12T14:30:05Z",
        "summary": "Identifying vulnerabilities in source code is crucial, especially in critical software components. Existing methods such as static analysis, dynamic analysis, formal verification, and recently Large Language Models are widely used to detect security flaws. This paper introduces CASTLE (CWE Automated Security Testing and Low-Level Evaluation), a benchmarking framework for evaluating the vulnerability detection capabilities of different methods. We assess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using a hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs. We propose the CASTLE Score, a novel evaluation metric to ensure fair comparison. Our results reveal key differences: ESBMC (a formal verification tool) minimizes false positives but struggles with vulnerabilities beyond model checking, such as weak cryptography or SQL injection. Static analyzers suffer from high false positives, increasing manual validation efforts for developers. LLMs perform exceptionally well in the CASTLE dataset when identifying vulnerabilities in small code snippets. However, their accuracy declines, and hallucinations increase as the code size grows. These results suggest that LLMs could play a pivotal role in future security solutions, particularly within code completion frameworks, where they can provide real-time guidance to prevent vulnerabilities. The dataset is accessible at https://github.com/CASTLE-Benchmark.",
        "field": "AI-Enhanced Financial Literacy Programs",
        "link": "http://arxiv.org/abs/2503.09433v1"
    },
    {
        "id": "2503.08969v1",
        "title": "Large Language Models-Aided Program Debloating",
        "authors": [
            "Bo Lin",
            "Shangwen Wang",
            "Yihao Qin",
            "Liqian Chen",
            "Xiaoguang Mao"
        ],
        "published": "2025-03-12T00:30:51Z",
        "summary": "As software grows in complexity to accommodate diverse features and platforms, software bloating has emerged as a significant challenge, adversely affecting performance and security. However, existing approaches inadequately address the dual objectives of debloating: maintaining functionality by preserving essential features and enhancing security by reducing security issues. Specifically, current software debloating techniques often rely on input-based analysis, using user inputs as proxies for the specifications of desired features. However, these approaches frequently overfit provided inputs, leading to functionality loss and potential security vulnerabilities. To address these limitations, we propose LEADER, a program debloating framework enhanced by Large Language Models (LLMs), which leverages their semantic understanding, generative capabilities, and decision-making strengths. LEADER mainly consists of two modules: (1) a documentation-guided test augmentation module designed to preserve functionality, which leverages LLMs to comprehend program documentation and generates sufficient tests to cover the desired features comprehensively, and (2) a multi-advisor-aided program debloating module that employs a neuro-symbolic pipeline to ensure that the security of the software can be perceived during debloating. This module combines debloating and security advisors for analysis and employs an LLM as a decision-maker to eliminate undesired code securely. Extensive evaluations on widely used benchmarks demonstrate the efficacy of LEADER. These results demonstrate that LEADER surpasses the state-of-the-art tool CovA in functionality and security. These results underscore the potential of LEADER to set a new standard in program debloating by effectively balancing functionality and security.",
        "field": "AI-Enhanced Financial Literacy Programs",
        "link": "http://arxiv.org/abs/2503.08969v1"
    },
    {
        "id": "2503.07243v1",
        "title": "Beyond the Edge of Function: Unraveling the Patterns of Type Recovery in Binary Code",
        "authors": [
            "Gangyang Li",
            "Xiuwei Shang",
            "Shaoyin Cheng",
            "Junqi Zhang",
            "Li Hu",
            "Xu Zhu",
            "Weiming Zhang",
            "Nenghai Yu"
        ],
        "published": "2025-03-10T12:27:05Z",
        "summary": "Type recovery is a crucial step in binary code analysis, holding significant importance for reverse engineering and various security applications. Existing works typically simply target type identifiers within binary code and achieve type recovery by analyzing variable characteristics within functions. However, we find that the types in real-world binary programs are more complex and often follow specific distribution patterns. In this paper, to gain a profound understanding of the variable type recovery problem in binary code, we first conduct a comprehensive empirical study. We utilize the TYDA dataset, which includes 163,643 binary programs across four architectures and four compiler optimization options, fully reflecting the complexity and diversity of real-world programs. We carefully study the unique patterns that characterize types and variables in binary code, and also investigate the impact of compiler optimizations on them, yielding many valuable insights. Based on our empirical findings, we propose ByteTR, a framework for recovering variable types in binary code. We decouple the target type set to address the issue of unbalanced type distribution and perform static program analysis to tackle the impact of compiler optimizations on variable storage. In light of the ubiquity of variable propagation across functions observed in our study, ByteTR conducts inter-procedural analysis to trace variable propagation and employs a gated graph neural network to capture long-range data flow dependencies for variable type recovery. We conduct extensive experiments to evaluate the performance of ByteTR. The results demonstrate that ByteTR leads state-of-the-art works in both effectiveness and efficiency. Moreover, in real CTF challenge case, the pseudo code optimized by ByteTR significantly improves readability, surpassing leading tools IDA and Ghidra.",
        "field": "AI-Enhanced Financial Literacy Programs",
        "link": "http://arxiv.org/abs/2503.07243v1"
    },
    {
        "id": "2503.09823v1",
        "title": "Data Traceability for Privacy Alignment",
        "authors": [
            "Kevin Liao",
            "Shreya Thipireddy",
            "Daniel Weitzner"
        ],
        "published": "2025-03-12T20:42:23Z",
        "summary": "This paper offers a new privacy approach for the growing ecosystem of services--ranging from open banking to healthcare--dependent on sensitive personal data sharing between individuals and third-parties. While these services offer significant benefits, individuals want control over their data, transparency regarding how their data is used, and accountability from third-parties for misuse. However, existing legal and technical mechanisms are inadequate for supporting these needs. A comprehensive approach to the modern privacy challenges of accountable third-party data sharing requires a closer alignment of technical system architecture and legal institutional design. In order to achieve this privacy alignment, we extend traditional security threat modeling and analysis to encompass a broader range of privacy notions than has been typically considered. In particular, we introduce the concept of covert-accountability, which addresses adversaries that may act dishonestly but face potential identification and legal consequences. As a concrete instance of this design approach, we present the OTrace protocol, designed to provide traceable, accountable, consumer-control in third-party data sharing ecosystems. OTrace empowers consumers with the knowledge of where their data is, who has it, what it is being used for, and whom it is being shared with. By applying our alignment framework to OTrace, we demonstrate that OTrace's technical affordances can provide more confident, scalable regulatory oversight when combined with complementary legal mechanisms.",
        "field": "AI-Driven Customer Experience Personalization",
        "link": "http://arxiv.org/abs/2503.09823v1"
    },
    {
        "id": "2503.09669v1",
        "title": "Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models",
        "authors": [
            "Sangwon Jang",
            "June Suk Choi",
            "Jaehyeong Jo",
            "Kimin Lee",
            "Sung Ju Hwang"
        ],
        "published": "2025-03-12T17:21:57Z",
        "summary": "Text-to-image diffusion models have achieved remarkable success in generating high-quality contents from text prompts. However, their reliance on publicly available data and the growing trend of data sharing for fine-tuning make these models particularly vulnerable to data poisoning attacks. In this work, we introduce the Silent Branding Attack, a novel data poisoning method that manipulates text-to-image diffusion models to generate images containing specific brand logos or symbols without any text triggers. We find that when certain visual patterns are repeatedly in the training data, the model learns to reproduce them naturally in its outputs, even without prompt mentions. Leveraging this, we develop an automated data poisoning algorithm that unobtrusively injects logos into original images, ensuring they blend naturally and remain undetected. Models trained on this poisoned dataset generate images containing logos without degrading image quality or text alignment. We experimentally validate our silent branding attack across two realistic settings on large-scale high-quality image datasets and style personalization datasets, achieving high success rates even without a specific text trigger. Human evaluation and quantitative metrics including logo detection show that our method can stealthily embed logos.",
        "field": "AI-Driven Customer Experience Personalization",
        "link": "http://arxiv.org/abs/2503.09669v1"
    },
    {
        "id": "2503.09414v1",
        "title": "Mitigating Membership Inference Vulnerability in Personalized Federated Learning",
        "authors": [
            "Kangsoo Jung",
            "Sayan Biswas",
            "Catuscia Palamidessi"
        ],
        "published": "2025-03-12T14:10:35Z",
        "summary": "Federated Learning (FL) has emerged as a promising paradigm for collaborative model training without the need to share clients' personal data, thereby preserving privacy. However, the non-IID nature of the clients' data introduces major challenges for FL, highlighting the importance of personalized federated learning (PFL) methods. In PFL, models are trained to cater to specific feature distributions present in the population data. A notable method for PFL is the Iterative Federated Clustering Algorithm (IFCA), which mitigates the concerns associated with the non-IID-ness by grouping clients with similar data distributions. While it has been shown that IFCA enhances both accuracy and fairness, its strategy of dividing the population into smaller clusters increases vulnerability to Membership Inference Attacks (MIA), particularly among minorities with limited training samples. In this paper, we introduce IFCA-MIR, an improved version of IFCA that integrates MIA risk assessment into the clustering process. Allowing clients to select clusters based on both model performance and MIA vulnerability, IFCA-MIR achieves an improved performance with respect to accuracy, fairness, and privacy. We demonstrate that IFCA-MIR significantly reduces MIA risk while maintaining comparable model accuracy and fairness as the original IFCA.",
        "field": "AI-Driven Customer Experience Personalization",
        "link": "http://arxiv.org/abs/2503.09414v1"
    },
    {
        "id": "2503.09334v1",
        "title": "CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs Using Cyber Security Data",
        "authors": [
            "Adel ElZemity",
            "Budi Arief",
            "Shujun Li"
        ],
        "published": "2025-03-12T12:29:27Z",
        "summary": "The integration of large language models (LLMs) into cyber security applications presents significant opportunities, such as enhancing threat analysis and malware detection, but can also introduce critical risks and safety concerns, including personal data leakage and automated generation of new malware. To address these challenges, we developed CyberLLMInstruct, a dataset of 54,928 instruction-response pairs spanning cyber security tasks such as malware analysis, phishing simulations, and zero-day vulnerabilities. The dataset was constructed through a multi-stage process. This involved sourcing data from multiple resources, filtering and structuring it into instruction-response pairs, and aligning it with real-world scenarios to enhance its applicability. Seven open-source LLMs were chosen to test the usefulness of CyberLLMInstruct: Phi 3 Mini 3.8B, Mistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B. In our primary example, we rigorously assess the safety of fine-tuned models using the OWASP top 10 framework, finding that fine-tuning reduces safety resilience across all tested LLMs and every adversarial attack (e.g., the security score of Llama 3.1 8B against prompt injection drops from 0.95 to 0.15). In our second example, we show that these same fine-tuned models can also achieve up to 92.50 percent accuracy on the CyberMetric benchmark. These findings highlight a trade-off between performance and safety, showing the importance of adversarial testing and further research into fine-tuning methodologies that can mitigate safety risks while still improving performance across diverse datasets and domains. All scripts required to reproduce the dataset, along with examples and relevant resources for replicating our results, will be made available upon the paper's acceptance.",
        "field": "AI-Driven Customer Experience Personalization",
        "link": "http://arxiv.org/abs/2503.09334v1"
    },
    {
        "id": "2503.09192v1",
        "title": "Differential Privacy Personalized Federated Learning Based on Dynamically Sparsified Client Updates",
        "authors": [
            "Chuanyin Wang",
            "Yifei Zhang",
            "Neng Gao",
            "Qiang Luo"
        ],
        "published": "2025-03-12T09:34:05Z",
        "summary": "Personalized federated learning is extensively utilized in scenarios characterized by data heterogeneity, facilitating more efficient and automated local training on data-owning terminals. This includes the automated selection of high-performance model parameters for upload, thereby enhancing the overall training process. However, it entails significant risks of privacy leakage. Existing studies have attempted to mitigate these risks by utilizing differential privacy. Nevertheless, these studies present two major limitations: (1) The integration of differential privacy into personalized federated learning lacks sufficient personalization, leading to the introduction of excessive noise into the model. (2) It fails to adequately control the spatial scope of model update information, resulting in a suboptimal balance between data privacy and model effectiveness in differential privacy federated learning. In this paper, we propose a differentially private personalized federated learning approach that employs dynamically sparsified client updates through reparameterization and adaptive norm(DP-pFedDSU). Reparameterization training effectively selects personalized client update information, thereby reducing the quantity of updates. This approach minimizes the introduction of noise to the greatest extent possible. Additionally, dynamic adaptive norm refers to controlling the norm space of model updates during the training process, mitigating the negative impact of clipping on the update information. These strategies substantially enhance the effective integration of differential privacy and personalized federated learning. Experimental results on EMNIST, CIFAR-10, and CIFAR-100 demonstrate that our proposed scheme achieves superior performance and is well-suited for more complex personalized federated learning scenarios.",
        "field": "AI-Driven Customer Experience Personalization",
        "link": "http://arxiv.org/abs/2503.09192v1"
    },
    {
        "id": "2503.11216v1",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.11216v1"
    },
    {
        "id": "2503.10411v1",
        "title": "Public Channel-Based Fair Exchange Protocols with Advertising",
        "authors": [
            "Pierpaolo Della Monica",
            "Ivan Visconti",
            "Andrea Vitaletti",
            "Marco Zecchini"
        ],
        "published": "2025-03-13T14:35:32Z",
        "summary": "Before a fair exchange takes place, there is typically an advertisement phase with the goal of increasing the appeal of possessing a digital asset while keeping it sufficiently hidden. In this work, we give a definition that explicitly combines a fair-exchange protocol with a prior advertising phase. Then, we construct such a fair exchange protocol with aids using zk-SNARKs and relying on mainstream decentralized platforms (i.e., a blockchain with smart contracts like Ethereum and a decentralized storage system like IPFS). Experimental results confirm the practical relevance of our decentralized approach, paving the road towards building decentralized marketplaces where users can, even anonymously, and without direct off-chain communications, effectively advertise and exchange their digital assets as part of a system of enhanced NFTs.",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.10411v1"
    },
    {
        "id": "2503.10239v1",
        "title": "I Can Tell Your Secrets: Inferring Privacy Attributes from Mini-app Interaction History in Super-apps",
        "authors": [
            "Yifeng Cai",
            "Ziqi Zhang",
            "Mengyu Yao",
            "Junlin Liu",
            "Xiaoke Zhao",
            "Xinyi Fu",
            "Ruoyu Li",
            "Zhe Li",
            "Xiangqun Chen",
            "Yao Guo",
            "Ding Li"
        ],
        "published": "2025-03-13T10:29:40Z",
        "summary": "Super-apps have emerged as comprehensive platforms integrating various mini-apps to provide diverse services. While super-apps offer convenience and enriched functionality, they can introduce new privacy risks. This paper reveals a new privacy leakage source in super-apps: mini-app interaction history, including mini-app usage history (Mini-H) and operation history (Op-H). Mini-H refers to the history of mini-apps accessed by users, such as their frequency and categories. Op-H captures user interactions within mini-apps, including button clicks, bar drags, and image views. Super-apps can naturally collect these data without instrumentation due to the web-based feature of mini-apps. We identify these data types as novel and unexplored privacy risks through a literature review of 30 papers and an empirical analysis of 31 super-apps. We design a mini-app interaction history-oriented inference attack (THEFT), to exploit this new vulnerability. Using THEFT, the insider threats within the low-privilege business department of the super-app vendor acting as the adversary can achieve more than 95.5% accuracy in inferring privacy attributes of over 16.1% of users. THEFT only requires a small training dataset of 200 users from public breached databases on the Internet. We also engage with super-app vendors and a standards association to increase industry awareness and commitment to protect this data. Our contributions are significant in identifying overlooked privacy risks, demonstrating the effectiveness of a new attack, and influencing industry practices toward better privacy protection in the super-app ecosystem.",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.10239v1"
    },
    {
        "id": "2503.10058v1",
        "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
        "authors": [
            "Jiani Fan",
            "Lwin Khin Shar",
            "Ruichen Zhang",
            "Ziyao Liu",
            "Wenzhuo Yang",
            "Dusit Niyato",
            "Bomin Mao",
            "Kwok-Yan Lam"
        ],
        "published": "2025-03-13T05:19:44Z",
        "summary": "Money laundering is a financial crime that obscures the origin of illicit funds, necessitating the development and enforcement of anti-money laundering (AML) policies by governments and organizations. The proliferation of mobile payment platforms and smart IoT devices has significantly complicated AML investigations. As payment networks become more interconnected, there is an increasing need for efficient real-time detection to process large volumes of transaction data on heterogeneous payment systems by different operators such as digital currencies, cryptocurrencies and account-based payments. Most of these mobile payment networks are supported by connected devices, many of which are considered loT devices in the FinTech space that constantly generate data. Furthermore, the growing complexity and unpredictability of transaction patterns across these networks contribute to a higher incidence of false positives. While machine learning solutions have the potential to enhance detection efficiency, their application in AML faces unique challenges, such as addressing privacy concerns tied to sensitive financial data and managing the real-world constraint of limited data availability due to data regulations. Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML. Additionally, we propose a novel framework that applies the least-privilege principle by integrating machine learning techniques, codifying AML red flags, and employing account profiling to provide context for predictions and enable effective fraud detection under limited data availability....",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.10058v1"
    },
    {
        "id": "2503.09513v1",
        "title": "RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment",
        "authors": [
            "Md Morshed Alam",
            "Lokesh Chandra Das",
            "Sandip Roy",
            "Sachin Shetty",
            "Weichao Wang"
        ],
        "published": "2025-03-12T16:23:14Z",
        "summary": "Internet of Things (IoT) platforms with trigger-action capability allow event conditions to trigger actions in IoT devices autonomously by creating a chain of interactions. Adversaries exploit this chain of interactions to maliciously inject fake event conditions into IoT hubs, triggering unauthorized actions on target IoT devices to implement remote injection attacks. Existing defense mechanisms focus mainly on the verification of event transactions using physical event fingerprints to enforce the security policies to block unsafe event transactions. These approaches are designed to provide offline defense against injection attacks. The state-of-the-art online defense mechanisms offer real-time defense, but extensive reliability on the inference of attack impacts on the IoT network limits the generalization capability of these approaches. In this paper, we propose a platform-independent multi-agent online defense system, namely RESTRAIN, to counter remote injection attacks at runtime. RESTRAIN allows the defense agent to profile attack actions at runtime and leverages reinforcement learning to optimize a defense policy that complies with the security requirements of the IoT network. The experimental results show that the defense agent effectively takes real-time defense actions against complex and dynamic remote injection attacks and maximizes the security gain with minimal computational overhead.",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.09513v1"
    },
    {
        "id": "2503.04218v1",
        "title": "Hedging with Sparse Reward Reinforcement Learning",
        "authors": [
            "Yiheng Ding",
            "Gangnan Yuan",
            "Dewei Zuo",
            "Ting Gao"
        ],
        "published": "2025-03-06T08:53:28Z",
        "summary": "Derivatives, as a critical class of financial instruments, isolate and trade the price attributes of risk assets such as stocks, commodities, and indices, aiding risk management and enhancing market efficiency. However, traditional hedging models, constrained by assumptions such as continuous trading and zero transaction costs, fail to satisfy risk control requirements in complex and uncertain real-world markets. With advances in computing technology and deep learning, data-driven trading strategies are becoming increasingly prevalent. This thesis proposes a derivatives hedging framework integrating deep learning and reinforcement learning. The framework comprises a probabilistic forecasting model and a hedging agent, enabling market probability prediction, derivative pricing, and hedging. Specifically, we design a spatiotemporal attention-based probabilistic financial time series forecasting Transformer to address the scarcity of derivatives hedging data. A low-rank attention mechanism compresses high-dimensional assets into a low-dimensional latent space, capturing nonlinear asset relationships. The Transformer models sequential dependencies within this latent space, improving market probability forecasts and constructing an online training environment for downstream hedging tasks. Additionally, we incorporate generalized geometric Brownian motion to develop a risk-neutral pricing approach for derivatives. We model derivatives hedging as a reinforcement learning problem with sparse rewards and propose a behavior cloning-based recurrent proximal policy optimization (BC-RPPO) algorithm. This pretraining-finetuning framework significantly enhances the hedging agent's performance. Numerical experiments in the U.S. and Chinese financial markets demonstrate our method's superiority over traditional approaches.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.04218v1"
    },
    {
        "id": "2503.08696v1",
        "title": "Multimodal Stock Price Prediction: A Case Study of the Russian Securities Market",
        "authors": [
            "Kasymkhan Khubiev",
            "Mikhail Semenov"
        ],
        "published": "2025-03-05T21:20:32Z",
        "summary": "Classical asset price forecasting methods primarily rely on numerical data, such as price time series, trading volumes, limit order book data, and technical analysis indicators. However, the news flow plays a significant role in price formation, making the development of multimodal approaches that combine textual and numerical data for improved prediction accuracy highly relevant. This paper addresses the problem of forecasting financial asset prices using the multimodal approach that combines candlestick time series and textual news flow data. A unique dataset was collected for the study, which includes time series for 176 Russian stocks traded on the Moscow Exchange and 79,555 financial news articles in Russian. For processing textual data, pre-trained models RuBERT and Vikhr-Qwen2.5-0.5b-Instruct (a large language model) were used, while time series and vectorized text data were processed using an LSTM recurrent neural network. The experiments compared models based on a single modality (time series only) and two modalities, as well as various methods for aggregating text vector representations. Prediction quality was estimated using two key metrics: Accuracy (direction of price movement prediction: up or down) and Mean Absolute Percentage Error (MAPE), which measures the deviation of the predicted price from the true price. The experiments showed that incorporating textual modality reduced the MAPE value by 55%. The resulting multimodal dataset holds value for the further adaptation of language models in the financial sector. Future research directions include optimizing textual modality parameters, such as the time window, sentiment, and chronological order of news messages.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.08696v1"
    },
    {
        "id": "2503.03612v2",
        "title": "Large language models in finance : what is financial sentiment?",
        "authors": [
            "Kemal Kirtac",
            "Guido Germano"
        ],
        "published": "2025-03-05T15:51:25Z",
        "summary": "Financial sentiment has become a crucial yet complex concept in finance, increasingly used in market forecasting and investment strategies. Despite its growing importance, there remains a need to define and understand what financial sentiment truly represents and how it can be effectively measured. We explore the nature of financial sentiment and investigate how large language models (LLMs) contribute to its estimation. We trace the evolution of sentiment measurement in finance, from market-based and lexicon-based methods to advanced natural language processing techniques. The emergence of LLMs has significantly enhanced sentiment analysis, providing deeper contextual understanding and greater accuracy in extracting sentiment from financial text. We examine how BERT-based models, such as RoBERTa and FinBERT, are optimized for structured sentiment classification, while GPT-based models, including GPT-4, OPT, and LLaMA, excel in financial text generation and real-time sentiment interpretation. A comparative analysis of bidirectional and autoregressive transformer architectures highlights their respective roles in investor sentiment analysis, algorithmic trading, and financial decision-making. By exploring what financial sentiment is and how it is estimated within LLMs, we provide insights into the growing role of AI-driven sentiment analysis in finance.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.03612v2"
    },
    {
        "id": "2503.01591v1",
        "title": "The Role of Deep Learning in Financial Asset Management: A Systematic Review",
        "authors": [
            "Pedro Reis",
            "Ana Paula Serra",
            "JoÃ£o Gama"
        ],
        "published": "2025-03-03T14:29:13Z",
        "summary": "This review systematically examines deep learning applications in financial asset management. Unlike prior reviews, this study focuses on identifying emerging trends, such as the integration of explainable artificial intelligence (XAI) and deep reinforcement learning (DRL), and their transformative potential. It highlights new developments, including hybrid models (e.g., transformer-based architectures) and the growing use of alternative data sources such as ESG indicators and sentiment analysis. These advancements challenge traditional financial paradigms and set the stage for a deeper understanding of the evolving landscape. We use the Scopus database to select the most relevant articles published from 2018 to 2023. The inclusion criteria encompassed articles that explicitly apply deep learning models within financial asset management. We excluded studies focused on physical assets. This review also outlines our methodology for evaluating the relevance and impact of the included studies, including data sources and analytical methods. Our search identified 934 articles, with 612 meeting the inclusion criteria based on their focus and methodology. The synthesis of results from these articles provides insights into the effectiveness of deep learning models in improving portfolio performance and price forecasting accuracy. The review highlights the broad applicability and potential enhancements deep learning offers to financial asset management. Despite some limitations due to the scope of model application and variation in methodological rigour, the overall evidence supports deep learning as a valuable tool in this field. Our systematic review underscores the progressive integration of deep learning in financial asset management, suggesting a trajectory towards more sophisticated and impactful applications.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.01591v1"
    },
    {
        "id": "2502.20978v2",
        "title": "Using quantile time series and historical simulation to forecast financial risk multiple steps ahead",
        "authors": [
            "Richard Gerlach",
            "Antonio Naimoli",
            "Giuseppe Storti"
        ],
        "published": "2025-02-28T11:48:35Z",
        "summary": "A method for quantile-based, semi-parametric historical simulation estimation of multiple step ahead Value-at-Risk (VaR) and Expected Shortfall (ES) models is developed. It uses the quantile loss function, analogous to how the quasi-likelihood is employed by standard historical simulation methods. The returns data are scaled by the estimated quantile series, then resampling is employed to estimate the forecast distribution one and multiple steps ahead, allowing tail risk forecasting. The proposed method is applicable to any data or model where the relationship between VaR and ES does not change over time and can be extended to allow a measurement equation incorporating realized measures, thus including Realized GARCH and Realized CAViaR type models. Its finite sample properties, and its comparison with existing historical simulation methods, are evaluated via a simulation study. A forecasting study assesses the relative accuracy of the 1% and 2.5% VaR and ES one-day-ahead and ten-day-ahead forecasting results for the proposed class of models compared to several competitors.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2502.20978v2"
    },
    {
        "id": "2503.10945v1",
        "title": "$(\\varepsilon, Î´)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees",
        "authors": [
            "Juan Felipe Gomez",
            "Bogdan Kulynych",
            "Georgios Kaissis",
            "Jamie Hayes",
            "Borja Balle",
            "Antti Honkela"
        ],
        "published": "2025-03-13T23:06:30Z",
        "summary": "Current practices for reporting the level of differential privacy (DP) guarantees for machine learning (ML) algorithms provide an incomplete and potentially misleading picture of the guarantees and make it difficult to compare privacy levels across different settings. We argue for using Gaussian differential privacy (GDP) as the primary means of communicating DP guarantees in ML, with the full privacy profile as a secondary option in case GDP is too inaccurate. Unlike other widely used alternatives, GDP has only one parameter, which ensures easy comparability of guarantees, and it can accurately capture the full privacy profile of many important ML applications. To support our claims, we investigate the privacy profiles of state-of-the-art DP large-scale image classification, and the TopDown algorithm for the U.S. Decennial Census, observing that GDP fits the profiles remarkably well in all three cases. Although GDP is ideal for reporting the final guarantees, other formalisms (e.g., privacy loss random variables) are needed for accurate privacy accounting. We show that such intermediate representations can be efficiently converted to GDP with minimal loss in tightness.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.10945v1"
    },
    {
        "id": "2503.10846v1",
        "title": "WAFFLED: Exploiting Parsing Discrepancies to Bypass Web Application Firewalls",
        "authors": [
            "Seyed Ali Akhavani",
            "Bahruz Jabiyev",
            "Ben Kallus",
            "Cem Topcuoglu",
            "Sergey Bratus",
            "Engin Kirda"
        ],
        "published": "2025-03-13T19:56:29Z",
        "summary": "Web Application Firewalls (WAFs) have been introduced as essential and popular security gates that inspect incoming HTTP traffic to filter out malicious requests and provide defenses against a diverse array of web-based threats. Evading WAFs can compromise these defenses, potentially harming Internet users. In recent years, parsing discrepancies have plagued many entities in the communication path; however, their potential impact on WAF evasion and request smuggling remains largely unexplored. In this work, we present an innovative approach to bypassing WAFs by uncovering and exploiting parsing discrepancies through advanced fuzzing techniques. By targeting non-malicious components such as headers and segments of the body and using widely used content-types such as application/json, multipart/form-data, and application/xml, we identified and confirmed 1207 bypasses across 5 well-known WAFs, AWS, Azure, Cloud Armor, Cloudflare, and ModSecurity. To validate our findings, we conducted a study in the wild, revealing that more than 90% of websites accepted both form/x-www-form-urlencoded and multipart/form-data interchangeably, highlighting a significant vulnerability and the broad applicability of our bypass techniques. We have reported these vulnerabilities to the affected parties and received acknowledgments from all, as well as bug bounty rewards from some vendors. Further, to mitigate these vulnerabilities, we introduce HTTP-Normalizer, a robust proxy tool designed to rigorously validate HTTP requests against current RFC standards. Our results demonstrate its effectiveness in normalizing or blocking all bypass attempts presented in this work.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.10846v1"
    },
    {
        "id": "2503.10793v1",
        "title": "HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust",
        "authors": [
            "Yu Luo",
            "Han Zhou",
            "Mengtao Zhang",
            "Dylan De La Rosa",
            "Hafsa Ahmed",
            "Weifeng Xu",
            "Dianxiang Xu"
        ],
        "published": "2025-03-13T18:38:34Z",
        "summary": "As an emerging programming language, Rust has rapidly gained popularity and recognition among developers due to its strong emphasis on safety. It employs a unique ownership system and safe concurrency practices to ensure robust safety. Despite these safeguards, security in Rust still presents challenges. Since 2018, 442 Rust-related vulnerabilities have been reported in real-world applications. The limited availability of data has resulted in existing vulnerability detection tools performing poorly in real-world scenarios, often failing to adapt to new and complex vulnerabilities. This paper introduces HALURust, a novel framework that leverages hallucinations of large language models (LLMs) to detect vulnerabilities in real-world Rust scenarios. HALURust leverages LLMs' strength in natural language generation by transforming code into detailed vulnerability analysis reports. The key innovation lies in prompting the LLM to always assume the presence of a vulnerability. If the code sample is vulnerable, the LLM provides an accurate analysis; if not, it generates a hallucinated report. By fine-tuning LLMs on these hallucinations, HALURust can effectively distinguish between vulnerable and non-vulnerable code samples. HALURust was evaluated on a dataset of 81 real-world vulnerabilities, covering 447 functions and 18,691 lines of code across 54 applications. It outperformed existing methods, achieving an F1 score of 77.3%, with over 10% improvement. The hallucinated report-based fine-tuning improved detection by 20\\% compared to traditional code-based fine-tuning. Additionally, HALURust effectively adapted to unseen vulnerabilities and other programming languages, demonstrating strong generalization capabilities.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.10793v1"
    },
    {
        "id": "2503.09988v1",
        "title": "Label Unbalance in High-frequency Trading",
        "authors": [
            "Zijian Zhao",
            "Xuming Chen",
            "Jiayu Wen",
            "Mingwen Liu",
            "Xiaoteng Ma"
        ],
        "published": "2025-03-13T02:55:06Z",
        "summary": "In financial trading, return prediction is one of the foundation for a successful trading system. By the fast development of the deep learning in various areas such as graphical processing, natural language, it has also demonstrate significant edge in handling with financial data. While the success of the deep learning relies on huge amount of labeled sample, labeling each time/event as profitable or unprofitable, under the transaction cost, especially in the high-frequency trading world, suffers from serious label imbalance issue.In this paper, we adopts rigurious end-to-end deep learning framework with comprehensive label imbalance adjustment methods and succeed in predicting in high-frequency return in the Chinese future market. The code for our method is publicly available at https://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.09988v1"
    },
    {
        "id": "2503.09934v1",
        "title": "A Pharmacy Benefit Manager Insurance Business Model",
        "authors": [
            "Lawrence W. Abrams"
        ],
        "published": "2025-03-13T01:13:16Z",
        "summary": "It is time to move on from attempts to make the pharmacy benefit manager (PBM) reseller business model more transparent. Time and time again the Big 3 PBMs have developed opaque alternatives to piece-meal 100% pass-through mandates. Time and time again PBMs have demonstrated expertise in finding loopholes in state government disclosure laws. The purpose of this paper is to provide quantitative estimates of two transparent insurance business models as a solution to the PBM agency issue. The key parameter used is an 8% gross profit margin figure disclosed by the Big 3 PBMs themselves. Based on reported drug trend delivered to plans, we use a $1,200 to $1,500 per member per year (PMPY) as the range for this key performance indicator (KPI). We propose that discussions of PBM insurance business models start with the following figures: (1) a fixed premium model with medical loss ratio ranging from 92% to 85%; (2) a fee-for-service model ranging from $96 to $180 PMPY with risk sharing of deviations from a contracted PMPY delivered drug spend.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.09934v1"
    },
    {
        "id": "2502.20555v1",
        "title": "Robust Multicast Origin Authentication in MACsec and CANsec for Automotive Scenarios",
        "authors": [
            "Gianluca Cena",
            "Lucia Seno",
            "Stefano Scanzio"
        ],
        "published": "2025-02-27T21:55:08Z",
        "summary": "Having everything interconnected through the Internet, including vehicle onboard systems, is making security a primary concern in the automotive domain as well. Although Ethernet and CAN XL provide link-level security based on symmetric cryptography, they do not support origin authentication for multicast transmissions. Asymmetric cryptography is unsuitable for networked embedded control systems with real-time constraints and limited computational resources. In these cases, solutions derived from the TESLA broadcast authentication protocol may constitute a more suitable option. In this paper, some such strategies are presented and analyzed that allow for multicast origin authentication, also improving robustness to frame losses by means of interleaved keychains. A flexible authentication mechanism that relies on a unified receiver is then proposed, which enables transmitters to select strategies at runtime, to achieve the best compromise among security, reliability, and resource consumption.",
        "field": "AI-Driven Customer Onboarding",
        "link": "http://arxiv.org/abs/2502.20555v1"
    },
    {
        "id": "2502.17653v1",
        "title": "Formally-verified Security against Forgery of Remote Attestation using SSProve",
        "authors": [
            "Sara Zain",
            "Jannik MÃ¤hn",
            "Stefan KÃ¶psell",
            "Sebastian Ertel"
        ],
        "published": "2025-02-24T21:02:56Z",
        "summary": "Remote attestation (RA) is the foundation for trusted execution environments in the cloud and trusted device driver onboarding in operating systems. However, RA misses a rigorous mechanized definition of its security properties in one of the strongest models, i.e., the semantic model. Such a mechanization requires the concept of State-Separating Proofs (SSP). However, SSP was only recently implemented as a foundational framework in the Rocq Prover. Based on this framework, this paper presents the first mechanized formalization of the fundamental security properties of RA. Our Rocq Prover development first defines digital signatures and formally verifies security against forgery in the strong existential attack model. Based on these results, we define RA and reduce the security of RA to the security of digital signatures. Our development provides evidence that the RA protocol is secure against forgery. Additionally, we extend our reasoning to the primitives of RA and reduce their security to the security of the primitives of the digital signatures. Finally, we found that proving the security of the primitives for digital signatures was not feasible. This observation contrasts textbook formalizations and sparks a discussion on reasoning about the security of libraries in SSP-based frameworks.",
        "field": "AI-Driven Customer Onboarding",
        "link": "http://arxiv.org/abs/2502.17653v1"
    },
    {
        "id": "2502.16375v1",
        "title": "Personhood Credentials: Human-Centered Design Recommendation Balancing Security, Usability, and Trust",
        "authors": [
            "Ayae Ide",
            "Tanusree Sharma"
        ],
        "published": "2025-02-22T22:33:00Z",
        "summary": "Building on related concepts, like, decentralized identifiers (DIDs), proof of personhood, anonymous credentials, personhood credentials (PHCs) emerged as an alternative approach, enabling individuals to verify to digital service providers that they are a person without disclosing additional information. However, new technologies might introduce some friction due to users misunderstandings and mismatched expectations. Despite their growing importance, limited research has been done on users perceptions and preferences regarding PHCs. To address this gap, we conducted competitive analysis, and semi-structured online user interviews with 23 participants from US and EU to provide concrete design recommendations for PHCs that incorporate user needs, adoption rules, and preferences. Our study -- (a)surfaces how people reason about unknown privacy and security guarantees of PHCs compared to current verification methods -- (b) presents the impact of several factors on how people would like to onboard and manage PHCs, including, trusted issuers (e.g. gov), ground truth data to issue PHC (e.g biometrics, physical id), and issuance system (e.g. centralized vs decentralized). In a think-aloud conceptual design session, participants recommended -- conceptualized design, such as periodic biometrics verification, time-bound credentials, visually interactive human-check, and supervision of government for issuance system. We propose actionable designs reflecting users preferences.",
        "field": "AI-Driven Customer Onboarding",
        "link": "http://arxiv.org/abs/2502.16375v1"
    },
    {
        "id": "2502.03868v2",
        "title": "Time-based GNSS attack detection",
        "authors": [
            "Marco Spanghero",
            "Panos Papadimitratos"
        ],
        "published": "2025-02-06T08:28:41Z",
        "summary": "To safeguard Civilian Global Navigation Satellite Systems (GNSS) external information available to the platform encompassing the GNSS receiver can be used to detect attacks. Cross-checking the GNSS-provided time against alternative multiple trusted time sources can lead to attack detection aiming at controlling the GNSS receiver time. Leveraging external, network-connected secure time providers and onboard clock references, we achieve detection even under fine-grained time attacks. We provide an extensive evaluation of our multi-layered defense against adversaries mounting attacks against the GNSS receiver along with controlling the network link. We implement adversaries spanning from simplistic spoofers to advanced ones synchronized with the GNSS constellation. We demonstrate attack detection is possible in all tested cases (sharp discontinuity, smooth take-over, and coordinated network manipulation) without changes to the structure of the GNSS receiver. Leveraging the diversity of the reference time sources, detection of take-over time push as low as 150us is possible. Smooth take-overs forcing variations as low as 30ns are also detected based on on-board precision oscillators. The method (and thus the evaluation) is largely agnostic to the satellite constellation and the attacker type, making time-based data validation of GNSS information compatible with existing receivers and readily deployable.",
        "field": "AI-Driven Customer Onboarding",
        "link": "http://arxiv.org/abs/2502.03868v2"
    },
    {
        "id": "2502.05220v1",
        "title": "Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making",
        "authors": [
            "Balakrishnan Dharmalingam",
            "Rajdeep Mukherjee",
            "Brett Piggott",
            "Guohuan Feng",
            "Anyi Liu"
        ],
        "published": "2025-02-05T15:46:27Z",
        "summary": "Increased utilization of unmanned aerial vehicles (UAVs) in critical operations necessitates secure and reliable communication with Ground Control Stations (GCS). This paper introduces Aero-LLM, a framework integrating multiple Large Language Models (LLMs) to enhance UAV mission security and operational efficiency. Unlike conventional singular LLMs, Aero-LLM leverages multiple specialized LLMs for various tasks, such as inferencing, anomaly detection, and forecasting, deployed across onboard systems, edge, and cloud servers. This dynamic, distributed architecture reduces performance bottleneck and increases security capabilities. Aero-LLM's evaluation demonstrates outstanding task-specific metrics and robust defense against cyber threats, significantly enhancing UAV decision-making and operational capabilities and security resilience against cyber attacks, setting a new standard for secure, intelligent UAV operations.",
        "field": "AI-Driven Customer Onboarding",
        "link": "http://arxiv.org/abs/2502.05220v1"
    },
    {
        "id": "2501.17748v1",
        "title": "Investigating Vulnerability Disclosures in Open-Source Software Using Bug Bounty Reports and Security Advisories",
        "authors": [
            "Jessy Ayala",
            "Yu-Jye Tung",
            "Joshua Garcia"
        ],
        "published": "2025-01-29T16:36:41Z",
        "summary": "In the world of open-source software (OSS), the number of known vulnerabilities has tremendously increased. The GitHub Advisory Database contains advisories for security risks in GitHub-hosted OSS projects. As of 09/25/2023, there are 197,609 unreviewed GitHub security advisories. Of those unreviewed, at least 63,852 are publicly documented vulnerabilities, potentially leaving many OSS projects vulnerable. Recently, bug bounty platforms have emerged to focus solely on providing bounties to help secure OSS. In this paper, we conduct an empirical study on 3,798 reviewed GitHub security advisories and 4,033 disclosed OSS bug bounty reports, a perspective that is currently understudied, because they contain comprehensive information about security incidents, e.g., the nature of vulnerabilities, their impact, and how they were resolved. We are the first to determine the explicit process describing how OSS vulnerabilities propagate from security advisories and bug bounty reports, which are the main intermediaries between vulnerability reporters, OSS maintainers, and dependent projects, to vulnerable OSS projects and entries in global vulnerability databases and possibly back. This process uncovers how missing or delayed CVE assignments for OSS vulnerabilities result in projects, both in and out of OSS, not being notified of necessary security updates promptly and corresponding bottlenecks. Based on our findings, we provide suggestions, actionable items, and future research directions to help improve the security posture of OSS projects.",
        "field": "AI-Enhanced Investment Advisory",
        "link": "http://arxiv.org/abs/2501.17748v1"
    },
    {
        "id": "2412.08068v1",
        "title": "Repository-Level Graph Representation Learning for Enhanced Security Patch Detection",
        "authors": [
            "Xin-Cheng Wen",
            "Zirui Lin",
            "Cuiyun Gao",
            "Hongyu Zhang",
            "Yong Wang",
            "Qing Liao"
        ],
        "published": "2024-12-11T03:29:56Z",
        "summary": "Software vendors often silently release security patches without providing sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed updates via resources (e.g., National Vulnerability Database). Therefore, it has become crucial to detect these security patches to ensure secure software maintenance. However, existing methods face the following challenges: (1) They primarily focus on the information within the patches themselves, overlooking the complex dependencies in the repository. (2) Security patches typically involve multiple functions and files, increasing the difficulty in well learning the representations. To alleviate the above challenges, this paper proposes a Repository-level Security Patch Detection framework named RepoSPD, which comprises three key components: 1) a repository-level graph construction, RepoCPG, which represents software patches by merging pre-patch and post-patch source code at the repository level; 2) a structure-aware patch representation, which fuses the graph and sequence branch and aims at comprehending the relationship among multiple code changes; 3) progressive learning, which facilitates the model in balancing semantic and structural information. To evaluate RepoSPD, we employ two widely-used datasets in security patch detection: SPI-DB and PatchDB. We further extend these datasets to the repository level, incorporating a total of 20,238 and 28,781 versions of repository in C/C++ programming languages, respectively, denoted as SPI-DB* and PatchDB*. We compare RepoSPD with six existing security patch detection methods and five static tools. Our experimental results demonstrate that RepoSPD outperforms the state-of-the-art baseline, with improvements of 11.90%, and 3.10% in terms of accuracy on the two datasets, respectively.",
        "field": "AI-Enhanced Investment Advisory",
        "link": "http://arxiv.org/abs/2412.08068v1"
    },
    {
        "id": "2409.07669v2",
        "title": "A Mixed-Methods Study of Open-Source Software Maintainers On Vulnerability Management and Platform Security Features",
        "authors": [
            "Jessy Ayala",
            "Yu-Jye Tung",
            "Joshua Garcia"
        ],
        "published": "2024-09-12T00:15:03Z",
        "summary": "In open-source software (OSS), software vulnerabilities have significantly increased. Although researchers have investigated the perspectives of vulnerability reporters and OSS contributor security practices, understanding the perspectives of OSS maintainers on vulnerability management and platform security features is currently understudied. In this paper, we investigate the perspectives of OSS maintainers who maintain projects listed in the GitHub Advisory Database. We explore this area by conducting two studies: identifying aspects through a listing survey ($n_1=80$) and gathering insights from semi-structured interviews ($n_2=22$). Of the 37 identified aspects, we find that supply chain mistrust and lack of automation for vulnerability management are the most challenging, and barriers to adopting platform security features include a lack of awareness and the perception that they are not necessary. Surprisingly, we find that despite being previously vulnerable, some maintainers still allow public vulnerability reporting, or ignore reports altogether. Based on our findings, we discuss implications for OSS platforms and how the research community can better support OSS vulnerability management efforts.",
        "field": "AI-Enhanced Investment Advisory",
        "link": "http://arxiv.org/abs/2409.07669v2"
    },
    {
        "id": "2408.14937v1",
        "title": "From Chaos to Consistency: The Role of CSAF in Streamlining Security Advisories",
        "authors": [
            "Julia Wunder",
            "Janik Aurich",
            "Zinaida Benenson"
        ],
        "published": "2024-08-27T10:22:59Z",
        "summary": "Security advisories have become an important part of vulnerability management. They can be used to gather and distribute valuable information about vulnerabilities. Although there is a predefined broad format for advisories, it is not really standardized. As a result, their content and form vary greatly depending on the vendor. Thus, it is cumbersome and resource-intensive for security analysts to extract the relevant information. The Common Security Advisory Format (CSAF) aims to bring security advisories into a standardized format which is intended to solve existing problems and to enable automated processing of the advisories. However, a new standard only makes sense if it can benefit users. Hence the questions arise: Do security advisories cause issues in their current state? Which of these issues is CSAF able to resolve? What is the current state of automation? To investigate these questions, we interviewed three security experts, and then conducted an online survey with 197 participants. The results show that problems exist and can often be traced back to confusing and inconsistent structures and formats. CSAF attempts to solve precisely these problems. However, our results show that CSAF is currently rarely used. Although users perceive automation as necessary to improve the processing of security advisories, many are at the same time skeptical. One of the main reasons is that systems are not yet designed for automation and a migration would require vast amounts of resources.",
        "field": "AI-Enhanced Investment Advisory",
        "link": "http://arxiv.org/abs/2408.14937v1"
    },
    {
        "id": "2408.10695v2",
        "title": "On NVD Users' Attitudes, Experiences, Hopes and Hurdles",
        "authors": [
            "Julia Wunder",
            "Alan Corona",
            "Andreas Hammer",
            "Zinaida Benenson"
        ],
        "published": "2024-08-20T09:46:53Z",
        "summary": "The National Vulnerability Database (NVD) is a major vulnerability database that is free to use for everyone. It provides information about vulnerabilities and further useful resources such as linked advisories and patches. The NVD is often considered as the central source for vulnerability information and as a help to improve the resource-intensive process of vulnerability management. Although the NVD receives much public attention, little is known about its usage in vulnerability management, users' attitudes towards it and whether they encounter any problems during usage. We explored these questions using a preliminary interview study with seven people, and a follow-up survey with 71 participants. The results show that the NVD is consulted regularly and often aids decision making. Generally, users are positive about the NVD and perceive it as a helpful, clearly structured tool. But users also faced issues: missing or incorrect entries, incomplete descriptions or incomprehensible CVSS ratings. In order to identify the problems origins, we discussed the results with two senior NVD members. Many of the problems can be attributed to higher-level problems such as the CVE List or limited resources. Nevertheless, the NVD is working on improving existing problems.",
        "field": "AI-Enhanced Investment Advisory",
        "link": "http://arxiv.org/abs/2408.10695v2"
    },
    {
        "id": "2503.09712v1",
        "title": "Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain",
        "authors": [
            "Yuanmin Huang",
            "Mi Zhang",
            "Zhaoxiang Wang",
            "Wenxuan Li",
            "Min Yang"
        ],
        "published": "2025-03-12T18:05:32Z",
        "summary": "Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack. Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.09712v1"
    },
    {
        "id": "2503.09460v1",
        "title": "Automatic Association of Quality Requirements and Quantifiable Metrics for Cloud Security Certification",
        "authors": [
            "John Bianchi",
            "Shuya Dong",
            "Luca Petrillo",
            "Marinella Petrocchi"
        ],
        "published": "2025-03-12T15:06:45Z",
        "summary": "The European Cybersecurity Certification Scheme for Cloud Services (EUCS) is one of the first cybersecurity schemes in Europe, defined by the European Union Agency for Cybersecurity (ENISA). It aims to encourage cloud providers to strengthen their cybersecurity policies in order to receive an official seal of approval from European authorities. EUCS defines a set of security requirements that the cloud provider must meet, in whole or in part, in order to achieve the security certification. The requirements are written in natural language and cover every aspect of security in the cloud environment, from logging access to protecting the system with anti-malware tools to training staff. Operationally, each requirement is associated with one or more evaluable metrics. For example, a requirement to monitor access attempts to a service will have associated metrics that take into account the number of accesses, the number of access attempts, who is accessing, and what resources are being used. Partners in the European project Medina, which ended in October 2023, defined 163 metrics and manually mapped them to 70 EUCS requirements. Manual mapping is intuitively a long and costly process in terms of human resources. This paper proposes an approach based on Sentence Transformers to automatically associate requirements and metrics. In terms of correctness of associations, the proposed method achieves a Normalized Discounted Cumulative Gain of 0.640, improving a previous experiment by 0.146 points.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.09460v1"
    },
    {
        "id": "2503.08707v1",
        "title": "A Secure Blockchain-Assisted Framework for Real-Time Maritime Environmental Compliance Monitoring",
        "authors": [
            "William C. Quigley",
            "Mohamed Rahouti",
            "Gary M. Weiss"
        ],
        "published": "2025-03-10T00:38:34Z",
        "summary": "The maritime industry is governed by stringent environmental regulations, most notably the International Convention for the Prevention of Pollution from Ships (MARPOL). Ensuring compliance with these regulations is difficult due to low inspection rates and the risk of data fabrication. To address these issues, this paper proposes a secure blockchain-assisted framework for real-time maritime environmental compliance monitoring. By integrating IoT and shipboard sensors with blockchain technology, the framework ensures immutable and transparent record-keeping of environmental data. Smart contracts automate compliance verification and notify relevant authorities in case of non-compliance. A proof-of-concept case study on sulfur emissions demonstrates the framework's efficacy in enhancing MARPOL enforcement through real-time data integrity and regulatory adherence. The proposed system leverages the Polygon blockchain for scalability and efficiency, providing a robust solution for maritime environmental protection. The evaluation results demonstrate that the proposed blockchain-enhanced compliance monitoring system effectively and securely ensures real-time regulatory adherence with high scalability, efficiency, and cost-effectiveness, leveraging the robust capabilities of the Polygon blockchain.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.08707v1"
    },
    {
        "id": "2503.05045v1",
        "title": "Semi-Quantum Conference Key Agreement with GHZ-type states",
        "authors": [
            "RÃºben Barreiro",
            "Walter O. Krawec",
            "Paulo Mateus",
            "Nikola PaunkoviÄ",
            "AndrÃ© Souto"
        ],
        "published": "2025-03-06T23:45:21Z",
        "summary": "We propose a semi-quantum conference key agreement (SQCKA) protocol that leverages on GHZ states. We provide a comprehensive security analysis for our protocol that does not rely on a trusted mediator party. We present information-theoretic security proof, addressing collective attacks within the asymptotic limit of infinitely many rounds. This assumption is practical, as participants can monitor and abort the protocol if deviations from expected noise patterns occur. This advancement enhances the feasibility of SQCKA protocols for real-world applications, ensuring strong security without complex network topologies or third-party trust.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.05045v1"
    },
    {
        "id": "2503.04178v1",
        "title": "Unsupervised anomaly detection on cybersecurity data streams: a case with BETH dataset",
        "authors": [
            "Evgeniy Eremin"
        ],
        "published": "2025-03-06T07:45:48Z",
        "summary": "In modern world the importance of cybersecurity of various systems is increasing from year to year. The number of information security events generated by information security tools grows up with the development of the IT infrastructure. At the same time, the cyber threat landscape does not remain constant, and monitoring should take into account both already known attack indicators and those for which there are no signature rules in information security products of various classes yet. Detecting anomalies in large cybersecurity data streams is a complex task that, if properly addressed, can allow for timely response to atypical and previously unknown cyber threats. The possibilities of using of offline algorithms may be limited for a number of reasons related to the time of training and the frequency of retraining. Using stream learning algorithms for solving this task is capable of providing near-real-time data processing. This article examines the results of ten algorithms from three Python stream machine-learning libraries on BETH dataset with cybersecurity events, which contains information about the creation, cloning, and destruction of operating system processes collected using extended eBPF. ROC-AUC metric and total processing time of processing with these algorithms are presented. Several combinations of features and the order of events are considered. In conclusion, some mentions are given about the most promising algorithms and possible directions for further research are outlined.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.04178v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12648v1",
        "title": "Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning",
        "authors": [
            "Andreas Teller",
            "Uta Pigorsch",
            "Christian Pigorsch"
        ],
        "published": "2025-03-16T20:56:44Z",
        "summary": "Forecasting the volatility of financial assets is essential for various financial applications. This paper addresses the challenging task of forecasting the volatility of financial assets with limited historical data, such as new issues or spin-offs, by proposing a multi-source transfer learning approach. Specifically, we exploit complementary source data of assets with a substantial historical data record by selecting source time series instances that are most similar to the limited target data of the new issue/spin-off. Based on these instances and the target data, we estimate linear and non-linear realized volatility models and compare their forecasting performance to forecasts of models trained exclusively on the target data, and models trained on the entire source and target data. The results show that our transfer learning approach outperforms the alternative models and that the integration of complementary data is also beneficial immediately after the initial trading day of the new issue/spin-off.",
        "field": "Quantum Computing",
        "link": "http://arxiv.org/abs/2503.12648v1"
    },
    {
        "id": "2503.11940v1",
        "title": "Vote Delegation in DeFi Governance",
        "authors": [
            "Dion Bongaerts",
            "Thomas Lambert",
            "Daniel Liebau",
            "Peter Roosenboom"
        ],
        "published": "2025-03-15T01:15:08Z",
        "summary": "We investigate the drivers of vote delegation in Decentralized Autonomous Organizations (DAOs), using the Uniswap governance DAO as a laboratory. We show that parties with fewer self-owned votes and those affiliated with the controlling venture capital firm, Andreesen Horowitz (a16z), receive more vote delegations. These patterns suggest that while the Uniswap ecosystem values decentralization, a16z may engage in window-dressing around it. Moreover, we find that an active and successful track record in submitting improvement proposals, especially in the final stage, leads to more vote delegations, indicating that delegation in DAOs is at least partly reputation- or merit-based. Combined, our findings provide new insights into how governance and decentralization operate in DeFi.",
        "field": "Decentralized Finance (DeFi)",
        "link": "http://arxiv.org/abs/2503.11940v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "RegTech (Regulatory Technology)",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "Digital Identity Verification",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12648v1",
        "title": "Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning",
        "authors": [
            "Andreas Teller",
            "Uta Pigorsch",
            "Christian Pigorsch"
        ],
        "published": "2025-03-16T20:56:44Z",
        "summary": "Forecasting the volatility of financial assets is essential for various financial applications. This paper addresses the challenging task of forecasting the volatility of financial assets with limited historical data, such as new issues or spin-offs, by proposing a multi-source transfer learning approach. Specifically, we exploit complementary source data of assets with a substantial historical data record by selecting source time series instances that are most similar to the limited target data of the new issue/spin-off. Based on these instances and the target data, we estimate linear and non-linear realized volatility models and compare their forecasting performance to forecasts of models trained exclusively on the target data, and models trained on the entire source and target data. The results show that our transfer learning approach outperforms the alternative models and that the integration of complementary data is also beneficial immediately after the initial trading day of the new issue/spin-off.",
        "field": "Neuromorphic Computing",
        "link": "http://arxiv.org/abs/2503.12648v1"
    },
    {
        "id": "2503.13224v1",
        "title": "ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction",
        "authors": [
            "Tong Zhou",
            "Shijin Duan",
            "Gaowen Liu",
            "Charles Fleming",
            "Ramana Rao Kompella",
            "Shaolei Ren",
            "Xiaolin Xu"
        ],
        "published": "2025-03-17T14:37:42Z",
        "summary": "Pre-trained models are valuable intellectual property, capturing both domain-specific and domain-invariant features within their weight spaces. However, model extraction attacks threaten these assets by enabling unauthorized source-domain inference and facilitating cross-domain transfer via the exploitation of domain-invariant features. In this work, we introduce **ProDiF**, a novel framework that leverages targeted weight space manipulation to secure pre-trained models against extraction attacks. **ProDiF** quantifies the transferability of filters and perturbs the weights of critical filters in unsecured memory, while preserving actual critical weights in a Trusted Execution Environment (TEE) for authorized users. A bi-level optimization further ensures resilience against adaptive fine-tuning attacks. Experimental results show that **ProDiF** reduces source-domain accuracy to near-random levels and decreases cross-domain transferability by 74.65\\%, providing robust protection for pre-trained models. This work offers comprehensive protection for pre-trained DNN models and highlights the potential of weight space manipulation as a novel approach to model security.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.13224v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12625v1",
        "title": "SCOOP: CoSt-effective COngestiOn Attacks in Payment Channel Networks",
        "authors": [
            "Mohammed Ababneh",
            "Kartick Kolachala",
            "Roopa Vishwanathan"
        ],
        "published": "2025-03-16T19:41:56Z",
        "summary": "Payment channel networks (PCNs) are a promising solution to address blockchain scalability and throughput challenges, However, the security of PCNs and their vulnerability to attacks are not sufficiently studied. In this paper, we introduce SCOOP, a framework that includes two novel congestion attacks on PCNs. These attacks consider the minimum transferable amount along a path (path capacity) and the number of channels involved (path length), formulated as linear optimization problems. The first attack allocates the attacker's budget to achieve a specific congestion threshold, while the second maximizes congestion under budget constraints. Simulation results show the effectiveness of the proposed attack formulations in comparison to other attack strategies. Specifically, the results indicate that the first attack provides around a 40\\% improvement in congestion performance, while the second attack offers approximately a 50\\% improvement in comparison to the state-of-the-art. Moreover, in terms of payment to congestion efficiency, the first attack is about 60\\% more efficient, and the second attack is around 90\\% more efficient in comparison to state-of-the-art",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.12625v1"
    },
    {
        "id": "2503.11777v1",
        "title": "Enhancing Resiliency of Sketch-based Security via LSB Sharing-based Dynamic Late Merging",
        "authors": [
            "Seungsam Yang",
            "Seyed Mohammad Mehdi Mirnajafizadeh",
            "Sian Kim",
            "Rhongho Jang",
            "DaeHun Nyang"
        ],
        "published": "2025-03-14T18:12:14Z",
        "summary": "With the exponentially growing Internet traffic, sketch data structure with a probabilistic algorithm has been expected to be an alternative solution for non-compromised (non-selective) security monitoring. While facilitating counting within a confined memory space, the sketch's memory efficiency and accuracy were further pushed to their limit through finer-grained and dynamic control of constrained memory space to adapt to the data stream's inherent skewness (i.e., Zipf distribution), namely small counters with extensions. In this paper, we unveil a vulnerable factor of the small counter design by introducing a new sketch-oriented attack, which threatens a stream of state-of-the-art sketches and their security applications. With the root cause analyses, we propose Siamese Counter with enhanced adversarial resiliency and verified feasibility with extensive experimental and theoretical analyses. Under a sketch pollution attack, Siamese Counter delivers 47% accurate results than a state-of-the-art scheme, and demonstrates up to 82% more accurate estimation under normal measurement scenarios.",
        "field": "5G and 6G Networks",
        "link": "http://arxiv.org/abs/2503.11777v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.12172v1",
        "title": "SEAL: Semantic Aware Image Watermarking",
        "authors": [
            "Kasra Arabi",
            "R. Teal Witter",
            "Chinmay Hegde",
            "Niv Cohen"
        ],
        "published": "2025-03-15T15:29:05Z",
        "summary": "Generative models have rapidly evolved to generate realistic outputs. However, their synthetic outputs increasingly challenge the clear distinction between natural and AI-generated content, necessitating robust watermarking techniques. Watermarks are typically expected to preserve the integrity of the target image, withstand removal attempts, and prevent unauthorized replication onto unrelated images. To address this need, recent methods embed persistent watermarks into images produced by diffusion models using the initial noise. Yet, to do so, they either distort the distribution of generated images or rely on searching through a long dictionary of used keys for detection. In this paper, we propose a novel watermarking method that embeds semantic information about the generated image directly into the watermark, enabling a distortion-free watermark that can be verified without requiring a database of key patterns. Instead, the key pattern can be inferred from the semantic embedding of the image using locality-sensitive hashing. Furthermore, conditioning the watermark detection on the original image content improves robustness against forgery attacks. To demonstrate that, we consider two largely overlooked attack strategies: (i) an attacker extracting the initial noise and generating a novel image with the same pattern; (ii) an attacker inserting an unrelated (potentially harmful) object into a watermarked image, possibly while preserving the watermark. We empirically validate our method's increased robustness to these attacks. Taken together, our results suggest that content-aware watermarks can mitigate risks arising from image-generative models.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.12172v1"
    },
    {
        "id": "2503.11917v1",
        "title": "A Framework for Evaluating Emerging Cyberattack Capabilities of AI",
        "authors": [
            "Mikel Rodriguez",
            "Raluca Ada Popa",
            "Four Flynn",
            "Lihao Liang",
            "Allan Dafoe",
            "Anna Wang"
        ],
        "published": "2025-03-14T23:05:02Z",
        "summary": "As frontier models become more capable, the community has attempted to evaluate their ability to enable cyberattacks. Performing a comprehensive evaluation and prioritizing defenses are crucial tasks in preparing for AGI safely. However, current cyber evaluation efforts are ad-hoc, with no systematic reasoning about the various phases of attacks, and do not provide a steer on how to use targeted defenses. In this work, we propose a novel approach to AI cyber capability evaluation that (1) examines the end-to-end attack chain, (2) helps to identify gaps in the evaluation of AI threats, and (3) helps defenders prioritize targeted mitigations and conduct AI-enabled adversary emulation to support red teaming. To achieve these goals, we propose adapting existing cyberattack chain frameworks to AI systems. We analyze over 12,000 instances of real-world attempts to use AI in cyberattacks catalogued by Google's Threat Intelligence Group. Using this analysis, we curate a representative collection of seven cyberattack chain archetypes and conduct a bottleneck analysis to identify areas of potential AI-driven cost disruption. Our evaluation benchmark consists of 50 new challenges spanning different phases of cyberattacks. Based on this, we devise targeted cybersecurity model evaluations, report on the potential for AI to amplify offensive cyber capabilities across specific attack phases, and conclude with recommendations on prioritizing defenses. In all, we consider this to be the most comprehensive AI cyber risk evaluation framework published so far.",
        "field": "Human-Centric AI",
        "link": "http://arxiv.org/abs/2503.11917v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "Green Finance Technology",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.12719v1",
        "title": "Enabling High-Frequency Trading with Near-Instant, Trustless Cross-Chain Transactions via Pre-Signing Adaptor Signatures",
        "authors": [
            "Ethan Francolla",
            "Arnav Shah"
        ],
        "published": "2025-03-17T01:15:33Z",
        "summary": "Atomic swaps have been widely considered to be an ideal solution for cross-chain cryptocurrency transactions due to their trustless and decentralized nature. However, their adoption in practice has been strictly limited compared to centralized exchange order books because of long transaction times (anywhere from 20 to 60 minutes) prohibiting market makers from accurately pricing atomic swap spreads. For the decentralized finance ecosystem to expand and benefit all users, this would require accommodating market makers and high-frequency traders to reduce spreads and dramatically boost liquidity. This white paper will introduce a protocol for atomic swaps that eliminates the need for an intermediary currency or centralized trusted third party, reducing transaction times between Bitcoin and Ethereum swaps to approximately 15 seconds for a market maker, and could be reduced further with future Layer 2 solutions.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.12719v1"
    },
    {
        "id": "2503.12648v1",
        "title": "Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning",
        "authors": [
            "Andreas Teller",
            "Uta Pigorsch",
            "Christian Pigorsch"
        ],
        "published": "2025-03-16T20:56:44Z",
        "summary": "Forecasting the volatility of financial assets is essential for various financial applications. This paper addresses the challenging task of forecasting the volatility of financial assets with limited historical data, such as new issues or spin-offs, by proposing a multi-source transfer learning approach. Specifically, we exploit complementary source data of assets with a substantial historical data record by selecting source time series instances that are most similar to the limited target data of the new issue/spin-off. Based on these instances and the target data, we estimate linear and non-linear realized volatility models and compare their forecasting performance to forecasts of models trained exclusively on the target data, and models trained on the entire source and target data. The results show that our transfer learning approach outperforms the alternative models and that the integration of complementary data is also beneficial immediately after the initial trading day of the new issue/spin-off.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.12648v1"
    },
    {
        "id": "2503.12305v1",
        "title": "Intraday Battery Dispatch for Hybrid Renewable Energy Assets",
        "authors": [
            "Thiha Aung",
            "Mike Ludkovski"
        ],
        "published": "2025-03-16T00:32:07Z",
        "summary": "We develop a mathematical model for intraday dispatch of co-located wind-battery energy assets. Focusing on the primary objective of firming grid-side actual production vis-a-vis the preset day-ahead hourly generation targets, we conduct a comprehensive study of the resulting stochastic control problem across different firming formulations and wind generation dynamics. Among others, we provide a closed-form solution in the special case of a quadratic objective and linear dynamics, as well as design a novel adaptation of a Gaussian Process-based Regression Monte Carlo algorithm for our setting. Extensions studied include an asymmetric loss function for peak shaving, capturing the cost of battery cycling, and the role of battery duration. In the applied portion of our work, we calibrate our model to a collection of 140+ wind-battery assets in Texas, benchmarking the economic benefits of firming based on outputs of a realistic unit commitment and economic dispatch solver.",
        "field": "Autonomous Finance",
        "link": "http://arxiv.org/abs/2503.12305v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12719v1",
        "title": "Enabling High-Frequency Trading with Near-Instant, Trustless Cross-Chain Transactions via Pre-Signing Adaptor Signatures",
        "authors": [
            "Ethan Francolla",
            "Arnav Shah"
        ],
        "published": "2025-03-17T01:15:33Z",
        "summary": "Atomic swaps have been widely considered to be an ideal solution for cross-chain cryptocurrency transactions due to their trustless and decentralized nature. However, their adoption in practice has been strictly limited compared to centralized exchange order books because of long transaction times (anywhere from 20 to 60 minutes) prohibiting market makers from accurately pricing atomic swap spreads. For the decentralized finance ecosystem to expand and benefit all users, this would require accommodating market makers and high-frequency traders to reduce spreads and dramatically boost liquidity. This white paper will introduce a protocol for atomic swaps that eliminates the need for an intermediary currency or centralized trusted third party, reducing transaction times between Bitcoin and Ethereum swaps to approximately 15 seconds for a market maker, and could be reduced further with future Layer 2 solutions.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.12719v1"
    },
    {
        "id": "2503.12625v1",
        "title": "SCOOP: CoSt-effective COngestiOn Attacks in Payment Channel Networks",
        "authors": [
            "Mohammed Ababneh",
            "Kartick Kolachala",
            "Roopa Vishwanathan"
        ],
        "published": "2025-03-16T19:41:56Z",
        "summary": "Payment channel networks (PCNs) are a promising solution to address blockchain scalability and throughput challenges, However, the security of PCNs and their vulnerability to attacks are not sufficiently studied. In this paper, we introduce SCOOP, a framework that includes two novel congestion attacks on PCNs. These attacks consider the minimum transferable amount along a path (path capacity) and the number of channels involved (path length), formulated as linear optimization problems. The first attack allocates the attacker's budget to achieve a specific congestion threshold, while the second maximizes congestion under budget constraints. Simulation results show the effectiveness of the proposed attack formulations in comparison to other attack strategies. Specifically, the results indicate that the first attack provides around a 40\\% improvement in congestion performance, while the second attack offers approximately a 50\\% improvement in comparison to the state-of-the-art. Moreover, in terms of payment to congestion efficiency, the first attack is about 60\\% more efficient, and the second attack is around 90\\% more efficient in comparison to state-of-the-art",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.12625v1"
    },
    {
        "id": "2503.12305v1",
        "title": "Intraday Battery Dispatch for Hybrid Renewable Energy Assets",
        "authors": [
            "Thiha Aung",
            "Mike Ludkovski"
        ],
        "published": "2025-03-16T00:32:07Z",
        "summary": "We develop a mathematical model for intraday dispatch of co-located wind-battery energy assets. Focusing on the primary objective of firming grid-side actual production vis-a-vis the preset day-ahead hourly generation targets, we conduct a comprehensive study of the resulting stochastic control problem across different firming formulations and wind generation dynamics. Among others, we provide a closed-form solution in the special case of a quadratic objective and linear dynamics, as well as design a novel adaptation of a Gaussian Process-based Regression Monte Carlo algorithm for our setting. Extensions studied include an asymmetric loss function for peak shaving, capturing the cost of battery cycling, and the role of battery duration. In the applied portion of our work, we calibrate our model to a collection of 140+ wind-battery assets in Texas, benchmarking the economic benefits of firming based on outputs of a realistic unit commitment and economic dispatch solver.",
        "field": "Blockchain Interoperability Solutions",
        "link": "http://arxiv.org/abs/2503.12305v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.13224v1",
        "title": "ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction",
        "authors": [
            "Tong Zhou",
            "Shijin Duan",
            "Gaowen Liu",
            "Charles Fleming",
            "Ramana Rao Kompella",
            "Shaolei Ren",
            "Xiaolin Xu"
        ],
        "published": "2025-03-17T14:37:42Z",
        "summary": "Pre-trained models are valuable intellectual property, capturing both domain-specific and domain-invariant features within their weight spaces. However, model extraction attacks threaten these assets by enabling unauthorized source-domain inference and facilitating cross-domain transfer via the exploitation of domain-invariant features. In this work, we introduce **ProDiF**, a novel framework that leverages targeted weight space manipulation to secure pre-trained models against extraction attacks. **ProDiF** quantifies the transferability of filters and perturbs the weights of critical filters in unsecured memory, while preserving actual critical weights in a Trusted Execution Environment (TEE) for authorized users. A bi-level optimization further ensures resilience against adaptive fine-tuning attacks. Experimental results show that **ProDiF** reduces source-domain accuracy to near-random levels and decreases cross-domain transferability by 74.65\\%, providing robust protection for pre-trained models. This work offers comprehensive protection for pre-trained DNN models and highlights the potential of weight space manipulation as a novel approach to model security.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.13224v1"
    },
    {
        "id": "2503.13116v1",
        "title": "VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding",
        "authors": [
            "Zeng Wang",
            "Minghao Shao",
            "Mohammed Nabeel",
            "Prithwish Basu Roy",
            "Likhitha Mankali",
            "Jitendra Bhandari",
            "Ramesh Karri",
            "Ozgur Sinanoglu",
            "Muhammad Shafique",
            "Johann Knechtel"
        ],
        "published": "2025-03-17T12:38:03Z",
        "summary": "Large language models (LLMs) offer significant potential for coding, yet fine-tuning (FT) with curated data is essential for niche languages like Verilog. Using proprietary intellectual property (IP) for FT presents a serious risk, as FT data can be leaked through LLM inference. This leads to a critical dilemma for design houses: seeking to build externally accessible LLMs offering competitive Verilog coding, how can they leverage in-house IP to enhance FT utility while ensuring IP protection? For the first time in the literature, we study this dilemma. Using LLaMA 3.1-8B, we conduct in-house FT on a baseline Verilog dataset (RTLCoder) supplemented with our own in-house IP, which is validated through multiple tape-outs. To rigorously assess IP leakage, we quantify structural similarity (AST/Dolos) and functional equivalence (Synopsys Formality) between generated codes and our in-house IP. We show that our IP can indeed be leaked, confirming the threat. As defense, we evaluate logic locking of Verilog codes (ASSURE). This offers some level of protection, yet reduces the IP's utility for FT and degrades the LLM's performance. Our study shows the need for novel strategies that are both effective and minimally disruptive to FT, an essential effort for enabling design houses to fully utilize their proprietary IP toward LLM-driven Verilog coding.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.13116v1"
    },
    {
        "id": "2503.13052v1",
        "title": "Bitcoin Battle: Burning Bitcoin for Geopolitical Fun and Profit",
        "authors": [
            "Kris Oosthoek",
            "Kelvin Lubbertsen",
            "Georgios Smaragdakis"
        ],
        "published": "2025-03-17T10:55:59Z",
        "summary": "This study empirically analyzes the transaction activity of Bitcoin addresses linked to Russian intelligence services, which have liquidated over 7 Bitcoin (BTC), i.e., equivalent to approximately US$300,000 based on the exchange rate at the time. Our investigation begins with an observed anomaly in transaction outputs featuring the Bitcoin Script operation code, tied to input addresses identified by cyber threat intelligence sources and court documents as belonging to Russian intelligence agencies. We explore how an unauthorized entity appears to have gained control of the associated private keys, with messages embedded in the outputs confirming the seizure. Tracing the funds' origins, we connect them to cryptocurrency mixers and establish a link to the Russian ransomware group Conti, implicating intelligence service involvement. This analysis represents one of the first empirical studies of large-scale Bitcoin misuse by nation-state cyber actors.",
        "field": "Quantum-Safe Cryptography",
        "link": "http://arxiv.org/abs/2503.13052v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.12217v1",
        "title": "TFHE-Coder: Evaluating LLM-agentic Fully Homomorphic Encryption Code Generation",
        "authors": [
            "Mayank Kumar",
            "Jiaqi Xue",
            "Mengxin Zheng",
            "Qian Lou"
        ],
        "published": "2025-03-15T17:57:44Z",
        "summary": "Fully Homomorphic Encryption over the torus (TFHE) enables computation on encrypted data without decryption, making it a cornerstone of secure and confidential computing. Despite its potential in privacy preserving machine learning, secure multi party computation, private blockchain transactions, and secure medical diagnostics, its adoption remains limited due to cryptographic complexity and usability challenges. While various TFHE libraries and compilers exist, practical code generation remains a hurdle. We propose a compiler integrated framework to evaluate LLM inference and agentic optimization for TFHE code generation, focusing on logic gates and ReLU activation. Our methodology assesses error rates, compilability, and structural similarity across open and closedsource LLMs. Results highlight significant limitations in off-the-shelf models, while agentic optimizations such as retrieval augmented generation (RAG) and few-shot prompting reduce errors and enhance code fidelity. This work establishes the first benchmark for TFHE code generation, demonstrating how LLMs, when augmented with domain-specific feedback, can bridge the expertise gap in FHE code generation.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.12217v1"
    },
    {
        "id": "2503.12188v1",
        "title": "Multi-Agent Systems Execute Arbitrary Malicious Code",
        "authors": [
            "Harold Triedman",
            "Rishi Jha",
            "Vitaly Shmatikov"
        ],
        "published": "2025-03-15T16:16:08Z",
        "summary": "Multi-agent systems coordinate LLM-based agents to perform tasks on users' behalf. In real-world applications, multi-agent systems will inevitably interact with untrusted inputs, such as malicious Web content, files, email attachments, etc. Using several recently proposed multi-agent frameworks as concrete examples, we demonstrate that adversarial content can hijack control and communication within the system to invoke unsafe agents and functionalities. This results in a complete security breach, up to execution of arbitrary malicious code on the user's device and/or exfiltration of sensitive data from the user's containerized environment. We show that control-flow hijacking attacks succeed even if the individual agents are not susceptible to direct or indirect prompt injection, and even if they refuse to perform harmful actions.",
        "field": "Autonomous Banking Agents",
        "link": "http://arxiv.org/abs/2503.12188v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12719v1",
        "title": "Enabling High-Frequency Trading with Near-Instant, Trustless Cross-Chain Transactions via Pre-Signing Adaptor Signatures",
        "authors": [
            "Ethan Francolla",
            "Arnav Shah"
        ],
        "published": "2025-03-17T01:15:33Z",
        "summary": "Atomic swaps have been widely considered to be an ideal solution for cross-chain cryptocurrency transactions due to their trustless and decentralized nature. However, their adoption in practice has been strictly limited compared to centralized exchange order books because of long transaction times (anywhere from 20 to 60 minutes) prohibiting market makers from accurately pricing atomic swap spreads. For the decentralized finance ecosystem to expand and benefit all users, this would require accommodating market makers and high-frequency traders to reduce spreads and dramatically boost liquidity. This white paper will introduce a protocol for atomic swaps that eliminates the need for an intermediary currency or centralized trusted third party, reducing transaction times between Bitcoin and Ethereum swaps to approximately 15 seconds for a market maker, and could be reduced further with future Layer 2 solutions.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.12719v1"
    },
    {
        "id": "2503.12625v1",
        "title": "SCOOP: CoSt-effective COngestiOn Attacks in Payment Channel Networks",
        "authors": [
            "Mohammed Ababneh",
            "Kartick Kolachala",
            "Roopa Vishwanathan"
        ],
        "published": "2025-03-16T19:41:56Z",
        "summary": "Payment channel networks (PCNs) are a promising solution to address blockchain scalability and throughput challenges, However, the security of PCNs and their vulnerability to attacks are not sufficiently studied. In this paper, we introduce SCOOP, a framework that includes two novel congestion attacks on PCNs. These attacks consider the minimum transferable amount along a path (path capacity) and the number of channels involved (path length), formulated as linear optimization problems. The first attack allocates the attacker's budget to achieve a specific congestion threshold, while the second maximizes congestion under budget constraints. Simulation results show the effectiveness of the proposed attack formulations in comparison to other attack strategies. Specifically, the results indicate that the first attack provides around a 40\\% improvement in congestion performance, while the second attack offers approximately a 50\\% improvement in comparison to the state-of-the-art. Moreover, in terms of payment to congestion efficiency, the first attack is about 60\\% more efficient, and the second attack is around 90\\% more efficient in comparison to state-of-the-art",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.12625v1"
    },
    {
        "id": "2503.12305v1",
        "title": "Intraday Battery Dispatch for Hybrid Renewable Energy Assets",
        "authors": [
            "Thiha Aung",
            "Mike Ludkovski"
        ],
        "published": "2025-03-16T00:32:07Z",
        "summary": "We develop a mathematical model for intraday dispatch of co-located wind-battery energy assets. Focusing on the primary objective of firming grid-side actual production vis-a-vis the preset day-ahead hourly generation targets, we conduct a comprehensive study of the resulting stochastic control problem across different firming formulations and wind generation dynamics. Among others, we provide a closed-form solution in the special case of a quadratic objective and linear dynamics, as well as design a novel adaptation of a Gaussian Process-based Regression Monte Carlo algorithm for our setting. Extensions studied include an asymmetric loss function for peak shaving, capturing the cost of battery cycling, and the role of battery duration. In the applied portion of our work, we calibrate our model to a collection of 140+ wind-battery assets in Texas, benchmarking the economic benefits of firming based on outputs of a realistic unit commitment and economic dispatch solver.",
        "field": "Digital Asset Custody Solutions",
        "link": "http://arxiv.org/abs/2503.12305v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.11940v1",
        "title": "Vote Delegation in DeFi Governance",
        "authors": [
            "Dion Bongaerts",
            "Thomas Lambert",
            "Daniel Liebau",
            "Peter Roosenboom"
        ],
        "published": "2025-03-15T01:15:08Z",
        "summary": "We investigate the drivers of vote delegation in Decentralized Autonomous Organizations (DAOs), using the Uniswap governance DAO as a laboratory. We show that parties with fewer self-owned votes and those affiliated with the controlling venture capital firm, Andreesen Horowitz (a16z), receive more vote delegations. These patterns suggest that while the Uniswap ecosystem values decentralization, a16z may engage in window-dressing around it. Moreover, we find that an active and successful track record in submitting improvement proposals, especially in the final stage, leads to more vote delegations, indicating that delegation in DAOs is at least partly reputation- or merit-based. Combined, our findings provide new insights into how governance and decentralization operate in DeFi.",
        "field": "AI-Driven Risk Management",
        "link": "http://arxiv.org/abs/2503.11940v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.12931v1",
        "title": "MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting",
        "authors": [
            "Rui Pu",
            "Chaozhuo Li",
            "Rui Ha",
            "Litian Zhang",
            "Lirong Qiu",
            "Xi Zhang"
        ],
        "published": "2025-03-17T08:41:29Z",
        "summary": "Defending large language models (LLMs) against jailbreak attacks is crucial for ensuring their safe deployment. Existing defense strategies generally rely on predefined static criteria to differentiate between harmful and benign prompts. However, such rigid rules are incapable of accommodating the inherent complexity and dynamic nature of real jailbreak attacks. In this paper, we propose a novel concept of ``mirror'' to enable dynamic and adaptive defense. A mirror refers to a dynamically generated prompt that mirrors the syntactic structure of the input while ensuring semantic safety. The personalized discrepancies between the input prompts and their corresponding mirrors serve as the guiding principles for defense. A new defense paradigm, MirrorGuard, is further proposed to detect and calibrate risky inputs based on such mirrors. An entropy-based detection metric, Relative Input Uncertainty (RIU), is integrated into MirrorGuard to quantify the discrepancies between input prompts and mirrors. MirrorGuard is evaluated on several popular datasets, demonstrating state-of-the-art defense performance while maintaining general effectiveness.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.12931v1"
    },
    {
        "id": "2503.12801v1",
        "title": "BLIA: Detect model memorization in binary classification model through passive Label Inference attack",
        "authors": [
            "Mohammad Wahiduzzaman Khan",
            "Sheng Chen",
            "Ilya Mironov",
            "Leizhen Zhang",
            "Rabib Noor"
        ],
        "published": "2025-03-17T04:15:47Z",
        "summary": "Model memorization has implications for both the generalization capacity of machine learning models and the privacy of their training data. This paper investigates label memorization in binary classification models through two novel passive label inference attacks (BLIA). These attacks operate passively, relying solely on the outputs of pre-trained models, such as confidence scores and log-loss values, without interacting with or modifying the training process. By intentionally flipping 50% of the labels in controlled subsets, termed \"canaries,\" we evaluate the extent of label memorization under two conditions: models trained without label differential privacy (Label-DP) and those trained with randomized response-based Label-DP. Despite the application of varying degrees of Label-DP, the proposed attacks consistently achieve success rates exceeding 50%, surpassing the baseline of random guessing and conclusively demonstrating that models memorize training labels, even when these labels are deliberately uncorrelated with the features.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.12801v1"
    },
    {
        "id": "2503.12368v1",
        "title": "SCReedSolo: A Secure and Robust LSB Image Steganography Framework with Randomized Symmetric Encryption and Reed-Solomon Coding",
        "authors": [
            "Syed Rifat Raiyan",
            "Md. Hasanul Kabir"
        ],
        "published": "2025-03-16T06:01:05Z",
        "summary": "Image steganography is an information-hiding technique that involves the surreptitious concealment of covert informational content within digital images. In this paper, we introduce ${\\rm SCR{\\small EED}S{\\small OLO}}$, a novel framework for concealing arbitrary binary data within images. Our approach synergistically leverages Random Shuffling, Fernet Symmetric Encryption, and Reed-Solomon Error Correction Codes to encode the secret payload, which is then discretely embedded into the carrier image using LSB (Least Significant Bit) Steganography. The combination of these methods addresses the vulnerability vectors of both security and resilience against bit-level corruption in the resultant stego-images. We show that our framework achieves a data payload of 3 bits per pixel for an RGB image, and mathematically assess the probability of successful transmission for the amalgamated $n$ message bits and $k$ error correction bits. Additionally, we find that ${\\rm SCR{\\small EED}S{\\small OLO}}$ yields good results upon being evaluated with multiple performance metrics, successfully eludes detection by various passive steganalysis tools, and is immune to simple active steganalysis attacks. Our code and data are available at https://github.com/Starscream-11813/SCReedSolo-Steganography.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.12368v1"
    },
    {
        "id": "2503.12220v1",
        "title": "A Bubble-Cluster Federated Learning Framework for Privacy-Preserving Demand Forecasting on Heterogeneous Retail Data",
        "authors": [
            "Yunbo Long",
            "Liming Xu",
            "Ge Zheng",
            "Alexandra Brintrup"
        ],
        "published": "2025-03-15T18:07:54Z",
        "summary": "Federated learning (FL) enables retailers to share model parameters for demand forecasting while maintaining privacy. However, heterogeneous data across diverse regions, driven by factors such as varying consumer behavior, poses challenges to the effectiveness of federated learning. To tackle this challenge, we propose Bubble-Cluster Federated Learning (BFL), a novel clustering-based federated learning framework tailored for sales prediction. By leveraging differential privacy and feature importance distribution, BFL groups retailers into distinct \"bubbles\", each forming its own federated learning (FL) system to effectively isolate data heterogeneity. Within each bubble, Transformer models are designed to predict local sales for each client. Our experiments demonstrate that BFL significantly surpasses FedAvg and outperforms local learning in demand forecasting performance across all participating clients. Compared to local learning, BFL can achieve a 5.4\\% improvement in R\\textsuperscript{2}, a 69\\% reduction in RMSE, and a 45\\% decrease in MAE. Our study highlights BFL's adaptability in enabling effective federated learning through dynamic adjustments to noise levels and the range of clients participating in each bubble. This approach strategically groups participants into distinct \"bubbles\" while proactively identifying and filtering out risky clients that could compromise the FL system. The findings demonstrate BFL's ability to enhance collaborative learning in regression tasks on heterogeneous data, achieving a balance between forecasting accuracy and privacy preservation in retail applications. Additionally, BFL's capability to detect and neutralize poisoned data from clients enhances the system's robustness and reliability, ensuring more secure and effective federated learning.",
        "field": "AI-Powered Fraud Detection",
        "link": "http://arxiv.org/abs/2503.12220v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.11940v1",
        "title": "Vote Delegation in DeFi Governance",
        "authors": [
            "Dion Bongaerts",
            "Thomas Lambert",
            "Daniel Liebau",
            "Peter Roosenboom"
        ],
        "published": "2025-03-15T01:15:08Z",
        "summary": "We investigate the drivers of vote delegation in Decentralized Autonomous Organizations (DAOs), using the Uniswap governance DAO as a laboratory. We show that parties with fewer self-owned votes and those affiliated with the controlling venture capital firm, Andreesen Horowitz (a16z), receive more vote delegations. These patterns suggest that while the Uniswap ecosystem values decentralization, a16z may engage in window-dressing around it. Moreover, we find that an active and successful track record in submitting improvement proposals, especially in the final stage, leads to more vote delegations, indicating that delegation in DAOs is at least partly reputation- or merit-based. Combined, our findings provide new insights into how governance and decentralization operate in DeFi.",
        "field": "AI-Driven Personal Finance Management",
        "link": "http://arxiv.org/abs/2503.11940v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "Digital Wallet Interoperability",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "The Current Frontier of Banking Technology",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.12931v1",
        "title": "MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting",
        "authors": [
            "Rui Pu",
            "Chaozhuo Li",
            "Rui Ha",
            "Litian Zhang",
            "Lirong Qiu",
            "Xi Zhang"
        ],
        "published": "2025-03-17T08:41:29Z",
        "summary": "Defending large language models (LLMs) against jailbreak attacks is crucial for ensuring their safe deployment. Existing defense strategies generally rely on predefined static criteria to differentiate between harmful and benign prompts. However, such rigid rules are incapable of accommodating the inherent complexity and dynamic nature of real jailbreak attacks. In this paper, we propose a novel concept of ``mirror'' to enable dynamic and adaptive defense. A mirror refers to a dynamically generated prompt that mirrors the syntactic structure of the input while ensuring semantic safety. The personalized discrepancies between the input prompts and their corresponding mirrors serve as the guiding principles for defense. A new defense paradigm, MirrorGuard, is further proposed to detect and calibrate risky inputs based on such mirrors. An entropy-based detection metric, Relative Input Uncertainty (RIU), is integrated into MirrorGuard to quantify the discrepancies between input prompts and mirrors. MirrorGuard is evaluated on several popular datasets, demonstrating state-of-the-art defense performance while maintaining general effectiveness.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.12931v1"
    },
    {
        "id": "2503.12801v1",
        "title": "BLIA: Detect model memorization in binary classification model through passive Label Inference attack",
        "authors": [
            "Mohammad Wahiduzzaman Khan",
            "Sheng Chen",
            "Ilya Mironov",
            "Leizhen Zhang",
            "Rabib Noor"
        ],
        "published": "2025-03-17T04:15:47Z",
        "summary": "Model memorization has implications for both the generalization capacity of machine learning models and the privacy of their training data. This paper investigates label memorization in binary classification models through two novel passive label inference attacks (BLIA). These attacks operate passively, relying solely on the outputs of pre-trained models, such as confidence scores and log-loss values, without interacting with or modifying the training process. By intentionally flipping 50% of the labels in controlled subsets, termed \"canaries,\" we evaluate the extent of label memorization under two conditions: models trained without label differential privacy (Label-DP) and those trained with randomized response-based Label-DP. Despite the application of varying degrees of Label-DP, the proposed attacks consistently achieve success rates exceeding 50%, surpassing the baseline of random guessing and conclusively demonstrating that models memorize training labels, even when these labels are deliberately uncorrelated with the features.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.12801v1"
    },
    {
        "id": "2503.12368v1",
        "title": "SCReedSolo: A Secure and Robust LSB Image Steganography Framework with Randomized Symmetric Encryption and Reed-Solomon Coding",
        "authors": [
            "Syed Rifat Raiyan",
            "Md. Hasanul Kabir"
        ],
        "published": "2025-03-16T06:01:05Z",
        "summary": "Image steganography is an information-hiding technique that involves the surreptitious concealment of covert informational content within digital images. In this paper, we introduce ${\\rm SCR{\\small EED}S{\\small OLO}}$, a novel framework for concealing arbitrary binary data within images. Our approach synergistically leverages Random Shuffling, Fernet Symmetric Encryption, and Reed-Solomon Error Correction Codes to encode the secret payload, which is then discretely embedded into the carrier image using LSB (Least Significant Bit) Steganography. The combination of these methods addresses the vulnerability vectors of both security and resilience against bit-level corruption in the resultant stego-images. We show that our framework achieves a data payload of 3 bits per pixel for an RGB image, and mathematically assess the probability of successful transmission for the amalgamated $n$ message bits and $k$ error correction bits. Additionally, we find that ${\\rm SCR{\\small EED}S{\\small OLO}}$ yields good results upon being evaluated with multiple performance metrics, successfully eludes detection by various passive steganalysis tools, and is immune to simple active steganalysis attacks. Our code and data are available at https://github.com/Starscream-11813/SCReedSolo-Steganography.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.12368v1"
    },
    {
        "id": "2503.12220v1",
        "title": "A Bubble-Cluster Federated Learning Framework for Privacy-Preserving Demand Forecasting on Heterogeneous Retail Data",
        "authors": [
            "Yunbo Long",
            "Liming Xu",
            "Ge Zheng",
            "Alexandra Brintrup"
        ],
        "published": "2025-03-15T18:07:54Z",
        "summary": "Federated learning (FL) enables retailers to share model parameters for demand forecasting while maintaining privacy. However, heterogeneous data across diverse regions, driven by factors such as varying consumer behavior, poses challenges to the effectiveness of federated learning. To tackle this challenge, we propose Bubble-Cluster Federated Learning (BFL), a novel clustering-based federated learning framework tailored for sales prediction. By leveraging differential privacy and feature importance distribution, BFL groups retailers into distinct \"bubbles\", each forming its own federated learning (FL) system to effectively isolate data heterogeneity. Within each bubble, Transformer models are designed to predict local sales for each client. Our experiments demonstrate that BFL significantly surpasses FedAvg and outperforms local learning in demand forecasting performance across all participating clients. Compared to local learning, BFL can achieve a 5.4\\% improvement in R\\textsuperscript{2}, a 69\\% reduction in RMSE, and a 45\\% decrease in MAE. Our study highlights BFL's adaptability in enabling effective federated learning through dynamic adjustments to noise levels and the range of clients participating in each bubble. This approach strategically groups participants into distinct \"bubbles\" while proactively identifying and filtering out risky clients that could compromise the FL system. The findings demonstrate BFL's ability to enhance collaborative learning in regression tasks on heterogeneous data, achieving a balance between forecasting accuracy and privacy preservation in retail applications. Additionally, BFL's capability to detect and neutralize poisoned data from clients enhances the system's robustness and reliability, ensuring more secure and effective federated learning.",
        "field": "AI-Driven Financial Crime Detection",
        "link": "http://arxiv.org/abs/2503.12220v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.11940v1",
        "title": "Vote Delegation in DeFi Governance",
        "authors": [
            "Dion Bongaerts",
            "Thomas Lambert",
            "Daniel Liebau",
            "Peter Roosenboom"
        ],
        "published": "2025-03-15T01:15:08Z",
        "summary": "We investigate the drivers of vote delegation in Decentralized Autonomous Organizations (DAOs), using the Uniswap governance DAO as a laboratory. We show that parties with fewer self-owned votes and those affiliated with the controlling venture capital firm, Andreesen Horowitz (a16z), receive more vote delegations. These patterns suggest that while the Uniswap ecosystem values decentralization, a16z may engage in window-dressing around it. Moreover, we find that an active and successful track record in submitting improvement proposals, especially in the final stage, leads to more vote delegations, indicating that delegation in DAOs is at least partly reputation- or merit-based. Combined, our findings provide new insights into how governance and decentralization operate in DeFi.",
        "field": "AI-Powered Wealth Management",
        "link": "http://arxiv.org/abs/2503.11940v1"
    },
    {
        "id": "2503.13419v1",
        "title": "Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI",
        "authors": [
            "Ripan Kumar Kundu",
            "Matthew Denton",
            "Genova Mongalo",
            "Prasad Calyam",
            "Khaza Anuarul Hoque"
        ],
        "published": "2025-03-17T17:49:51Z",
        "summary": "The synergy between virtual reality (VR) and artificial intelligence (AI), specifically deep learning (DL)-based cybersickness detection models, has ushered in unprecedented advancements in immersive experiences by automatically detecting cybersickness severity and adaptively various mitigation techniques, offering a smooth and comfortable VR experience. While this DL-enabled cybersickness detection method provides promising solutions for enhancing user experiences, it also introduces new risks since these models are vulnerable to adversarial attacks; a small perturbation of the input data that is visually undetectable to human observers can fool the cybersickness detection model and trigger unexpected mitigation, thus disrupting user immersive experiences (UIX) and even posing safety risks. In this paper, we present a new type of VR attack, i.e., a cybersickness attack, which successfully stops the triggering of cybersickness mitigation by fooling DL-based cybersickness detection models and dramatically hinders the UIX. Next, we propose a novel explainable artificial intelligence (XAI)-guided cybersickness attack detection framework to detect such attacks in VR to ensure UIX and a comfortable VR experience. We evaluate the proposed attack and the detection framework using two state-of-the-art open-source VR cybersickness datasets: Simulation 2021 and Gameplay dataset. Finally, to verify the effectiveness of our proposed method, we implement the attack and the XAI-based detection using a testbed with a custom-built VR roller coaster simulation with an HTC Vive Pro Eye headset and perform a user study. Our study shows that such an attack can dramatically hinder the UIX. However, our proposed XAI-guided cybersickness attack detection can successfully detect cybersickness attacks and trigger the proper mitigation, effectively reducing VR cybersickness.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.13419v1"
    },
    {
        "id": "2503.13255v1",
        "title": "Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning",
        "authors": [
            "Tianxing Fu",
            "Jia Hu",
            "Geyong Min",
            "Zi Wang"
        ],
        "published": "2025-03-17T15:13:10Z",
        "summary": "Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.13255v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12220v1",
        "title": "A Bubble-Cluster Federated Learning Framework for Privacy-Preserving Demand Forecasting on Heterogeneous Retail Data",
        "authors": [
            "Yunbo Long",
            "Liming Xu",
            "Ge Zheng",
            "Alexandra Brintrup"
        ],
        "published": "2025-03-15T18:07:54Z",
        "summary": "Federated learning (FL) enables retailers to share model parameters for demand forecasting while maintaining privacy. However, heterogeneous data across diverse regions, driven by factors such as varying consumer behavior, poses challenges to the effectiveness of federated learning. To tackle this challenge, we propose Bubble-Cluster Federated Learning (BFL), a novel clustering-based federated learning framework tailored for sales prediction. By leveraging differential privacy and feature importance distribution, BFL groups retailers into distinct \"bubbles\", each forming its own federated learning (FL) system to effectively isolate data heterogeneity. Within each bubble, Transformer models are designed to predict local sales for each client. Our experiments demonstrate that BFL significantly surpasses FedAvg and outperforms local learning in demand forecasting performance across all participating clients. Compared to local learning, BFL can achieve a 5.4\\% improvement in R\\textsuperscript{2}, a 69\\% reduction in RMSE, and a 45\\% decrease in MAE. Our study highlights BFL's adaptability in enabling effective federated learning through dynamic adjustments to noise levels and the range of clients participating in each bubble. This approach strategically groups participants into distinct \"bubbles\" while proactively identifying and filtering out risky clients that could compromise the FL system. The findings demonstrate BFL's ability to enhance collaborative learning in regression tasks on heterogeneous data, achieving a balance between forecasting accuracy and privacy preservation in retail applications. Additionally, BFL's capability to detect and neutralize poisoned data from clients enhances the system's robustness and reliability, ensuring more secure and effective federated learning.",
        "field": "AI-Enhanced Customer Experience",
        "link": "http://arxiv.org/abs/2503.12220v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.13052v1",
        "title": "Bitcoin Battle: Burning Bitcoin for Geopolitical Fun and Profit",
        "authors": [
            "Kris Oosthoek",
            "Kelvin Lubbertsen",
            "Georgios Smaragdakis"
        ],
        "published": "2025-03-17T10:55:59Z",
        "summary": "This study empirically analyzes the transaction activity of Bitcoin addresses linked to Russian intelligence services, which have liquidated over 7 Bitcoin (BTC), i.e., equivalent to approximately US$300,000 based on the exchange rate at the time. Our investigation begins with an observed anomaly in transaction outputs featuring the Bitcoin Script operation code, tied to input addresses identified by cyber threat intelligence sources and court documents as belonging to Russian intelligence agencies. We explore how an unauthorized entity appears to have gained control of the associated private keys, with messages embedded in the outputs confirming the seizure. Tracing the funds' origins, we connect them to cryptocurrency mixers and establish a link to the Russian ransomware group Conti, implicating intelligence service involvement. This analysis represents one of the first empirical studies of large-scale Bitcoin misuse by nation-state cyber actors.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.13052v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12314v1",
        "title": "Empirical Privacy Variance",
        "authors": [
            "Yuzheng Hu",
            "Fan Wu",
            "Ruicheng Xian",
            "Yuhang Liu",
            "Lydia Zakynthinou",
            "Pritish Kamath",
            "Chiyuan Zhang",
            "David Forsyth"
        ],
        "published": "2025-03-16T01:43:49Z",
        "summary": "We propose the notion of empirical privacy variance and study it in the context of differentially private fine-tuning of language models. Specifically, we show that models calibrated to the same $(\\varepsilon, \\delta)$-DP guarantee using DP-SGD with different hyperparameter configurations can exhibit significant variations in empirical privacy, which we quantify through the lens of memorization. We investigate the generality of this phenomenon across multiple dimensions and discuss why it is surprising and relevant. Through regression analysis, we examine how individual and composite hyperparameters influence empirical privacy. The results reveal a no-free-lunch trade-off: existing practices of hyperparameter tuning in DP-SGD, which focus on optimizing utility under a fixed privacy budget, often come at the expense of empirical privacy. To address this, we propose refined heuristics for hyperparameter selection that explicitly account for empirical privacy, showing that they are both precise and practically useful. Finally, we take preliminary steps to understand empirical privacy variance. We propose two hypotheses, identify limitations in existing techniques like privacy auditing, and outline open questions for future research.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.12314v1"
    },
    {
        "id": "2503.12248v1",
        "title": "Electromagnetic Side-Channel Analysis of PRESENT Lightweight Cipher",
        "authors": [
            "Nilupulee A Gunathilake",
            "Owen Lo",
            "William J Buchanan",
            "Ahmed Al-Dubai"
        ],
        "published": "2025-03-15T20:09:23Z",
        "summary": "Side-channel vulnerabilities pose an increasing threat to cryptographically protected devices. Consequently, it is crucial to observe information leakages through physical parameters such as power consumption and electromagnetic (EM) radiation to reduce susceptibility during interactions with cryptographic functions. EM side-channel attacks are becoming more prevalent. PRESENT is a promising lightweight cryptographic algorithm expected to be incorporated into Internet-of-Things (IoT) devices in the future. This research investigates the EM side-channel robustness of PRESENT using a correlation attack model. This work extends our previous Correlation EM Analysis (CEMA) of PRESENT with improved results. The attack targets the Substitution box (S-box) and can retrieve 8 bytes of the 10-byte encryption key with a minimum of 256 EM waveforms. This paper presents the process of EM attack modelling, encompassing both simple and correlation attacks, followed by a critical analysis.",
        "field": "AI-Driven ESG Analysis",
        "link": "http://arxiv.org/abs/2503.12248v1"
    },
    {
        "id": "2503.13116v1",
        "title": "VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding",
        "authors": [
            "Zeng Wang",
            "Minghao Shao",
            "Mohammed Nabeel",
            "Prithwish Basu Roy",
            "Likhitha Mankali",
            "Jitendra Bhandari",
            "Ramesh Karri",
            "Ozgur Sinanoglu",
            "Muhammad Shafique",
            "Johann Knechtel"
        ],
        "published": "2025-03-17T12:38:03Z",
        "summary": "Large language models (LLMs) offer significant potential for coding, yet fine-tuning (FT) with curated data is essential for niche languages like Verilog. Using proprietary intellectual property (IP) for FT presents a serious risk, as FT data can be leaked through LLM inference. This leads to a critical dilemma for design houses: seeking to build externally accessible LLMs offering competitive Verilog coding, how can they leverage in-house IP to enhance FT utility while ensuring IP protection? For the first time in the literature, we study this dilemma. Using LLaMA 3.1-8B, we conduct in-house FT on a baseline Verilog dataset (RTLCoder) supplemented with our own in-house IP, which is validated through multiple tape-outs. To rigorously assess IP leakage, we quantify structural similarity (AST/Dolos) and functional equivalence (Synopsys Formality) between generated codes and our in-house IP. We show that our IP can indeed be leaked, confirming the threat. As defense, we evaluate logic locking of Verilog codes (ASSURE). This offers some level of protection, yet reduces the IP's utility for FT and degrades the LLM's performance. Our study shows the need for novel strategies that are both effective and minimally disruptive to FT, an essential effort for enabling design houses to fully utilize their proprietary IP toward LLM-driven Verilog coding.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.13116v1"
    },
    {
        "id": "2503.12958v1",
        "title": "FedSDP: Explainable Differential Privacy in Federated Learning via Shapley Values",
        "authors": [
            "Yunbo Li",
            "Jiaping Gui",
            "Yue Wu"
        ],
        "published": "2025-03-17T09:14:19Z",
        "summary": "Federated learning (FL) enables participants to store data locally while collaborating in training, yet it remains vulnerable to privacy attacks, such as data reconstruction. Existing differential privacy (DP) technologies inject noise dynamically into the training process to mitigate the impact of excessive noise. However, this dynamic scheduling is often grounded in factors indirectly related to privacy, making it difficult to clearly explain the intricate relationship between dynamic noise adjustments and privacy requirements. To address this issue, we propose FedSDP, a novel and explainable DP-based privacy protection mechanism that guides noise injection based on privacy contribution. Specifically, FedSDP leverages Shapley values to assess the contribution of private attributes to local model training and dynamically adjusts the amount of noise injected accordingly. By providing theoretical insights into the injection of varying scales of noise into local training, FedSDP enhances interpretability. Extensive experiments demonstrate that FedSDP can achieve a superior balance between privacy preservation and model performance, surpassing state-of-the-art (SOTA) solutions.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.12958v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12368v1",
        "title": "SCReedSolo: A Secure and Robust LSB Image Steganography Framework with Randomized Symmetric Encryption and Reed-Solomon Coding",
        "authors": [
            "Syed Rifat Raiyan",
            "Md. Hasanul Kabir"
        ],
        "published": "2025-03-16T06:01:05Z",
        "summary": "Image steganography is an information-hiding technique that involves the surreptitious concealment of covert informational content within digital images. In this paper, we introduce ${\\rm SCR{\\small EED}S{\\small OLO}}$, a novel framework for concealing arbitrary binary data within images. Our approach synergistically leverages Random Shuffling, Fernet Symmetric Encryption, and Reed-Solomon Error Correction Codes to encode the secret payload, which is then discretely embedded into the carrier image using LSB (Least Significant Bit) Steganography. The combination of these methods addresses the vulnerability vectors of both security and resilience against bit-level corruption in the resultant stego-images. We show that our framework achieves a data payload of 3 bits per pixel for an RGB image, and mathematically assess the probability of successful transmission for the amalgamated $n$ message bits and $k$ error correction bits. Additionally, we find that ${\\rm SCR{\\small EED}S{\\small OLO}}$ yields good results upon being evaluated with multiple performance metrics, successfully eludes detection by various passive steganalysis tools, and is immune to simple active steganalysis attacks. Our code and data are available at https://github.com/Starscream-11813/SCReedSolo-Steganography.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.12368v1"
    },
    {
        "id": "2503.12217v1",
        "title": "TFHE-Coder: Evaluating LLM-agentic Fully Homomorphic Encryption Code Generation",
        "authors": [
            "Mayank Kumar",
            "Jiaqi Xue",
            "Mengxin Zheng",
            "Qian Lou"
        ],
        "published": "2025-03-15T17:57:44Z",
        "summary": "Fully Homomorphic Encryption over the torus (TFHE) enables computation on encrypted data without decryption, making it a cornerstone of secure and confidential computing. Despite its potential in privacy preserving machine learning, secure multi party computation, private blockchain transactions, and secure medical diagnostics, its adoption remains limited due to cryptographic complexity and usability challenges. While various TFHE libraries and compilers exist, practical code generation remains a hurdle. We propose a compiler integrated framework to evaluate LLM inference and agentic optimization for TFHE code generation, focusing on logic gates and ReLU activation. Our methodology assesses error rates, compilability, and structural similarity across open and closedsource LLMs. Results highlight significant limitations in off-the-shelf models, while agentic optimizations such as retrieval augmented generation (RAG) and few-shot prompting reduce errors and enhance code fidelity. This work establishes the first benchmark for TFHE code generation, demonstrating how LLMs, when augmented with domain-specific feedback, can bridge the expertise gap in FHE code generation.",
        "field": "AI-Powered Climate Risk Assessment",
        "link": "http://arxiv.org/abs/2503.12217v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.12719v1",
        "title": "Enabling High-Frequency Trading with Near-Instant, Trustless Cross-Chain Transactions via Pre-Signing Adaptor Signatures",
        "authors": [
            "Ethan Francolla",
            "Arnav Shah"
        ],
        "published": "2025-03-17T01:15:33Z",
        "summary": "Atomic swaps have been widely considered to be an ideal solution for cross-chain cryptocurrency transactions due to their trustless and decentralized nature. However, their adoption in practice has been strictly limited compared to centralized exchange order books because of long transaction times (anywhere from 20 to 60 minutes) prohibiting market makers from accurately pricing atomic swap spreads. For the decentralized finance ecosystem to expand and benefit all users, this would require accommodating market makers and high-frequency traders to reduce spreads and dramatically boost liquidity. This white paper will introduce a protocol for atomic swaps that eliminates the need for an intermediary currency or centralized trusted third party, reducing transaction times between Bitcoin and Ethereum swaps to approximately 15 seconds for a market maker, and could be reduced further with future Layer 2 solutions.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.12719v1"
    },
    {
        "id": "2503.12648v1",
        "title": "Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning",
        "authors": [
            "Andreas Teller",
            "Uta Pigorsch",
            "Christian Pigorsch"
        ],
        "published": "2025-03-16T20:56:44Z",
        "summary": "Forecasting the volatility of financial assets is essential for various financial applications. This paper addresses the challenging task of forecasting the volatility of financial assets with limited historical data, such as new issues or spin-offs, by proposing a multi-source transfer learning approach. Specifically, we exploit complementary source data of assets with a substantial historical data record by selecting source time series instances that are most similar to the limited target data of the new issue/spin-off. Based on these instances and the target data, we estimate linear and non-linear realized volatility models and compare their forecasting performance to forecasts of models trained exclusively on the target data, and models trained on the entire source and target data. The results show that our transfer learning approach outperforms the alternative models and that the integration of complementary data is also beneficial immediately after the initial trading day of the new issue/spin-off.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.12648v1"
    },
    {
        "id": "2503.12305v1",
        "title": "Intraday Battery Dispatch for Hybrid Renewable Energy Assets",
        "authors": [
            "Thiha Aung",
            "Mike Ludkovski"
        ],
        "published": "2025-03-16T00:32:07Z",
        "summary": "We develop a mathematical model for intraday dispatch of co-located wind-battery energy assets. Focusing on the primary objective of firming grid-side actual production vis-a-vis the preset day-ahead hourly generation targets, we conduct a comprehensive study of the resulting stochastic control problem across different firming formulations and wind generation dynamics. Among others, we provide a closed-form solution in the special case of a quadratic objective and linear dynamics, as well as design a novel adaptation of a Gaussian Process-based Regression Monte Carlo algorithm for our setting. Extensions studied include an asymmetric loss function for peak shaving, capturing the cost of battery cycling, and the role of battery duration. In the applied portion of our work, we calibrate our model to a collection of 140+ wind-battery assets in Texas, benchmarking the economic benefits of firming based on outputs of a realistic unit commitment and economic dispatch solver.",
        "field": "AI-Driven Behavioral Finance",
        "link": "http://arxiv.org/abs/2503.12305v1"
    },
    {
        "id": "2503.12801v1",
        "title": "BLIA: Detect model memorization in binary classification model through passive Label Inference attack",
        "authors": [
            "Mohammad Wahiduzzaman Khan",
            "Sheng Chen",
            "Ilya Mironov",
            "Leizhen Zhang",
            "Rabib Noor"
        ],
        "published": "2025-03-17T04:15:47Z",
        "summary": "Model memorization has implications for both the generalization capacity of machine learning models and the privacy of their training data. This paper investigates label memorization in binary classification models through two novel passive label inference attacks (BLIA). These attacks operate passively, relying solely on the outputs of pre-trained models, such as confidence scores and log-loss values, without interacting with or modifying the training process. By intentionally flipping 50% of the labels in controlled subsets, termed \"canaries,\" we evaluate the extent of label memorization under two conditions: models trained without label differential privacy (Label-DP) and those trained with randomized response-based Label-DP. Despite the application of varying degrees of Label-DP, the proposed attacks consistently achieve success rates exceeding 50%, surpassing the baseline of random guessing and conclusively demonstrating that models memorize training labels, even when these labels are deliberately uncorrelated with the features.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.12801v1"
    },
    {
        "id": "2503.12497v1",
        "title": "Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy",
        "authors": [
            "Jian-Ping Mei",
            "Weibin Zhang",
            "Jie Chen",
            "Xuyun Zhang",
            "Tiantian Zhu"
        ],
        "published": "2025-03-16T13:22:53Z",
        "summary": "Malicious users attempt to replicate commercial models functionally at low cost by training a clone model with query responses. It is challenging to timely prevent such model-stealing attacks to achieve strong protection and maintain utility. In this paper, we propose a novel non-parametric detector called Account-aware Distribution Discrepancy (ADD) to recognize queries from malicious users by leveraging account-wise local dependency. We formulate each class as a Multivariate Normal distribution (MVN) in the feature space and measure the malicious score as the sum of weighted class-wise distribution discrepancy. The ADD detector is combined with random-based prediction poisoning to yield a plug-and-play defense module named D-ADD for image classification models. Results of extensive experimental studies show that D-ADD achieves strong defense against different types of attacks with little interference in serving benign users for both soft and hard-label settings.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.12497v1"
    },
    {
        "id": "2503.12192v1",
        "title": "Closing the Chain: How to reduce your risk of being SolarWinds, Log4j, or XZ Utils",
        "authors": [
            "Sivana Hamer",
            "Jacob Bowen",
            "Md Nazmul Haque",
            "Robert Hines",
            "Chris Madden",
            "Laurie Williams"
        ],
        "published": "2025-03-15T16:22:09Z",
        "summary": "Software supply chain frameworks, such as the US NIST Secure Software Development Framework (SSDF), detail what tasks software development organizations should adopt to reduce security risk. However, to further reduce the risk of similar attacks occurring, framework adopters (i.e., software organizations) would benefit from knowing what tasks mitigate attack techniques the attackers are currently using to help organizations prioritize and to indicate current framework task gaps that leave organizations vulnerable to attacks. The goal of this study is to aid software supply chain framework adopters in reducing the risk of attacks by systematically mapping the attack techniques used in the SolarWinds, Log4j, and XZ Utils attacks to mitigating framework tasks. We qualitatively analyzed 106 Cyber Threat Intelligence (CTI) reports of the 3 attacks to gather the attack techniques. We then systematically constructed a mapping between attack techniques and the 73 tasks enumerated in 10 software supply chain frameworks. Afterward, we established and ranked priority tasks that mitigate attack techniques. The three mitigation tasks with the highest scores are role-based access control, system monitoring, and boundary protection. Additionally, three mitigation tasks were missing from all ten frameworks, including sustainable open-source software and environmental scanning tools. Thus, software products would still be vulnerable to software supply chain attacks even if organizations adopted all recommended tasks.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.12192v1"
    },
    {
        "id": "2503.11750v1",
        "title": "Making Every Step Effective: Jailbreaking Large Vision-Language Models Through Hierarchical KV Equalization",
        "authors": [
            "Shuyang Hao",
            "Yiwei Wang",
            "Bryan Hooi",
            "Jun Liu",
            "Muhao Chen",
            "Zi Huang",
            "Yujun Cai"
        ],
        "published": "2025-03-14T17:57:42Z",
        "summary": "In the realm of large vision-language models (LVLMs), adversarial jailbreak attacks serve as a red-teaming approach to identify safety vulnerabilities of these models and their associated defense mechanisms. However, we identify a critical limitation: not every adversarial optimization step leads to a positive outcome, and indiscriminately accepting optimization results at each step may reduce the overall attack success rate. To address this challenge, we introduce HKVE (Hierarchical Key-Value Equalization), an innovative jailbreaking framework that selectively accepts gradient optimization results based on the distribution of attention scores across different layers, ensuring that every optimization step positively contributes to the attack. Extensive experiments demonstrate HKVE's significant effectiveness, achieving attack success rates of 75.08% on MiniGPT4, 85.84% on LLaVA and 81.00% on Qwen-VL, substantially outperforming existing methods by margins of 20.43\\%, 21.01\\% and 26.43\\% respectively. Furthermore, making every step effective not only leads to an increase in attack success rate but also allows for a reduction in the number of iterations, thereby lowering computational costs. Warning: This paper contains potentially harmful example data.",
        "field": "AI-Powered Credit Scoring",
        "link": "http://arxiv.org/abs/2503.11750v1"
    },
    {
        "id": "2503.13193v1",
        "title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs",
        "authors": [
            "Kristoffer Andersson",
            "Adam Andersson",
            "Cornelis W. Oosterlee"
        ],
        "published": "2025-03-17T14:01:37Z",
        "summary": "We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.13193v1"
    },
    {
        "id": "2503.13052v1",
        "title": "Bitcoin Battle: Burning Bitcoin for Geopolitical Fun and Profit",
        "authors": [
            "Kris Oosthoek",
            "Kelvin Lubbertsen",
            "Georgios Smaragdakis"
        ],
        "published": "2025-03-17T10:55:59Z",
        "summary": "This study empirically analyzes the transaction activity of Bitcoin addresses linked to Russian intelligence services, which have liquidated over 7 Bitcoin (BTC), i.e., equivalent to approximately US$300,000 based on the exchange rate at the time. Our investigation begins with an observed anomaly in transaction outputs featuring the Bitcoin Script operation code, tied to input addresses identified by cyber threat intelligence sources and court documents as belonging to Russian intelligence agencies. We explore how an unauthorized entity appears to have gained control of the associated private keys, with messages embedded in the outputs confirming the seizure. Tracing the funds' origins, we connect them to cryptocurrency mixers and establish a link to the Russian ransomware group Conti, implicating intelligence service involvement. This analysis represents one of the first empirical studies of large-scale Bitcoin misuse by nation-state cyber actors.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.13052v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12314v1",
        "title": "Empirical Privacy Variance",
        "authors": [
            "Yuzheng Hu",
            "Fan Wu",
            "Ruicheng Xian",
            "Yuhang Liu",
            "Lydia Zakynthinou",
            "Pritish Kamath",
            "Chiyuan Zhang",
            "David Forsyth"
        ],
        "published": "2025-03-16T01:43:49Z",
        "summary": "We propose the notion of empirical privacy variance and study it in the context of differentially private fine-tuning of language models. Specifically, we show that models calibrated to the same $(\\varepsilon, \\delta)$-DP guarantee using DP-SGD with different hyperparameter configurations can exhibit significant variations in empirical privacy, which we quantify through the lens of memorization. We investigate the generality of this phenomenon across multiple dimensions and discuss why it is surprising and relevant. Through regression analysis, we examine how individual and composite hyperparameters influence empirical privacy. The results reveal a no-free-lunch trade-off: existing practices of hyperparameter tuning in DP-SGD, which focus on optimizing utility under a fixed privacy budget, often come at the expense of empirical privacy. To address this, we propose refined heuristics for hyperparameter selection that explicitly account for empirical privacy, showing that they are both precise and practically useful. Finally, we take preliminary steps to understand empirical privacy variance. We propose two hypotheses, identify limitations in existing techniques like privacy auditing, and outline open questions for future research.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.12314v1"
    },
    {
        "id": "2503.12248v1",
        "title": "Electromagnetic Side-Channel Analysis of PRESENT Lightweight Cipher",
        "authors": [
            "Nilupulee A Gunathilake",
            "Owen Lo",
            "William J Buchanan",
            "Ahmed Al-Dubai"
        ],
        "published": "2025-03-15T20:09:23Z",
        "summary": "Side-channel vulnerabilities pose an increasing threat to cryptographically protected devices. Consequently, it is crucial to observe information leakages through physical parameters such as power consumption and electromagnetic (EM) radiation to reduce susceptibility during interactions with cryptographic functions. EM side-channel attacks are becoming more prevalent. PRESENT is a promising lightweight cryptographic algorithm expected to be incorporated into Internet-of-Things (IoT) devices in the future. This research investigates the EM side-channel robustness of PRESENT using a correlation attack model. This work extends our previous Correlation EM Analysis (CEMA) of PRESENT with improved results. The attack targets the Substitution box (S-box) and can retrieve 8 bytes of the 10-byte encryption key with a minimum of 256 EM waveforms. This paper presents the process of EM attack modelling, encompassing both simple and correlation attacks, followed by a critical analysis.",
        "field": "AI-Driven Customer Sentiment Analysis",
        "link": "http://arxiv.org/abs/2503.12248v1"
    },
    {
        "id": "2503.12896v1",
        "title": "Safeguarding LLM Embeddings in End-Cloud Collaboration via Entropy-Driven Perturbation",
        "authors": [
            "Shuaifan Jin",
            "Xiaoyi Pang",
            "Zhibo Wang",
            "He Wang",
            "Jiacheng Du",
            "Jiahui Hu",
            "Kui Ren"
        ],
        "published": "2025-03-17T07:58:05Z",
        "summary": "Recent studies improve on-device language model (LM) inference through end-cloud collaboration, where the end device retrieves useful information from cloud databases to enhance local processing, known as Retrieval-Augmented Generation (RAG). Typically, to retrieve information from the cloud while safeguarding privacy, the end device transforms original data into embeddings with a local embedding model. However, the recently emerging Embedding Inversion Attacks (EIAs) can still recover the original data from text embeddings (e.g., training a recovery model to map embeddings back to original texts), posing a significant threat to user privacy. To address this risk, we propose EntroGuard, an entropy-driven perturbation-based embedding privacy protection method, which can protect the privacy of text embeddings while maintaining retrieval accuracy during the end-cloud collaboration. Specifically, to defeat various EIAs, we perturb the embeddings to increase the entropy of the recovered text in the common structure of recovery models, thus steering the embeddings toward meaningless texts rather than original sensitive texts during the recovery process. To maintain retrieval performance in the cloud, we constrain the perturbations within a bound, applying the strategy of reducing them where redundant and increasing them where sparse. Moreover, EntroGuard can be directly integrated into end devices without requiring any modifications to the embedding model. Extensive experimental results demonstrate that EntroGuard can reduce the risk of privacy leakage by up to 8 times at most with negligible loss of retrieval performance compared to existing privacy-preserving methods.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.12896v1"
    },
    {
        "id": "2503.12192v1",
        "title": "Closing the Chain: How to reduce your risk of being SolarWinds, Log4j, or XZ Utils",
        "authors": [
            "Sivana Hamer",
            "Jacob Bowen",
            "Md Nazmul Haque",
            "Robert Hines",
            "Chris Madden",
            "Laurie Williams"
        ],
        "published": "2025-03-15T16:22:09Z",
        "summary": "Software supply chain frameworks, such as the US NIST Secure Software Development Framework (SSDF), detail what tasks software development organizations should adopt to reduce security risk. However, to further reduce the risk of similar attacks occurring, framework adopters (i.e., software organizations) would benefit from knowing what tasks mitigate attack techniques the attackers are currently using to help organizations prioritize and to indicate current framework task gaps that leave organizations vulnerable to attacks. The goal of this study is to aid software supply chain framework adopters in reducing the risk of attacks by systematically mapping the attack techniques used in the SolarWinds, Log4j, and XZ Utils attacks to mitigating framework tasks. We qualitatively analyzed 106 Cyber Threat Intelligence (CTI) reports of the 3 attacks to gather the attack techniques. We then systematically constructed a mapping between attack techniques and the 73 tasks enumerated in 10 software supply chain frameworks. Afterward, we established and ranked priority tasks that mitigate attack techniques. The three mitigation tasks with the highest scores are role-based access control, system monitoring, and boundary protection. Additionally, three mitigation tasks were missing from all ten frameworks, including sustainable open-source software and environmental scanning tools. Thus, software products would still be vulnerable to software supply chain attacks even if organizations adopted all recommended tasks.",
        "field": "AI-Driven Customer Journey Mapping",
        "link": "http://arxiv.org/abs/2503.12192v1"
    },
    {
        "id": "2503.10619v2",
        "title": "Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search",
        "authors": [
            "Andy Zhou"
        ],
        "published": "2025-03-13T17:57:32Z",
        "summary": "We introduce Siege, a multi-turn adversarial framework that models the gradual erosion of Large Language Model (LLM) safety through a tree search perspective. Unlike single-turn jailbreaks that rely on one meticulously engineered prompt, Siege expands the conversation at each turn in a breadth-first fashion, branching out multiple adversarial prompts that exploit partial compliance from previous responses. By tracking these incremental policy leaks and re-injecting them into subsequent queries, Siege reveals how minor concessions can accumulate into fully disallowed outputs. Evaluations on the JailbreakBench dataset show that Siege achieves a 100% success rate on GPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries than baselines such as Crescendo or GOAT. This tree search methodology offers an in-depth view of how model safeguards degrade over successive dialogue turns, underscoring the urgency of robust multi-turn testing procedures for language models.",
        "field": "AI-Enhanced Regulatory Compliance",
        "link": "http://arxiv.org/abs/2503.10619v2"
    },
    {
        "id": "2503.13116v1",
        "title": "VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding",
        "authors": [
            "Zeng Wang",
            "Minghao Shao",
            "Mohammed Nabeel",
            "Prithwish Basu Roy",
            "Likhitha Mankali",
            "Jitendra Bhandari",
            "Ramesh Karri",
            "Ozgur Sinanoglu",
            "Muhammad Shafique",
            "Johann Knechtel"
        ],
        "published": "2025-03-17T12:38:03Z",
        "summary": "Large language models (LLMs) offer significant potential for coding, yet fine-tuning (FT) with curated data is essential for niche languages like Verilog. Using proprietary intellectual property (IP) for FT presents a serious risk, as FT data can be leaked through LLM inference. This leads to a critical dilemma for design houses: seeking to build externally accessible LLMs offering competitive Verilog coding, how can they leverage in-house IP to enhance FT utility while ensuring IP protection? For the first time in the literature, we study this dilemma. Using LLaMA 3.1-8B, we conduct in-house FT on a baseline Verilog dataset (RTLCoder) supplemented with our own in-house IP, which is validated through multiple tape-outs. To rigorously assess IP leakage, we quantify structural similarity (AST/Dolos) and functional equivalence (Synopsys Formality) between generated codes and our in-house IP. We show that our IP can indeed be leaked, confirming the threat. As defense, we evaluate logic locking of Verilog codes (ASSURE). This offers some level of protection, yet reduces the IP's utility for FT and degrades the LLM's performance. Our study shows the need for novel strategies that are both effective and minimally disruptive to FT, an essential effort for enabling design houses to fully utilize their proprietary IP toward LLM-driven Verilog coding.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.13116v1"
    },
    {
        "id": "2503.13056v1",
        "title": "Deep Hedging of Green PPAs in Electricity Markets",
        "authors": [
            "Richard Biegler-KÃ¶nig",
            "Daniel Oeltz"
        ],
        "published": "2025-03-17T11:02:23Z",
        "summary": "In power markets, Green Power Purchase Agreements have become an important contractual tool of the energy transition from fossil fuels to renewable sources such as wind or solar radiation. Trading Green PPAs exposes agents to price risks and weather risks. Also, developed electricity markets feature the so-called cannibalisation effect : large infeeds induce low prices and vice versa. As weather is a non-tradable entity the question arises how to hedge and risk-manage in this highly incom-plete setting. We propose a ''deep hedging'' framework utilising machine learning methods to construct hedging strategies. The resulting strategies outperform static and dynamic benchmark strategies with respect to different risk measures.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.13056v1"
    },
    {
        "id": "2503.12952v1",
        "title": "Performance Analysis and Industry Deployment of Post-Quantum Cryptography Algorithms",
        "authors": [
            "Elif Dicle Demir",
            "Buse Bilgin",
            "Mehmet Cengiz Onbasli"
        ],
        "published": "2025-03-17T09:06:03Z",
        "summary": "As quantum computing advances, modern cryptographic standards face an existential threat, necessitating a transition to post-quantum cryptography (PQC). The National Institute of Standards and Technology (NIST) has selected CRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure key exchange and digital signatures, respectively. This study conducts a comprehensive performance analysis of these algorithms by benchmarking execution times across cryptographic operations such as key generation, encapsulation, decapsulation, signing, and verification. Additionally, the impact of AVX2 optimizations is evaluated to assess hardware acceleration benefits. Our findings demonstrate that Kyber and Dilithium achieve efficient execution times, outperforming classical cryptographic schemes such as RSA and ECDSA at equivalent security levels. Beyond technical performance, the real-world deployment of PQC introduces challenges in telecommunications networks, where large-scale infrastructure upgrades, interoperability with legacy systems, and regulatory constraints must be addressed. This paper examines the feasibility of PQC adoption in telecom environments, highlighting key transition challenges, security risks, and implementation strategies. Through industry case studies, we illustrate how telecom operators are integrating PQC into 5G authentication, subscriber identity protection, and secure communications. Our analysis provides insights into the computational trade-offs, deployment considerations, and standardization efforts shaping the future of quantum-safe cryptographic infrastructure.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.12952v1"
    },
    {
        "id": "2503.12931v1",
        "title": "MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting",
        "authors": [
            "Rui Pu",
            "Chaozhuo Li",
            "Rui Ha",
            "Litian Zhang",
            "Lirong Qiu",
            "Xi Zhang"
        ],
        "published": "2025-03-17T08:41:29Z",
        "summary": "Defending large language models (LLMs) against jailbreak attacks is crucial for ensuring their safe deployment. Existing defense strategies generally rely on predefined static criteria to differentiate between harmful and benign prompts. However, such rigid rules are incapable of accommodating the inherent complexity and dynamic nature of real jailbreak attacks. In this paper, we propose a novel concept of ``mirror'' to enable dynamic and adaptive defense. A mirror refers to a dynamically generated prompt that mirrors the syntactic structure of the input while ensuring semantic safety. The personalized discrepancies between the input prompts and their corresponding mirrors serve as the guiding principles for defense. A new defense paradigm, MirrorGuard, is further proposed to detect and calibrate risky inputs based on such mirrors. An entropy-based detection metric, Relative Input Uncertainty (RIU), is integrated into MirrorGuard to quantify the discrepancies between input prompts and mirrors. MirrorGuard is evaluated on several popular datasets, demonstrating state-of-the-art defense performance while maintaining general effectiveness.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.12931v1"
    },
    {
        "id": "2503.12896v1",
        "title": "Safeguarding LLM Embeddings in End-Cloud Collaboration via Entropy-Driven Perturbation",
        "authors": [
            "Shuaifan Jin",
            "Xiaoyi Pang",
            "Zhibo Wang",
            "He Wang",
            "Jiacheng Du",
            "Jiahui Hu",
            "Kui Ren"
        ],
        "published": "2025-03-17T07:58:05Z",
        "summary": "Recent studies improve on-device language model (LM) inference through end-cloud collaboration, where the end device retrieves useful information from cloud databases to enhance local processing, known as Retrieval-Augmented Generation (RAG). Typically, to retrieve information from the cloud while safeguarding privacy, the end device transforms original data into embeddings with a local embedding model. However, the recently emerging Embedding Inversion Attacks (EIAs) can still recover the original data from text embeddings (e.g., training a recovery model to map embeddings back to original texts), posing a significant threat to user privacy. To address this risk, we propose EntroGuard, an entropy-driven perturbation-based embedding privacy protection method, which can protect the privacy of text embeddings while maintaining retrieval accuracy during the end-cloud collaboration. Specifically, to defeat various EIAs, we perturb the embeddings to increase the entropy of the recovered text in the common structure of recovery models, thus steering the embeddings toward meaningless texts rather than original sensitive texts during the recovery process. To maintain retrieval performance in the cloud, we constrain the perturbations within a bound, applying the strategy of reducing them where redundant and increasing them where sparse. Moreover, EntroGuard can be directly integrated into end devices without requiring any modifications to the embedding model. Extensive experimental results demonstrate that EntroGuard can reduce the risk of privacy leakage by up to 8 times at most with negligible loss of retrieval performance compared to existing privacy-preserving methods.",
        "field": "AI-Driven Customer Retention Strategies",
        "link": "http://arxiv.org/abs/2503.12896v1"
    },
    {
        "id": "2503.12192v1",
        "title": "Closing the Chain: How to reduce your risk of being SolarWinds, Log4j, or XZ Utils",
        "authors": [
            "Sivana Hamer",
            "Jacob Bowen",
            "Md Nazmul Haque",
            "Robert Hines",
            "Chris Madden",
            "Laurie Williams"
        ],
        "published": "2025-03-15T16:22:09Z",
        "summary": "Software supply chain frameworks, such as the US NIST Secure Software Development Framework (SSDF), detail what tasks software development organizations should adopt to reduce security risk. However, to further reduce the risk of similar attacks occurring, framework adopters (i.e., software organizations) would benefit from knowing what tasks mitigate attack techniques the attackers are currently using to help organizations prioritize and to indicate current framework task gaps that leave organizations vulnerable to attacks. The goal of this study is to aid software supply chain framework adopters in reducing the risk of attacks by systematically mapping the attack techniques used in the SolarWinds, Log4j, and XZ Utils attacks to mitigating framework tasks. We qualitatively analyzed 106 Cyber Threat Intelligence (CTI) reports of the 3 attacks to gather the attack techniques. We then systematically constructed a mapping between attack techniques and the 73 tasks enumerated in 10 software supply chain frameworks. Afterward, we established and ranked priority tasks that mitigate attack techniques. The three mitigation tasks with the highest scores are role-based access control, system monitoring, and boundary protection. Additionally, three mitigation tasks were missing from all ten frameworks, including sustainable open-source software and environmental scanning tools. Thus, software products would still be vulnerable to software supply chain attacks even if organizations adopted all recommended tasks.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.12192v1"
    },
    {
        "id": "2503.11850v1",
        "title": "Local Pan-Privacy for Federated Analytics",
        "authors": [
            "Vitaly Feldman",
            "Audra McMillan",
            "Guy N. Rothblum",
            "Kunal Talwar"
        ],
        "published": "2025-03-14T20:18:33Z",
        "summary": "Pan-privacy was proposed by Dwork et al. as an approach to designing a private analytics system that retains its privacy properties in the face of intrusions that expose the system's internal state. Motivated by federated telemetry applications, we study local pan-privacy, where privacy should be retained under repeated unannounced intrusions on the local state. We consider the problem of monitoring the count of an event in a federated system, where event occurrences on a local device should be hidden even from an intruder on that device. We show that under reasonable constraints, the goal of providing information-theoretic differential privacy under intrusion is incompatible with collecting telemetry information. We then show that this problem can be solved in a scalable way using standard cryptographic primitives.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.11850v1"
    },
    {
        "id": "2503.11777v1",
        "title": "Enhancing Resiliency of Sketch-based Security via LSB Sharing-based Dynamic Late Merging",
        "authors": [
            "Seungsam Yang",
            "Seyed Mohammad Mehdi Mirnajafizadeh",
            "Sian Kim",
            "Rhongho Jang",
            "DaeHun Nyang"
        ],
        "published": "2025-03-14T18:12:14Z",
        "summary": "With the exponentially growing Internet traffic, sketch data structure with a probabilistic algorithm has been expected to be an alternative solution for non-compromised (non-selective) security monitoring. While facilitating counting within a confined memory space, the sketch's memory efficiency and accuracy were further pushed to their limit through finer-grained and dynamic control of constrained memory space to adapt to the data stream's inherent skewness (i.e., Zipf distribution), namely small counters with extensions. In this paper, we unveil a vulnerable factor of the small counter design by introducing a new sketch-oriented attack, which threatens a stream of state-of-the-art sketches and their security applications. With the root cause analyses, we propose Siamese Counter with enhanced adversarial resiliency and verified feasibility with extensive experimental and theoretical analyses. Under a sketch pollution attack, Siamese Counter delivers 47% accurate results than a state-of-the-art scheme, and demonstrates up to 82% more accurate estimation under normal measurement scenarios.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.11777v1"
    },
    {
        "id": "2503.09712v2",
        "title": "Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain",
        "authors": [
            "Yuanmin Huang",
            "Mi Zhang",
            "Zhaoxiang Wang",
            "Wenxuan Li",
            "Min Yang"
        ],
        "published": "2025-03-12T18:05:32Z",
        "summary": "Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack. Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.",
        "field": "AI-Powered Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.09712v2"
    },
    {
        "id": "2503.12931v1",
        "title": "MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting",
        "authors": [
            "Rui Pu",
            "Chaozhuo Li",
            "Rui Ha",
            "Litian Zhang",
            "Lirong Qiu",
            "Xi Zhang"
        ],
        "published": "2025-03-17T08:41:29Z",
        "summary": "Defending large language models (LLMs) against jailbreak attacks is crucial for ensuring their safe deployment. Existing defense strategies generally rely on predefined static criteria to differentiate between harmful and benign prompts. However, such rigid rules are incapable of accommodating the inherent complexity and dynamic nature of real jailbreak attacks. In this paper, we propose a novel concept of ``mirror'' to enable dynamic and adaptive defense. A mirror refers to a dynamically generated prompt that mirrors the syntactic structure of the input while ensuring semantic safety. The personalized discrepancies between the input prompts and their corresponding mirrors serve as the guiding principles for defense. A new defense paradigm, MirrorGuard, is further proposed to detect and calibrate risky inputs based on such mirrors. An entropy-based detection metric, Relative Input Uncertainty (RIU), is integrated into MirrorGuard to quantify the discrepancies between input prompts and mirrors. MirrorGuard is evaluated on several popular datasets, demonstrating state-of-the-art defense performance while maintaining general effectiveness.",
        "field": "AI-Driven Customer Experience Personalization",
        "link": "http://arxiv.org/abs/2503.12931v1"
    },
    {
        "id": "2503.11841v1",
        "title": "Trust Under Siege: Label Spoofing Attacks against Machine Learning for Android Malware Detection",
        "authors": [
            "Tianwei Lan",
            "Luca Demetrio",
            "Farid Nait-Abdesselam",
            "Yufei Han",
            "Simone Aonzo"
        ],
        "published": "2025-03-14T20:05:56Z",
        "summary": "Machine learning (ML) malware detectors rely heavily on crowd-sourced AntiVirus (AV) labels, with platforms like VirusTotal serving as a trusted source of malware annotations. But what if attackers could manipulate these labels to classify benign software as malicious? We introduce label spoofing attacks, a new threat that contaminates crowd-sourced datasets by embedding minimal and undetectable malicious patterns into benign samples. These patterns coerce AV engines into misclassifying legitimate files as harmful, enabling poisoning attacks against ML-based malware classifiers trained on those data. We demonstrate this scenario by developing AndroVenom, a methodology for polluting realistic data sources, causing consequent poisoning attacks against ML malware detectors. Experiments show that not only state-of-the-art feature extractors are unable to filter such injection, but also various ML models experience Denial of Service already with 1% poisoned samples. Additionally, attackers can flip decisions of specific unaltered benign samples by modifying only 0.015% of the training data, threatening their reputation and market share and being unable to be stopped by anomaly detectors on training data. We conclude our manuscript by raising the alarm on the trustworthiness of the training process based on AV annotations, requiring further investigation on how to produce proper labels for ML malware detectors.",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.11841v1"
    },
    {
        "id": "2503.11216v2",
        "title": "Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and Openfhe",
        "authors": [
            "Faneela",
            "Jawad Ahmad",
            "Baraq Ghaleb",
            "Sana Ullah Jan",
            "William J. Buchanan"
        ],
        "published": "2025-03-14T09:08:30Z",
        "summary": "The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS. Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.",
        "field": "AI-Driven Financial Wellness Platforms",
        "link": "http://arxiv.org/abs/2503.11216v2"
    },
    {
        "id": "2503.12648v1",
        "title": "Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning",
        "authors": [
            "Andreas Teller",
            "Uta Pigorsch",
            "Christian Pigorsch"
        ],
        "published": "2025-03-16T20:56:44Z",
        "summary": "Forecasting the volatility of financial assets is essential for various financial applications. This paper addresses the challenging task of forecasting the volatility of financial assets with limited historical data, such as new issues or spin-offs, by proposing a multi-source transfer learning approach. Specifically, we exploit complementary source data of assets with a substantial historical data record by selecting source time series instances that are most similar to the limited target data of the new issue/spin-off. Based on these instances and the target data, we estimate linear and non-linear realized volatility models and compare their forecasting performance to forecasts of models trained exclusively on the target data, and models trained on the entire source and target data. The results show that our transfer learning approach outperforms the alternative models and that the integration of complementary data is also beneficial immediately after the initial trading day of the new issue/spin-off.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.12648v1"
    },
    {
        "id": "2503.12220v1",
        "title": "A Bubble-Cluster Federated Learning Framework for Privacy-Preserving Demand Forecasting on Heterogeneous Retail Data",
        "authors": [
            "Yunbo Long",
            "Liming Xu",
            "Ge Zheng",
            "Alexandra Brintrup"
        ],
        "published": "2025-03-15T18:07:54Z",
        "summary": "Federated learning (FL) enables retailers to share model parameters for demand forecasting while maintaining privacy. However, heterogeneous data across diverse regions, driven by factors such as varying consumer behavior, poses challenges to the effectiveness of federated learning. To tackle this challenge, we propose Bubble-Cluster Federated Learning (BFL), a novel clustering-based federated learning framework tailored for sales prediction. By leveraging differential privacy and feature importance distribution, BFL groups retailers into distinct \"bubbles\", each forming its own federated learning (FL) system to effectively isolate data heterogeneity. Within each bubble, Transformer models are designed to predict local sales for each client. Our experiments demonstrate that BFL significantly surpasses FedAvg and outperforms local learning in demand forecasting performance across all participating clients. Compared to local learning, BFL can achieve a 5.4\\% improvement in R\\textsuperscript{2}, a 69\\% reduction in RMSE, and a 45\\% decrease in MAE. Our study highlights BFL's adaptability in enabling effective federated learning through dynamic adjustments to noise levels and the range of clients participating in each bubble. This approach strategically groups participants into distinct \"bubbles\" while proactively identifying and filtering out risky clients that could compromise the FL system. The findings demonstrate BFL's ability to enhance collaborative learning in regression tasks on heterogeneous data, achieving a balance between forecasting accuracy and privacy preservation in retail applications. Additionally, BFL's capability to detect and neutralize poisoned data from clients enhances the system's robustness and reliability, ensuring more secure and effective federated learning.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.12220v1"
    },
    {
        "id": "2503.03612v3",
        "title": "Large language models in finance : what is financial sentiment?",
        "authors": [
            "Kemal Kirtac",
            "Guido Germano"
        ],
        "published": "2025-03-05T15:51:25Z",
        "summary": "Financial sentiment has become a crucial yet complex concept in finance, increasingly used in market forecasting and investment strategies. Despite its growing importance, there remains a need to define and understand what financial sentiment truly represents and how it can be effectively measured. We explore the nature of financial sentiment and investigate how large language models (LLMs) contribute to its estimation. We trace the evolution of sentiment measurement in finance, from market-based and lexicon-based methods to advanced natural language processing techniques. The emergence of LLMs has significantly enhanced sentiment analysis, providing deeper contextual understanding and greater accuracy in extracting sentiment from financial text. We examine how BERT-based models, such as RoBERTa and FinBERT, are optimized for structured sentiment classification, while GPT-based models, including GPT-4, OPT, and LLaMA, excel in financial text generation and real-time sentiment interpretation. A comparative analysis of bidirectional and autoregressive transformer architectures highlights their respective roles in investor sentiment analysis, algorithmic trading, and financial decision-making. By exploring what financial sentiment is and how it is estimated within LLMs, we provide insights into the growing role of AI-driven sentiment analysis in finance.",
        "field": "AI-Driven Financial Forecasting",
        "link": "http://arxiv.org/abs/2503.03612v3"
    },
    {
        "id": "2503.12192v1",
        "title": "Closing the Chain: How to reduce your risk of being SolarWinds, Log4j, or XZ Utils",
        "authors": [
            "Sivana Hamer",
            "Jacob Bowen",
            "Md Nazmul Haque",
            "Robert Hines",
            "Chris Madden",
            "Laurie Williams"
        ],
        "published": "2025-03-15T16:22:09Z",
        "summary": "Software supply chain frameworks, such as the US NIST Secure Software Development Framework (SSDF), detail what tasks software development organizations should adopt to reduce security risk. However, to further reduce the risk of similar attacks occurring, framework adopters (i.e., software organizations) would benefit from knowing what tasks mitigate attack techniques the attackers are currently using to help organizations prioritize and to indicate current framework task gaps that leave organizations vulnerable to attacks. The goal of this study is to aid software supply chain framework adopters in reducing the risk of attacks by systematically mapping the attack techniques used in the SolarWinds, Log4j, and XZ Utils attacks to mitigating framework tasks. We qualitatively analyzed 106 Cyber Threat Intelligence (CTI) reports of the 3 attacks to gather the attack techniques. We then systematically constructed a mapping between attack techniques and the 73 tasks enumerated in 10 software supply chain frameworks. Afterward, we established and ranked priority tasks that mitigate attack techniques. The three mitigation tasks with the highest scores are role-based access control, system monitoring, and boundary protection. Additionally, three mitigation tasks were missing from all ten frameworks, including sustainable open-source software and environmental scanning tools. Thus, software products would still be vulnerable to software supply chain attacks even if organizations adopted all recommended tasks.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.12192v1"
    },
    {
        "id": "2503.11920v1",
        "title": "Practical Implications of Implementing Local Differential Privacy for Smart grids",
        "authors": [
            "Khadija Hafeez",
            "Mubashir Husain Rehmani",
            "Sumita Mishra",
            "Donna OShea"
        ],
        "published": "2025-03-14T23:11:46Z",
        "summary": "Recent smart grid advancements enable near-realtime reporting of electricity consumption, raising concerns about consumer privacy. Differential privacy (DP) has emerged as a viable privacy solution, where a calculated amount of noise is added to the data by a trusted third party, or individual users perturb their information locally, and only send the randomized data to an aggregator for analysis safeguarding users and aggregators privacy. However, the practical implementation of a Local DP-based (LDP) privacy model for smart grids has its own challenges. In this paper, we discuss the challenges of implementing an LDP-based model for smart grids. We compare existing LDP mechanisms in smart grids for privacy preservation of numerical data and discuss different methods for selecting privacy parameters in the existing literature, their limitations and the non-existence of an optimal method for selecting the privacy parameters. We also discuss the challenges of translating theoretical models of LDP into a practical setting for smart grids for different utility functions, the impact of the size of data set on privacy and accuracy, and vulnerability of LDP-based smart grids to manipulation attacks. Finally, we discuss future directions in research for better practical applications in LDP based models for smart grids.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.11920v1"
    },
    {
        "id": "2503.11917v1",
        "title": "A Framework for Evaluating Emerging Cyberattack Capabilities of AI",
        "authors": [
            "Mikel Rodriguez",
            "Raluca Ada Popa",
            "Four Flynn",
            "Lihao Liang",
            "Allan Dafoe",
            "Anna Wang"
        ],
        "published": "2025-03-14T23:05:02Z",
        "summary": "As frontier models become more capable, the community has attempted to evaluate their ability to enable cyberattacks. Performing a comprehensive evaluation and prioritizing defenses are crucial tasks in preparing for AGI safely. However, current cyber evaluation efforts are ad-hoc, with no systematic reasoning about the various phases of attacks, and do not provide a steer on how to use targeted defenses. In this work, we propose a novel approach to AI cyber capability evaluation that (1) examines the end-to-end attack chain, (2) helps to identify gaps in the evaluation of AI threats, and (3) helps defenders prioritize targeted mitigations and conduct AI-enabled adversary emulation to support red teaming. To achieve these goals, we propose adapting existing cyberattack chain frameworks to AI systems. We analyze over 12,000 instances of real-world attempts to use AI in cyberattacks catalogued by Google's Threat Intelligence Group. Using this analysis, we curate a representative collection of seven cyberattack chain archetypes and conduct a bottleneck analysis to identify areas of potential AI-driven cost disruption. Our evaluation benchmark consists of 50 new challenges spanning different phases of cyberattacks. Based on this, we devise targeted cybersecurity model evaluations, report on the potential for AI to amplify offensive cyber capabilities across specific attack phases, and conclude with recommendations on prioritizing defenses. In all, we consider this to be the most comprehensive AI cyber risk evaluation framework published so far.",
        "field": "AI-Powered Regulatory Reporting",
        "link": "http://arxiv.org/abs/2503.11917v1"
    },
    {
        "id": "2503.12192v1",
        "title": "Closing the Chain: How to reduce your risk of being SolarWinds, Log4j, or XZ Utils",
        "authors": [
            "Sivana Hamer",
            "Jacob Bowen",
            "Md Nazmul Haque",
            "Robert Hines",
            "Chris Madden",
            "Laurie Williams"
        ],
        "published": "2025-03-15T16:22:09Z",
        "summary": "Software supply chain frameworks, such as the US NIST Secure Software Development Framework (SSDF), detail what tasks software development organizations should adopt to reduce security risk. However, to further reduce the risk of similar attacks occurring, framework adopters (i.e., software organizations) would benefit from knowing what tasks mitigate attack techniques the attackers are currently using to help organizations prioritize and to indicate current framework task gaps that leave organizations vulnerable to attacks. The goal of this study is to aid software supply chain framework adopters in reducing the risk of attacks by systematically mapping the attack techniques used in the SolarWinds, Log4j, and XZ Utils attacks to mitigating framework tasks. We qualitatively analyzed 106 Cyber Threat Intelligence (CTI) reports of the 3 attacks to gather the attack techniques. We then systematically constructed a mapping between attack techniques and the 73 tasks enumerated in 10 software supply chain frameworks. Afterward, we established and ranked priority tasks that mitigate attack techniques. The three mitigation tasks with the highest scores are role-based access control, system monitoring, and boundary protection. Additionally, three mitigation tasks were missing from all ten frameworks, including sustainable open-source software and environmental scanning tools. Thus, software products would still be vulnerable to software supply chain attacks even if organizations adopted all recommended tasks.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.12192v1"
    },
    {
        "id": "2503.11850v1",
        "title": "Local Pan-Privacy for Federated Analytics",
        "authors": [
            "Vitaly Feldman",
            "Audra McMillan",
            "Guy N. Rothblum",
            "Kunal Talwar"
        ],
        "published": "2025-03-14T20:18:33Z",
        "summary": "Pan-privacy was proposed by Dwork et al. as an approach to designing a private analytics system that retains its privacy properties in the face of intrusions that expose the system's internal state. Motivated by federated telemetry applications, we study local pan-privacy, where privacy should be retained under repeated unannounced intrusions on the local state. We consider the problem of monitoring the count of an event in a federated system, where event occurrences on a local device should be hidden even from an intruder on that device. We show that under reasonable constraints, the goal of providing information-theoretic differential privacy under intrusion is incompatible with collecting telemetry information. We then show that this problem can be solved in a scalable way using standard cryptographic primitives.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.11850v1"
    },
    {
        "id": "2503.11777v1",
        "title": "Enhancing Resiliency of Sketch-based Security via LSB Sharing-based Dynamic Late Merging",
        "authors": [
            "Seungsam Yang",
            "Seyed Mohammad Mehdi Mirnajafizadeh",
            "Sian Kim",
            "Rhongho Jang",
            "DaeHun Nyang"
        ],
        "published": "2025-03-14T18:12:14Z",
        "summary": "With the exponentially growing Internet traffic, sketch data structure with a probabilistic algorithm has been expected to be an alternative solution for non-compromised (non-selective) security monitoring. While facilitating counting within a confined memory space, the sketch's memory efficiency and accuracy were further pushed to their limit through finer-grained and dynamic control of constrained memory space to adapt to the data stream's inherent skewness (i.e., Zipf distribution), namely small counters with extensions. In this paper, we unveil a vulnerable factor of the small counter design by introducing a new sketch-oriented attack, which threatens a stream of state-of-the-art sketches and their security applications. With the root cause analyses, we propose Siamese Counter with enhanced adversarial resiliency and verified feasibility with extensive experimental and theoretical analyses. Under a sketch pollution attack, Siamese Counter delivers 47% accurate results than a state-of-the-art scheme, and demonstrates up to 82% more accurate estimation under normal measurement scenarios.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.11777v1"
    },
    {
        "id": "2503.09712v2",
        "title": "Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain",
        "authors": [
            "Yuanmin Huang",
            "Mi Zhang",
            "Zhaoxiang Wang",
            "Wenxuan Li",
            "Min Yang"
        ],
        "published": "2025-03-12T18:05:32Z",
        "summary": "Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack. Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.",
        "field": "AI-Driven Financial Health Monitoring",
        "link": "http://arxiv.org/abs/2503.09712v2"
    }
]